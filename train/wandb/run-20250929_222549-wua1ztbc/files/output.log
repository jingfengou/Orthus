[34m[1mwandb[0m: [33mWARNING[0m Serializing object of type dict that is 1922480 bytes
  0%|                                                                                                                                | 0/118 [00:00<?, ?it/s]2025-09-29 22:25:52,156 - WARNING - `use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.

======================================== [DEBUGGING AT GLOBAL STEP: 0] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because it is a vertically mirrored version of the back-bottom-left view.', 'C': 'Option C is incorrect because it is a horizontally mirrored version of the front-top-right view.', 'ABCD': 'Assuming the bottom face is the first cell in the second row of the net, then after folding, the front face is cyan, the back face is red, the left face is green, the right face is blue, the top face is yellow, the bottom face is pink.', 'B': 'Option B is correct because it shows the back-bottom-right view.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
  1%|‚ñà                                                                                                                       | 1/118 [00:18<36:19, 18.62s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 1] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'The counterclockwise rotation of the green object drives the orange object to rotate clockwise, which in turn pulls the weight upward.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
  2%|‚ñà‚ñà                                                                                                                      | 2/118 [00:33<31:32, 16.32s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 2] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'C': 'Option C is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
  3%|‚ñà‚ñà‚ñà                                                                                                                     | 3/118 [00:48<30:02, 15.67s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 3] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option D is correct because it shows the back-bottom-right view.', 'B': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option B is incorrect because it includes rotated non-symmetric faces.', 'C': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option C is incorrect because it includes rotated non-symmetric faces.', 'A': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option A is incorrect because it is a horizontally mirrored version of the back-top-left view.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
  3%|‚ñà‚ñà‚ñà‚ñà                                                                                                                    | 4/118 [01:03<29:25, 15.49s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 4] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because the initial arrow can be transformed into the final arrow.', 'BDA': 'Option BDA is incorrect because the initial arrow cannot be transformed into the final arrow.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
  4%|‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                                   | 5/118 [01:18<29:02, 15.42s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 5] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is incorrect because holes in column 1 are missing.', 'A': 'Option A is incorrect because extra holes appear in column 2.', 'D': 'Option D is incorrect because holes that should appear in column 1 appear in column 2.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
  5%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                                  | 6/118 [01:33<28:21, 15.19s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 6] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given three views, at least 4 cubes and at most 4 cubes are required to satisfy the constraints.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
  6%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                                 | 7/118 [01:48<28:02, 15.16s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 7] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because it was obtained by rotating the original image 180 degrees.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it horizontally.', 'B': 'Option B is incorrect because it was obtained by rotating the original image 90 degrees and then flipping it vertically.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                               | 8/118 [02:03<27:29, 14.99s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 8] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is incorrect because one cube is missing, resulting in an incorrect cube stack shape.', 'C': 'Option C is incorrect because one cube is missing, resulting in an incorrect cube stack shape.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                              | 9/118 [02:17<27:07, 14.93s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 9] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'CDB': 'Option CDB is incorrect because this net could be a valid net for the given cube, as the positions of cyan, pink, and blue match the shown cube.', 'A': 'Option A is correct because this net cannot be a valid net for the given cube, as the positions of yellow and cyan are reversed.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m cube cube[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                             | 10/118 [02:32<26:42, 14.84s/it]

{'loss': 19.7785, 'grad_norm': 72.0248794555664, 'learning_rate': 4.965903258506806e-06, 'epoch': 0.08}
(tensor([[[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -2.9062,  -2.0781,   5.2500,  ...,  -6.6250,  -2.8750,  -2.2188],
         [ -2.4062,  -1.6328,   5.5938,  ...,  -6.1250,  -2.0781,  -1.6641],
         [ -1.6797,  -1.6094,   6.5000,  ...,  -5.9688,  -0.4082,  -1.0781]],

        [[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -3.0781,  -2.3281,   5.1250,  ...,  -6.8438,  -3.0000,  -2.8438],
         [ -2.5938,  -1.9062,   5.5000,  ...,  -6.4062,  -2.1875,  -2.1875],
         [ -1.4922,  -1.7344,   6.5625,  ...,  -6.0000,  -0.5312,  -1.3047]]],
       device='cuda:0'),)
 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                        | 2/15 [00:02<00:15,  1.18s/it]
(tensor([[[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -2.9062,  -2.3906,   5.4375,  ...,  -6.6875,  -2.8125,  -1.9922],
         [ -2.3750,  -1.8672,   5.8125,  ...,  -6.1562,  -2.0312,  -1.3438],
         [ -1.6875,  -1.7891,   6.6562,  ...,  -6.0312,  -0.5352,  -1.0234]],

        [[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -3.3906,  -2.7031,   4.9688,  ...,  -6.8438,  -3.0469,  -3.1406],
         [ -2.8438,  -2.2031,   5.3750,  ...,  -6.3125,  -2.2344,  -2.2969],
         [ -1.8281,  -1.9141,   6.5312,  ...,  -5.8125,  -0.6914,  -1.6484]]],
       device='cuda:0'),)
(tensor([[[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -3.4219,  -2.9531,   4.7500,  ...,  -7.1250,  -3.5000,  -3.9219],
         [ -2.9219,  -2.4375,   5.1250,  ...,  -6.6562,  -2.5625,  -2.9844],
         [ -1.6797,  -2.3594,   6.2500,  ...,  -6.2188,  -0.8359,  -1.5078]],

        [[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -3.2188,  -2.6719,   4.9062,  ...,  -6.8438,  -2.8594,  -4.0938],
         [ -2.6406,  -2.1875,   5.3125,  ...,  -6.2812,  -2.1562,  -3.3125],
         [ -1.6328,  -1.7578,   6.2500,  ...,  -5.6875,  -0.4805,  -2.4375]]],
       device='cuda:0'),)
(tensor([[[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -2.6875,  -2.6250,   4.8125,  ...,  -6.8750,  -3.2344,  -4.1562],
         [ -2.2656,  -2.0938,   5.3125,  ...,  -6.3125,  -2.3125,  -2.9688],
         [ -1.3906,  -2.1094,   6.3438,  ...,  -6.0938,  -0.7539,  -2.2188]],

        [[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -3.5625,  -2.9219,   4.6875,  ...,  -7.1250,  -3.5000,  -3.8438],
         [ -3.1875,  -2.4375,   5.0312,  ...,  -6.6562,  -2.5938,  -2.9688],
         [ -1.9609,  -2.2656,   6.1875,  ...,  -6.2500,  -0.7969,  -1.3984]]],
       device='cuda:0'),)
(tensor([[[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -3.5312,  -2.7812,   4.8438,  ...,  -7.0938,  -2.9062,  -3.0625],
         [ -3.1875,  -2.3281,   5.2188,  ...,  -6.6250,  -2.0781,  -2.3906],
         [ -2.0000,  -2.0781,   6.2500,  ...,  -6.1562,  -0.6602,  -1.6250]],

        [[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -3.4844,  -2.5156,   4.9375,  ...,  -6.9688,  -3.0312,  -3.1406],
         [ -2.8906,  -2.0156,   5.3438,  ...,  -6.4062,  -2.0625,  -2.4844],
         [ -1.9688,  -1.8906,   6.3750,  ...,  -5.9688,  -0.3457,  -1.3594]]],
       device='cuda:0'),)
(tensor([[[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -2.9375,  -2.4688,   5.3125,  ...,  -6.8125,  -2.8438,  -2.7188],
         [ -2.4062,  -2.0625,   5.7188,  ...,  -6.3750,  -2.0625,  -1.9766],
         [ -1.3516,  -1.9141,   6.6562,  ...,  -5.9688,  -0.5664,  -1.4219]],

        [[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -3.2188,  -2.9375,   4.6562,  ...,  -7.0938,  -3.0000,  -4.0312],
         [ -2.9375,  -2.3438,   5.0000,  ...,  -6.5312,  -2.1719,  -3.2500],
         [ -1.6797,  -1.7812,   5.9688,  ...,  -5.8750,  -0.5508,  -2.3281]]],
       device='cuda:0'),)
(tensor([[[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -3.6094,  -2.6562,   5.0625,  ...,  -6.9375,  -2.7500,  -3.2344],
         [ -3.1562,  -2.2188,   5.4375,  ...,  -6.4062,  -1.9453,  -2.4688],
         [ -1.8672,  -1.9688,   6.3750,  ...,  -6.0625,  -0.5000,  -1.6641]],

        [[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -2.9219,  -2.4219,   5.0000,  ...,  -6.9062,  -2.8906,  -3.0625],
         [ -2.5781,  -2.0156,   5.3438,  ...,  -6.4688,  -2.0469,  -2.3438],
         [ -1.4844,  -1.9141,   6.5312,  ...,  -6.0000,  -0.4355,  -1.3906]]],
       device='cuda:0'),)
(tensor([[[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -2.9844,  -2.4531,   4.9688,  ...,  -6.8438,  -2.8438,  -3.0781],
         [ -2.6094,  -2.0781,   5.3125,  ...,  -6.4688,  -2.0625,  -2.4219],
         [ -1.4688,  -1.9844,   6.4375,  ...,  -6.0312,  -0.4922,  -1.4844]],

        [[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -3.4844,  -2.5000,   5.0938,  ...,  -7.1562,  -3.1094,  -4.0625],
         [ -3.2344,  -2.0156,   5.4062,  ...,  -6.7812,  -2.3906,  -3.5000],
         [ -2.1406,  -1.9844,   6.4688,  ...,  -6.2812,  -0.6641,  -2.0781]]],
       device='cuda:0'),)
(tensor([[[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -2.9375,  -2.5312,   5.1562,  ...,  -7.0938,  -2.6719,  -2.8594],
         [ -2.5156,  -2.0938,   5.4688,  ...,  -6.5938,  -1.8672,  -2.0469],
         [ -1.8438,  -2.0000,   6.3125,  ...,  -6.1562,  -0.4414,  -1.3125]],

        [[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -3.2500,  -2.5781,   5.2500,  ...,  -6.6875,  -2.9062,  -3.2188],
         [ -2.6719,  -2.1094,   5.6562,  ...,  -6.1250,  -2.1094,  -2.4219],
         [ -1.9766,  -1.9062,   6.4375,  ...,  -5.7188,  -0.4941,  -1.5625]]],
       device='cuda:0'),)
(tensor([[[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -2.9844,  -2.6094,   5.1562,  ...,  -6.7812,  -2.8594,  -3.1094],
         [ -2.4531,  -2.1562,   5.5625,  ...,  -6.2500,  -1.9922,  -2.2969],
         [ -1.7188,  -2.0000,   6.4062,  ...,  -5.8125,  -0.4844,  -1.6406]],

        [[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -3.4375,  -2.6406,   4.7812,  ...,  -7.0312,  -3.0469,  -3.2969],
         [ -3.0156,  -2.1406,   5.2188,  ...,  -6.5000,  -2.1094,  -2.5625],
         [ -1.9922,  -2.0469,   6.2812,  ...,  -6.1562,  -0.5117,  -1.5156]]],
       device='cuda:0'),)
(tensor([[[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -3.0000,  -2.4062,   5.2500,  ...,  -6.9062,  -2.7969,  -2.7188],
         [ -2.4062,  -2.0000,   5.6250,  ...,  -6.5000,  -2.0625,  -1.9453],
         [ -1.4141,  -1.8516,   6.5000,  ...,  -6.0312,  -0.5312,  -1.3516]],

        [[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -3.7969,  -2.5781,   5.2188,  ...,  -6.9062,  -2.8438,  -3.0312],
         [ -3.0938,  -2.1094,   5.7188,  ...,  -6.3750,  -1.9688,  -2.2812],
         [ -1.9922,  -1.8906,   6.5625,  ...,  -5.9688,  -0.2656,  -1.4297]]],
       device='cuda:0'),)
(tensor([[[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -3.0312,  -2.6562,   5.0000,  ...,  -6.8438,  -2.9688,  -2.9688],
         [ -2.2969,  -2.1719,   5.4375,  ...,  -6.2812,  -2.1250,  -2.0781],
         [ -1.4375,  -2.0312,   6.4688,  ...,  -6.0000,  -0.6133,  -1.6484]],

        [[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -3.7812,  -2.7344,   4.9375,  ...,  -7.0312,  -2.9844,  -2.9375],
         [ -3.2656,  -2.2344,   5.3750,  ...,  -6.5000,  -2.0625,  -2.2188],
         [ -2.0312,  -1.9766,   6.3438,  ...,  -6.0312,  -0.5352,  -1.3750]]],
       device='cuda:0'),)
(tensor([[[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -3.2969,  -2.5156,   5.0312,  ...,  -6.9375,  -3.0312,  -3.0312],
         [ -2.8438,  -2.0312,   5.4375,  ...,  -6.4688,  -2.0625,  -2.3906],
         [ -1.7812,  -1.9062,   6.4688,  ...,  -6.0000,  -0.4199,  -1.2891]],

        [[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -3.1562,  -2.3438,   5.1562,  ...,  -7.1875,  -3.0938,  -3.4531],
         [ -3.0469,  -1.9141,   5.5312,  ...,  -6.7188,  -2.3438,  -2.8281],
         [ -1.6562,  -1.9766,   6.5000,  ...,  -6.2500,  -0.8867,  -1.7656]]],
       device='cuda:0'),)
(tensor([[[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -3.3750,  -2.5156,   5.0000,  ...,  -6.8438,  -2.9062,  -3.1875],
         [ -2.9688,  -2.0938,   5.4375,  ...,  -6.2812,  -2.0156,  -2.4219],
         [ -2.2500,  -1.8984,   6.3125,  ...,  -5.8125,  -0.5391,  -1.6484]],

        [[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -3.1719,  -2.4844,   5.1875,  ...,  -6.9688,  -2.7344,  -3.3125],
         [ -2.6250,  -1.9844,   5.5938,  ...,  -6.4062,  -1.9453,  -2.4531],
         [ -1.6172,  -1.9062,   6.3750,  ...,  -6.0312,  -0.4785,  -1.4766]]],
       device='cuda:0'),)
(tensor([[[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -3.3906,  -2.6875,   4.8438,  ...,  -6.8438,  -2.9219,  -3.5312],
         [ -3.0781,  -2.1406,   5.1250,  ...,  -6.3750,  -2.1562,  -2.8906],
         [ -1.9453,  -1.7109,   6.0625,  ...,  -5.6875,  -0.6055,  -2.0781]],

        [[-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         [-17.3750, -15.6875,  -8.3125,  ..., -17.2500, -12.0625, -10.3125],
         ...,
         [ -3.6406,  -2.9219,   4.9062,  ...,  -7.1250,  -3.1562,  -3.4688],
         [ -3.0938,  -2.4219,   5.2188,  ...,  -6.6875,  -2.3906,  -2.6562],
         [ -1.9453,  -2.3125,   6.1562,  ...,  -6.2500,  -0.6836,  -1.6797]]],
       device='cuda:0'),)
{'eval_loss': 5.437773704528809, 'eval_runtime': 35.9118, 'eval_samples_per_second': 6.572, 'eval_steps_per_second': 0.418, 'epoch': 0.08}

======================================== [DEBUGGING AT GLOBAL STEP: 10] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option A is correct because it shows the back-top-left view.', 'D': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option D is incorrect because it includes rotated non-symmetric faces.', 'B': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option B is incorrect because it includes rotated non-symmetric faces.', 'C': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option C is incorrect because it is a horizontally mirrored version of the back-top-right view.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m''' second row right face its rightmetry cell the row face rightsymmetric faces' bottom first cell the second row right face is its rightrored mirtopleft answeransweransweransweranswer>answeransweranswer[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                            | 11/118 [03:24<46:25, 26.03s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 11] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is correct because the cube stack can be obtained by rotating the original stack around the y-axis by 270 degrees.', 'C': 'Option C is incorrect because it is a horizontally mirrored version of the original cube stack.', 'B': 'Option B is incorrect because it was obtained by removing one small cube from the original stack.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m''''''OptionOptionAcorrectcorrect correct cube cube cube cube cube cube cube cube cube cube cube cubeaxis axis'''''''''OptionOption incorrect incorrect incorrect incorrect incorrect horizontally mir mir mir mir cube cube cube cube cube'''''''''Option'' incorrect incorrect incorrect incorrect incorrect cube cube cube cube cube cube cube'''' answeransweransweransweransweransweranswer>>>answeranswer[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                           | 12/118 [03:38<39:57, 22.61s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 12] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given three views, at least 12 cubes and at most 17 cubes are required to satisfy the constraints.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABC'''''Given Given views viewsleastleast1 cubes cubes cubes least cubes cubes cubes cubes cubes cubes cubes satisfy constraints constraints constraints constraints''' answer answer answer answer<answeranswer><>answeranswer[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                          | 13/118 [03:53<35:22, 20.21s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 13] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because holes in row 2 are missing.', 'B': 'Option B is incorrect because extra holes appear in row 3.', 'A': 'Option A is incorrect because holes that should appear in row 2 appear in row 3.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'''::'Option' is incorrect because holes holes row row row missing missing'''''':''Option B is incorrect because because holes row row rows''''''':''Option A is incorrect because holes holes appear row row row appear row row row'' The final answer answer is<answer>D<<answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                         | 14/118 [04:08<32:15, 18.61s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 14] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is correct because the initial state can be transformed into the target state.', 'DAC': 'Option DAC is incorrect because the initial state cannot be transformed into the target state.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B':''Option B is correct because because initial state can can transformed transformed final target state.'' 'DAC'::'Option DAC is incorrect because because initial state cannot cannot transformed transformed into target state''} The final answer is is<answer>B<<answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                       | 15/118 [04:23<29:53, 17.42s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 15] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'The counterclockwise rotation of the orange shaft drives the internal boundary of the green object back and forth, causing it to move horizontally.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': ' The counterclock clock rotation of the orange shaft drives the internal boundary of of green object back back and, causing to to move horizontally.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                      | 16/118 [04:37<28:15, 16.62s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 16] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because the squares with asymmetric patterns have been rotated, so it cannot form the cube shown in the left image.', 'B': 'Option B is incorrect because the relative positions of three faces match the cube shown in the left image.', 'A': 'Option A is incorrect because the relative positions of three faces match the cube shown in the left image.', 'D': 'Option D is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is correct because the squares with asymmetric patterns have been rotated, so it cannot form the cube shown in in left image.',,'B': 'OptionB is incorrect because the relative positions of three faces match the cube shown in in left image.',,'A': 'Option A is incorrect because the relative positions of three faces match the cube shown in in left image.', 'D'::'OptionD is incorrect because the relative positions of three faces match the cube shown in in left image.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                     | 17/118 [04:52<27:01, 16.06s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 17] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Assuming the bottom face is the first cell in the second row of the net, then after folding, the front face is pink, the back face is red, the left face is green, the right face is blue, the top face is yellow, the bottom face is cyan.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Ass assuming the bottom face is the first cell in the second row of the net, then after folding, the front face is pink, the back face is red, the left face is green, the right face is blue, the top face is yellow, the bottom face is cyan.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                    | 18/118 [05:07<26:09, 15.70s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 18] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because it was obtained by rotating the original image 270 degrees.', 'B': 'Option B is incorrect because it was obtained by rotating the asymmetric patterns in the image.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it horizontally.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is correct because it was obtained by rotating the original image 270 degrees.', 'B': 'Option B is incorrect because it was obtained by rotating the asymmetric patterns in the image.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it horizontally.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                   | 19/118 [05:22<25:23, 15.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 19] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given three views, at least 13 cubes and at most 15 cubes are required to satisfy the constraints.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given three views, at least 13 cubes and at most 15 cubes are required to satisfy the constraints.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                  | 20/118 [05:36<24:52, 15.23s/it]

{'loss': 1.5957, 'grad_norm': 1.7725335359573364, 'learning_rate': 4.760892901743944e-06, 'epoch': 0.17}
(tensor([[[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -4.2500,   1.6641,   4.7188,  ...,  -5.9688,  -2.8125,  -1.5547],
         [ -6.2188,   9.4375,   6.5000,  ...,   0.2793,   1.8906,   3.5312],
         [  3.2344,  11.5625,   9.3750,  ...,   4.5625,   7.4375,   5.2500]],

        [[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -5.7188,   1.1875,   3.5312,  ...,  -6.5000,  -3.3906,  -1.7734],
         [ -5.8125,   9.8750,   6.8438,  ...,   0.5430,   2.1875,   3.8281],
         [  3.3438,  11.4375,   9.1875,  ...,   4.3438,   7.2500,   5.2188]]],
       device='cuda:0'),)
 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                        | 2/15 [00:02<00:15,  1.22s/it]
(tensor([[[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -4.6562,   0.6211,   4.4375,  ...,  -6.2812,  -3.2812,  -2.1094],
         [ -6.2812,   9.2500,   6.5938,  ...,   0.1973,   1.8203,   3.4688],
         [  3.2188,  11.6250,   9.3750,  ...,   4.5938,   7.5312,   5.2812]],

        [[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -6.0938,   0.5703,   3.3594,  ...,  -6.8125,  -3.5781,  -2.1406],
         [ -6.8750,   8.6875,   5.9375,  ...,  -0.5430,   1.4297,   3.3438],
         [  1.8672,  11.1250,   9.0625,  ...,   4.5000,   6.8750,   5.1875]]],
       device='cuda:0'),)
(tensor([[[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -4.7500,   2.2656,   4.0312,  ...,  -5.8125,  -2.4375,  -0.9609],
         [ -5.6875,   9.8125,   6.7500,  ...,   0.5703,   2.3906,   3.9531],
         [  2.2344,  11.4375,   9.3125,  ...,   4.7188,   7.4375,   5.4062]],

        [[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -5.9375,   1.1328,   4.1250,  ...,  -5.7812,  -2.7344,  -1.5938],
         [ -5.6875,   9.2500,   6.7812,  ...,   0.5898,   2.1094,   3.5781],
         [  3.3750,  11.3125,   8.9375,  ...,   4.6875,   7.3125,   5.6250]]],
       device='cuda:0'),)
(tensor([[[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -5.3125,   2.5469,   3.9844,  ...,  -5.5625,  -2.5625,  -1.1250],
         [ -6.5625,   9.4375,   6.6875,  ...,   0.2207,   2.0312,   3.2969],
         [  1.8672,  11.5625,   9.0000,  ...,   4.2500,   7.2500,   5.2500]],

        [[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -4.5938,   2.6562,   4.2500,  ...,  -5.5938,  -2.1562,  -0.7812],
         [ -5.5938,   9.8750,   6.7500,  ...,   0.6133,   2.4844,   3.9531],
         [  2.4688,  11.4375,   9.4375,  ...,   4.7188,   7.5938,   5.4688]]],
       device='cuda:0'),)
(tensor([[[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -6.0312,   1.4922,   3.5469,  ...,  -6.2500,  -2.8438,  -1.4844],
         [ -6.1875,   9.6875,   6.4375,  ...,   0.2852,   2.0781,   3.7031],
         [  2.6094,  11.5625,   9.1875,  ...,   4.9062,   7.4688,   5.5312]],

        [[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -5.6562,   1.3203,   3.2656,  ...,  -6.5625,  -3.0938,  -1.8047],
         [ -6.1250,   9.3750,   6.4062,  ...,   0.1973,   2.0781,   3.3438],
         [  2.3750,  11.3750,   9.0625,  ...,   4.6562,   7.4062,   4.9062]]],
       device='cuda:0'),)
(tensor([[[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -5.6875,   0.8984,   3.4844,  ...,  -6.3125,  -3.1406,  -1.7656],
         [ -5.9688,  10.0000,   6.9375,  ...,   0.5273,   2.3438,   3.8906],
         [  3.1094,  11.4375,   9.3750,  ...,   4.4062,   7.2188,   5.2812]],

        [[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -6.2500,   0.8008,   3.3750,  ...,  -6.3750,  -3.3594,  -2.0938],
         [ -6.8750,   8.7500,   6.1875,  ...,  -0.0889,   1.3750,   3.0781],
         [  4.0625,  11.7500,   9.1250,  ...,   4.9688,   7.5312,   6.5312]]],
       device='cuda:0'),)
(tensor([[[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -6.0312,   1.2500,   3.5938,  ...,  -6.1875,  -2.7812,  -1.5469],
         [ -5.2500,  10.0000,   6.8750,  ...,   0.9102,   2.7344,   4.0625],
         [  2.9062,  11.6875,   9.3125,  ...,   5.0938,   7.6875,   5.5000]],

        [[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -5.7188,   1.3438,   3.2031,  ...,  -6.4375,  -3.2188,  -1.6250],
         [ -6.4375,   9.5625,   6.1875,  ...,   0.2852,   1.9219,   3.5469],
         [  2.9844,  11.0000,   8.8125,  ...,   4.1562,   7.0000,   5.1875]]],
       device='cuda:0'),)
(tensor([[[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -5.8438,   1.0625,   3.1562,  ...,  -6.5000,  -3.2969,  -1.8125],
         [ -6.6562,   9.2500,   6.0000,  ...,   0.1177,   1.6953,   3.3281],
         [  2.8438,  11.1250,   8.8750,  ...,   4.2500,   7.0625,   5.3125]],

        [[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -4.7188,   2.0781,   4.4375,  ...,  -5.4062,  -2.5938,  -1.3047],
         [ -6.0000,   9.5000,   6.7812,  ...,   0.7539,   1.9609,   3.5000],
         [  2.1719,  11.5000,   8.8750,  ...,   4.3750,   7.2500,   5.2188]]],
       device='cuda:0'),)
(tensor([[[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -5.2500,   1.1484,   3.2500,  ...,  -6.2500,  -3.0938,  -1.7344],
         [ -5.9375,   9.6250,   6.5312,  ...,   0.3574,   2.2500,   3.6406],
         [  3.1094,  11.6250,   9.3125,  ...,   4.6250,   7.6250,   5.7812]],

        [[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -6.0938,   0.9648,   3.1250,  ...,  -6.7188,  -3.3438,  -1.7812],
         [ -6.5312,   9.1250,   6.5625,  ...,   0.1758,   2.0781,   3.5625],
         [  2.8438,  11.8125,   9.3125,  ...,   4.8750,   7.4062,   5.9062]]],
       device='cuda:0'),)
(tensor([[[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -5.9375,   0.9805,   3.1875,  ...,  -6.5312,  -3.3438,  -2.0312],
         [ -6.1875,   9.3125,   6.6562,  ...,   0.1787,   2.0625,   3.5000],
         [  3.1562,  11.4375,   9.0625,  ...,   4.4062,   7.0938,   5.5625]],

        [[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -5.3438,   1.8438,   3.7344,  ...,  -6.0000,  -2.7188,  -1.3906],
         [ -5.6562,   9.8125,   6.9062,  ...,   0.5938,   2.3594,   3.7344],
         [  2.7031,  11.7500,   9.3125,  ...,   4.7500,   7.6562,   5.4062]]],
       device='cuda:0'),)
(tensor([[[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -5.5000,   1.2578,   3.7656,  ...,  -5.9375,  -2.8906,  -1.5469],
         [ -5.6250,  10.0625,   7.2500,  ...,   0.7539,   2.5156,   4.0312],
         [  3.0938,  11.4375,   9.3750,  ...,   4.5000,   7.2812,   5.3750]],

        [[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -6.0000,   0.7656,   3.1875,  ...,  -6.6875,  -3.0625,  -1.8516],
         [ -6.0625,   9.8750,   6.7812,  ...,   0.4805,   2.6250,   3.9375],
         [  2.3438,  11.6875,   9.5000,  ...,   5.0312,   7.7188,   5.1875]]],
       device='cuda:0'),)
(tensor([[[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -6.0000,   0.2969,   3.2500,  ...,  -6.7500,  -3.5469,  -2.3594],
         [ -6.1875,   8.9375,   6.2188,  ...,  -0.1226,   1.8047,   3.3125],
         [  2.2656,  11.0000,   9.0625,  ...,   4.3438,   7.1250,   5.0312]],

        [[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -5.7812,   1.2422,   3.2969,  ...,  -6.5312,  -3.0625,  -1.6875],
         [ -6.7812,   9.4375,   6.4062,  ...,  -0.0771,   1.8438,   3.5625],
         [  2.3750,  11.5000,   9.3750,  ...,   4.8438,   7.3438,   5.1875]]],
       device='cuda:0'),)
(tensor([[[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -5.8438,   1.1328,   3.1719,  ...,  -6.7188,  -3.2500,  -1.8359],
         [ -6.1250,   9.5625,   6.5000,  ...,   0.3164,   2.1406,   3.4844],
         [  2.5156,  11.5625,   9.2500,  ...,   4.7188,   7.4688,   5.0000]],

        [[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -4.8125,   2.6719,   4.4062,  ...,  -4.7812,  -1.7891,  -0.7070],
         [ -5.5312,  10.1250,   7.5000,  ...,   1.2969,   2.8750,   4.1875],
         [  2.1406,  11.4375,   9.1875,  ...,   4.6250,   7.5625,   5.3438]]],
       device='cuda:0'),)
(tensor([[[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -6.0312,   1.3125,   3.1562,  ...,  -6.4375,  -3.3125,  -1.6328],
         [ -6.8125,   9.1875,   6.2812,  ...,   0.0596,   1.8047,   3.6094],
         [  2.7656,  11.3750,   9.0000,  ...,   4.5625,   6.9062,   5.7188]],

        [[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -5.6562,   0.8477,   3.1875,  ...,  -6.4375,  -3.1250,  -1.7109],
         [ -5.2812,  10.1875,   6.8125,  ...,   0.8477,   2.7969,   4.1562],
         [  2.9531,  11.7500,   9.1250,  ...,   4.6562,   7.4062,   5.6562]]],
       device='cuda:0'),)
(tensor([[[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -6.3125,   0.6992,   3.3125,  ...,  -6.3125,  -3.3594,  -2.0156],
         [ -6.9062,   9.0625,   6.0938,  ...,   0.1582,   1.6406,   3.4219],
         [  3.5312,  11.5625,   9.0000,  ...,   4.7812,   7.3750,   6.1250]],

        [[-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         [-13.4375,  -9.6250,  -4.2188,  ..., -12.5000,  -7.2500,  -5.2188],
         ...,
         [ -5.0000,   2.4062,   3.9219,  ...,  -5.5938,  -2.0469,  -1.0547],
         [ -5.5312,   9.9375,   7.0000,  ...,   0.5547,   2.6875,   4.0625],
         [  2.3281,  11.1250,   9.5000,  ...,   4.6250,   7.3750,   5.2812]]],
       device='cuda:0'),)
{'eval_loss': 0.03004739060997963, 'eval_runtime': 35.11, 'eval_samples_per_second': 6.722, 'eval_steps_per_second': 0.427, 'epoch': 0.17}

======================================== [DEBUGGING AT GLOBAL STEP: 20] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given two views, at least 13 cubes and at most 22 cubes are required to satisfy the constraints.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given two views, at least 13 cubes and at most 22 cubes are required to satisfy the constraints.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                 | 21/118 [06:27<41:57, 25.95s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 21] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is incorrect because the red cubes are not in the correct position in the view.', 'A': 'Option A is incorrect because the shape matches the right view instead of the left view, and the red cubes are not in the correct position.', 'B': 'Option B is incorrect because the image shows the right view of the cube stack instead of the left view.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is incorrect because the red cubes are not in the correct position in the view.', 'A': 'Option A is incorrect because the shape matches the right view instead of the left view, and the red cubes are not in the correct position.', 'B': 'Option B is incorrect because the image shows the right view of the cube stack instead of the left view.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                | 22/118 [06:44<36:48, 23.01s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 22] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because the red cubes are not in the correct position in the view.', 'B': 'Option B is incorrect because the shape matches the right view instead of the left view, and the red cubes are not in the correct position.', 'D': 'Option D is incorrect because the image shows the right view of the cube stack instead of the left view.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is incorrect because the red cubes are not in the correct position in the view.', 'B': 'Option B is incorrect because the shape matches the right view instead of the left view, and the red cubes are not in the correct position.', 'D': 'Option D is incorrect because the image shows the right view of the cube stack instead of the left view.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                               | 23/118 [07:00<33:07, 20.92s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 23] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is correct because it was obtained by rotating the original image 90 degrees.', 'C': 'Option C is incorrect because it was obtained by rotating the original image 90 degrees and then flipping it horizontally.', 'B': 'Option B is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it vertically.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is correct because it was obtained by rotating the original image 90 degrees.', 'C': 'Option C is incorrect because it was obtained by rotating the original image 90 degrees and then flipping it horizontally.', 'B': 'Option B is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it vertically.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                              | 24/118 [07:16<30:34, 19.52s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 24] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given two views, at least 12 cubes and at most 18 cubes are required to satisfy the constraints.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given two views, at least 12 cubes and at most 18 cubes are required to satisfy the constraints.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                             | 25/118 [07:31<28:16, 18.25s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 25] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is incorrect because holes in column 2 are missing.', 'C': 'Option C is incorrect because extra holes appear in column 1.', 'B': 'Option B is incorrect because holes that should appear in column 2 appear in column 1.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is incorrect because holes in column 2 are missing.', 'C': 'Option C is incorrect because extra holes appear in column 1.', 'B': 'Option B is incorrect because holes that should appear in column 2 appear in column 1.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                            | 26/118 [07:46<26:24, 17.22s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 26] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is incorrect because holes in row 3 are missing.', 'A': 'Option A is incorrect because extra holes appear in row 1.', 'B': 'Option B is incorrect because holes that should appear in row 3 appear in row 1.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is incorrect because holes in row 3 are missing.', 'A': 'Option A is incorrect because extra holes appear in row 1.', 'B': 'Option B is incorrect because holes that should appear in row 3 appear in row 1.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                           | 27/118 [08:01<24:57, 16.46s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 27] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given three views, at least 11 cubes and at most 13 cubes are required to satisfy the constraints.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given three views, at least 11 cubes and at most 13 cubes are required to satisfy the constraints.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                          | 28/118 [08:16<24:01, 16.02s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 28] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given two views, at least 7 cubes and at most 9 cubes are required to satisfy the constraints.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given two views, at least 7 cubes and at most 9 cubes are required to satisfy the constraints.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                         | 29/118 [08:30<23:13, 15.66s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 29] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because the internal outlines are missing.', 'B': 'Option B is incorrect because the internal outlines are missing.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is incorrect because the internal outlines are missing.', 'B': 'Option B is incorrect because the internal outlines are missing.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                                        | 30/118 [08:45<22:32, 15.37s/it]

{'loss': 0.0047, 'grad_norm': 0.042541977018117905, 'learning_rate': 4.385266524442241e-06, 'epoch': 0.25}
(tensor([[[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [ -9.7500,  -1.7266,   1.9141,  ...,  -7.6250,  -6.5938,  -4.2812],
         [ -9.4375,   3.3281,   4.7500,  ...,  -4.1562,  -3.1562,  -0.3145],
         [  2.5469,  11.0000,  10.0000,  ...,   4.2188,   7.1562,   6.2188]],

        [[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [-10.6250,  -2.4062,   0.9805,  ...,  -8.2500,  -7.2812,  -4.6562],
         [ -9.3750,   3.6406,   4.3750,  ...,  -3.9688,  -3.0469,  -0.1689],
         [  2.3125,  10.8125,   9.8125,  ...,   4.1875,   6.9062,   6.2500]]],
       device='cuda:0'),)
 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                        | 2/15 [00:02<00:15,  1.21s/it]
(tensor([[[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [-10.7500,  -2.4219,   1.2891,  ...,  -7.6875,  -6.7188,  -4.5938],
         [-10.0000,   3.0156,   4.2812,  ...,  -4.1250,  -3.2812,  -0.4590],
         [  2.4531,  10.9375,   9.8750,  ...,   4.3750,   7.2812,   6.2812]],

        [[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [-10.7500,  -2.3281,   1.3672,  ...,  -8.0000,  -6.9375,  -4.5938],
         [-10.5000,   3.1719,   4.6250,  ...,  -4.1875,  -3.2344,  -0.1240],
         [  1.6797,  11.1250,  10.0000,  ...,   4.5625,   7.1250,   6.5312]]],
       device='cuda:0'),)
(tensor([[[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [ -9.0625,  -0.7812,   2.1094,  ...,  -6.9688,  -5.6875,  -3.3906],
         [ -9.5625,   4.5312,   4.7188,  ...,  -3.1719,  -1.9844,   0.4023],
         [  1.9141,  11.0000,  10.0000,  ...,   4.6875,   7.3125,   6.2812]],

        [[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [-10.5625,  -2.4219,   1.3203,  ...,  -7.6875,  -6.5000,  -4.5312],
         [ -9.6875,   3.0156,   4.8125,  ...,  -4.2188,  -3.2031,  -0.4355],
         [  2.2500,  11.0625,   9.8125,  ...,   4.3125,   6.9375,   6.7500]]],
       device='cuda:0'),)
(tensor([[[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [-10.3125,  -1.3828,   1.5781,  ...,  -7.5000,  -6.2812,  -3.8750],
         [-10.0625,   3.8906,   4.5312,  ...,  -3.6250,  -2.5625,  -0.0422],
         [  1.5234,  10.9375,   9.7500,  ...,   4.4062,   6.9062,   6.2812]],

        [[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [ -9.0000,  -0.7148,   2.2031,  ...,  -7.0000,  -5.7188,  -3.4219],
         [ -9.0625,   4.8750,   4.9062,  ...,  -2.9375,  -1.7266,   0.6172],
         [  2.1250,  11.0000,  10.1250,  ...,   4.7188,   7.4375,   6.3125]]],
       device='cuda:0'),)
(tensor([[[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [-10.2500,  -1.5547,   1.2344,  ...,  -7.4062,  -6.1875,  -3.8594],
         [-10.1250,   3.6875,   4.7188,  ...,  -3.7031,  -2.7500,   0.1309],
         [  1.8203,  11.0625,   9.8750,  ...,   4.5312,   7.1875,   6.5938]],

        [[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [-10.4375,  -2.2500,   0.8711,  ...,  -8.1250,  -6.7812,  -4.5000],
         [ -9.9375,   3.3750,   4.2188,  ...,  -4.0312,  -3.0000,  -0.5781],
         [  2.0938,  11.0625,   9.9375,  ...,   4.5625,   7.3750,   6.0625]]],
       device='cuda:0'),)
(tensor([[[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [-10.8125,  -2.7188,   0.7852,  ...,  -8.1875,  -7.0938,  -4.6875],
         [ -9.7500,   3.2656,   4.3438,  ...,  -4.0312,  -3.0156,  -0.3047],
         [  2.2188,  10.8750,   9.9375,  ...,   4.3125,   7.0312,   6.4688]],

        [[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [-10.6250,  -2.0312,   1.1953,  ...,  -7.7500,  -6.6250,  -4.5312],
         [-10.3750,   3.3125,   4.5312,  ...,  -4.1250,  -3.3594,  -0.4648],
         [  2.4375,  11.0625,   9.6250,  ...,   4.0625,   6.7188,   6.8750]]],
       device='cuda:0'),)
(tensor([[[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [-10.8125,  -2.4219,   0.8594,  ...,  -7.7500,  -6.5625,  -4.3750],
         [-10.1875,   3.3594,   4.3438,  ...,  -3.7188,  -2.6406,   0.0223],
         [  2.1406,  11.0000,   9.8750,  ...,   4.6562,   7.4062,   6.6562]],

        [[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [-10.4375,  -2.2969,   0.8672,  ...,  -8.1250,  -6.9688,  -4.5312],
         [ -9.9375,   3.5938,   3.7969,  ...,  -4.0312,  -3.1719,  -0.3887],
         [  2.2188,  10.3750,   9.5000,  ...,   3.9062,   6.6250,   6.1250]]],
       device='cuda:0'),)
(tensor([[[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [-10.3750,  -2.2188,   0.9219,  ...,  -8.1250,  -7.0000,  -4.5312],
         [ -9.5000,   4.0312,   4.0000,  ...,  -3.7812,  -2.7969,  -0.1787],
         [  2.1875,  10.6875,   9.5625,  ...,   4.0000,   6.8125,   6.2812]],

        [[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [-10.0000,  -2.1406,   1.5312,  ...,  -7.8750,  -6.6875,  -4.5625],
         [ -9.1250,   4.5000,   4.7812,  ...,  -3.3438,  -2.5000,  -0.0679],
         [  2.1719,  11.0625,  10.0625,  ...,   4.6562,   7.3750,   6.4062]]],
       device='cuda:0'),)
(tensor([[[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [-10.3750,  -2.1719,   0.8008,  ...,  -7.9375,  -6.7188,  -4.5312],
         [-10.0625,   3.5312,   4.3750,  ...,  -3.7500,  -2.7500,  -0.1846],
         [  2.4375,  10.8750,   9.8750,  ...,   4.2188,   7.0938,   6.4062]],

        [[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [-10.8125,  -1.9297,   0.9258,  ...,  -7.8438,  -6.6250,  -4.1562],
         [-10.6875,   3.5781,   4.7500,  ...,  -3.6406,  -2.5469,   0.0427],
         [  2.0625,  11.3125,   9.9375,  ...,   4.4688,   7.1250,   6.7812]]],
       device='cuda:0'),)
(tensor([[[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [-10.9375,  -2.0312,   0.9219,  ...,  -7.8750,  -6.7188,  -4.4688],
         [ -9.9375,   3.2812,   4.6562,  ...,  -3.9531,  -2.8594,  -0.2969],
         [  1.9766,  10.7500,   9.6875,  ...,   4.1875,   6.7812,   6.4688]],

        [[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [ -9.6250,  -1.4531,   1.5078,  ...,  -7.5938,  -6.2812,  -4.0312],
         [ -9.1875,   4.0000,   5.2812,  ...,  -3.5469,  -2.5469,   0.0835],
         [  1.7422,  11.0625,   9.8750,  ...,   4.4062,   7.1250,   6.2500]]],
       device='cuda:0'),)
(tensor([[[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [-10.2500,  -2.3594,   1.0625,  ...,  -8.0625,  -6.9375,  -4.6250],
         [ -9.1250,   3.9375,   4.8125,  ...,  -3.4531,  -2.5156,   0.1270],
         [  2.1719,  10.5625,   9.8750,  ...,   4.0312,   6.8125,   6.3438]],

        [[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [-10.2500,  -2.2500,   1.0312,  ...,  -7.7812,  -6.3125,  -4.3438],
         [-10.0625,   3.7969,   4.7188,  ...,  -3.7031,  -2.4531,  -0.0830],
         [  2.2812,  11.3750,  10.2500,  ...,   4.8750,   7.7188,   6.5000]]],
       device='cuda:0'),)
(tensor([[[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [-11.1250,  -2.7969,   1.1953,  ...,  -7.9688,  -6.9375,  -4.8125],
         [-10.1250,   3.1250,   4.6250,  ...,  -3.9375,  -2.9844,  -0.2695],
         [  1.8516,  11.0625,  10.0000,  ...,   4.5625,   7.4062,   6.3125]],

        [[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [-10.3125,  -1.8750,   1.0234,  ...,  -7.7188,  -6.4375,  -4.1875],
         [-10.5000,   3.6250,   4.5312,  ...,  -3.8906,  -2.9219,  -0.2246],
         [  2.2344,  11.3750,  10.1875,  ...,   4.7500,   7.4062,   6.4062]]],
       device='cuda:0'),)
(tensor([[[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [-10.1250,  -2.0781,   1.0859,  ...,  -8.0000,  -6.6250,  -4.3125],
         [ -9.6875,   3.4844,   4.5312,  ...,  -3.9688,  -2.8750,  -0.4883],
         [  2.1562,  11.0625,  10.0625,  ...,   4.5625,   7.4062,   6.1562]],

        [[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [-10.2500,  -1.8594,   1.2891,  ...,  -7.3750,  -6.3125,  -4.2812],
         [ -9.7500,   4.3438,   5.0938,  ...,  -3.0312,  -2.2188,   0.2656],
         [  2.2812,  11.3125,  10.1250,  ...,   4.9688,   7.5312,   6.5938]]],
       device='cuda:0'),)
(tensor([[[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [-10.8750,  -1.6953,   0.8555,  ...,  -7.8125,  -6.7812,  -4.1250],
         [-10.8125,   3.3594,   4.4375,  ...,  -3.9062,  -3.0156,  -0.0226],
         [  1.8750,  11.0000,   9.7500,  ...,   4.2812,   6.7500,   6.6250]],

        [[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [-10.3125,  -2.1250,   0.8555,  ...,  -7.8125,  -6.7500,  -4.3438],
         [-10.3750,   3.6406,   4.3125,  ...,  -3.7500,  -2.7031,   0.0552],
         [  2.3125,  10.9375,   9.9375,  ...,   4.2188,   6.9688,   6.5938]]],
       device='cuda:0'),)
(tensor([[[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [-10.6875,  -2.0156,   1.2031,  ...,  -7.6562,  -6.5000,  -4.3438],
         [-10.1250,   3.2344,   4.5938,  ...,  -4.1562,  -3.2812,  -0.3164],
         [  2.0312,  11.1875,   9.6875,  ...,   4.1875,   6.7188,   6.8125]],

        [[-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         [-11.3125,  -7.2500,  -2.3906,  ..., -10.4375,  -5.5000,  -3.0000],
         ...,
         [ -9.6875,  -1.1328,   1.5469,  ...,  -7.1562,  -5.7188,  -3.8125],
         [-10.0000,   4.5000,   4.5000,  ...,  -3.2188,  -2.0156,   0.4141],
         [  2.0625,  11.0000,  10.1875,  ...,   4.6250,   7.5938,   6.2812]]],
       device='cuda:0'),)
{'eval_loss': 0.020264621824026108, 'eval_runtime': 34.963, 'eval_samples_per_second': 6.75, 'eval_steps_per_second': 0.429, 'epoch': 0.25}

======================================== [DEBUGGING AT GLOBAL STEP: 30] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Assuming the bottom face is the first cell in the second row of the net, then after folding, the front face is pink, the back face is green, the left face is red, the right face is blue, the top face is cyan, the bottom face is yellow.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Assuming the bottom face is the first cell in the second row of the net, then after folding, the front face is pink, the back face is green, the left face is red, the right face is blue, the top face is cyan, the bottom face is yellow.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                                       | 31/118 [09:35<37:29, 25.85s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 31] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because holes in column 3 are missing.', 'C': 'Option C is incorrect because extra holes appear in column 4.', 'D': 'Option D is incorrect because holes that should appear in column 3 appear in column 4.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is incorrect because holes in column 3 are missing.', 'C': 'Option C is incorrect because extra holes appear in column 4.', 'D': 'Option D is incorrect because holes that should appear in column 3 appear in column 4.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                                      | 32/118 [09:50<32:13, 22.48s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 32] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because the red cubes are not in the correct position in the view.', 'B': 'Option B is incorrect because the shape matches the right view instead of the left view, and the red cubes are not in the correct position.', 'D': 'Option D is incorrect because the image shows the right view of the cube stack instead of the left view.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is incorrect because the red cubes are not in the correct position in the view.', 'B': 'Option B is incorrect because the shape matches the right view instead of the left view, and the red cubes are not in the correct position.', 'D': 'Option D is incorrect because the image shows the right view of the cube stack instead of the left view.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                                     | 33/118 [10:05<28:48, 20.33s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 33] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because holes in row 2 are missing.', 'C': 'Option C is incorrect because extra holes appear in row 4.', 'D': 'Option D is incorrect because holes that should appear in row 2 appear in row 4.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is incorrect because holes in row 2 are missing.', 'C': 'Option C is incorrect because extra holes appear in row 4.', 'D': 'Option D is incorrect because holes that should appear in row 2 appear in row 4.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                                    | 34/118 [10:20<26:07, 18.66s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 34] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is incorrect because it is the cross-section made by a plane perpendicular to the YZ plane and rotated 135 degrees around the x-axis.', 'D': 'Option D is incorrect because it is the cross-section made by a plane perpendicular to the YZ plane and rotated 45 degrees around the x-axis.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'C': 'Option C is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is incorrect because it is the cross-section made by a plane perpendicular to the YZ plane and rotated 135 degrees around the x-axis.', 'D': 'Option D is incorrect because it is the cross-section made by a plane perpendicular to the YZ plane and rotated 45 degrees around the x-axis.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'C': 'Option C is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                                   | 35/118 [10:35<24:14, 17.52s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 35] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because the internal outlines are missing.', 'C': 'Option C is incorrect because the image is a horizontally or vertically mirrored version of an incorrect view.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is incorrect because the internal outlines are missing.', 'C': 'Option C is incorrect because the image is a horizontally or vertically mirrored version of an incorrect view.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                                  | 36/118 [10:50<22:45, 16.65s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 36] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because the internal outlines are missing.', 'A': 'Option A is incorrect because the internal outlines are missing.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is incorrect because the internal outlines are missing.', 'A': 'Option A is incorrect because the internal outlines are missing.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                                 | 37/118 [11:05<21:47, 16.14s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 37] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is correct because it was obtained by rotating the original image 180 degrees.', 'C': 'Option C is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it vertically.', 'A': 'Option A is incorrect because it was obtained by rotating the asymmetric patterns in the image.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is correct because it was obtained by rotating the original image 180 degrees.', 'C': 'Option C is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it vertically.', 'A': 'Option A is incorrect because it was obtained by rotating the asymmetric patterns in the image.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                                | 38/118 [11:19<20:55, 15.70s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 38] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because holes in row 3 are missing.', 'A': 'Option A is incorrect because extra holes appear in row 2.', 'B': 'Option B is incorrect because holes that should appear in row 3 appear in row 2.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is incorrect because holes in row 3 are missing.', 'A': 'Option A is incorrect because extra holes appear in row 2.', 'B': 'Option B is incorrect because holes that should appear in row 3 appear in row 2.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                               | 39/118 [11:34<20:22, 15.48s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 39] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is correct because it was obtained by rotating the original image 180 degrees.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it horizontally.', 'C': 'Option C is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it vertically.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is correct because it was obtained by rotating the original image 180 degrees.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it horizontally.', 'C': 'Option C is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it vertically.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                              | 40/118 [11:49<19:46, 15.21s/it]

{'loss': 0.0152, 'grad_norm': 1.60716712474823, 'learning_rate': 3.8673703953060685e-06, 'epoch': 0.34}
(tensor([[[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-4.5312,  2.3594,  5.2500,  ..., -4.2188, -1.7500, -0.6875],
         [-3.2188,  9.8125,  9.0625,  ...,  0.3730,  4.9062,  4.5938],
         [ 5.7812, 13.3750, 12.4375,  ...,  5.9375, 10.1250,  7.2812]],

        [[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-5.3438,  1.6328,  4.3438,  ..., -4.8438, -2.4062, -1.0391],
         [-3.3281,  9.9375,  8.8750,  ...,  0.4180,  5.0625,  4.8125],
         [ 5.5312, 13.2500, 12.1875,  ...,  6.0312, 10.0000,  7.3750]]],
       device='cuda:0'),)
 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                        | 2/15 [00:02<00:15,  1.18s/it]
(tensor([[[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-5.3125,  1.6562,  4.5938,  ..., -4.3750, -1.7500, -0.8750],
         [-3.6250,  9.5000,  8.8125,  ...,  0.4492,  5.3750,  4.6562],
         [ 5.5000, 13.1250, 12.2500,  ...,  6.0312, 10.3125,  7.2500]],

        [[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-5.4062,  1.7109,  4.7188,  ..., -4.4062, -2.0625, -0.7188],
         [-4.3750,  9.6875,  8.8750,  ...,  0.4336,  4.8438,  4.8438],
         [ 4.8750, 13.3125, 12.3125,  ...,  6.3438, 10.1250,  7.5000]]],
       device='cuda:0'),)
(tensor([[[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-4.0625,  3.2500,  5.2500,  ..., -3.5156, -0.8047,  0.1758],
         [-3.6094, 10.5000,  8.5625,  ...,  0.9180,  5.7188,  4.9688],
         [ 5.3438, 13.0000, 12.1875,  ...,  6.3750, 10.2500,  7.0312]],

        [[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-5.7500,  1.6406,  4.3438,  ..., -4.3438, -1.6484, -0.9844],
         [-3.3750, 10.0000,  9.2500,  ...,  0.7109,  5.6250,  4.8438],
         [ 5.4375, 13.6250, 12.3125,  ...,  6.0312,  9.9375,  7.7812]]],
       device='cuda:0'),)
(tensor([[[-9.6250e+00, -6.0938e+00, -1.4609e+00,  ..., -9.5625e+00,
          -4.3750e+00, -2.0781e+00],
         [-9.6250e+00, -6.0938e+00, -1.4609e+00,  ..., -9.5625e+00,
          -4.3750e+00, -2.0781e+00],
         [-9.6250e+00, -6.0938e+00, -1.4609e+00,  ..., -9.5625e+00,
          -4.3750e+00, -2.0781e+00],
         ...,
         [-4.9688e+00,  2.7500e+00,  5.0625e+00,  ..., -3.8906e+00,
          -1.2422e+00, -1.2061e-01],
         [-3.9844e+00,  1.0312e+01,  8.8750e+00,  ...,  7.6953e-01,
           5.2500e+00,  4.7812e+00],
         [ 4.6562e+00,  1.3250e+01,  1.2188e+01,  ...,  6.2500e+00,
           9.8750e+00,  7.3125e+00]],

        [[-9.6250e+00, -6.0938e+00, -1.4609e+00,  ..., -9.5625e+00,
          -4.3750e+00, -2.0781e+00],
         [-9.6250e+00, -6.0938e+00, -1.4609e+00,  ..., -9.5625e+00,
          -4.3750e+00, -2.0781e+00],
         [-9.6250e+00, -6.0938e+00, -1.4609e+00,  ..., -9.5625e+00,
          -4.3750e+00, -2.0781e+00],
         ...,
         [-4.3750e+00,  2.9375e+00,  4.9688e+00,  ..., -3.6719e+00,
          -1.1406e+00,  5.9509e-03],
         [-3.6875e+00,  1.0750e+01,  8.7500e+00,  ...,  1.1250e+00,
           5.8438e+00,  5.1562e+00],
         [ 5.0000e+00,  1.3000e+01,  1.2062e+01,  ...,  6.2812e+00,
           1.0125e+01,  7.0625e+00]]], device='cuda:0'),)
(tensor([[[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-5.1250,  2.2031,  4.3750,  ..., -3.9688, -1.5547, -0.2168],
         [-3.7812, 10.0625,  9.0000,  ...,  0.7109,  5.5625,  5.1562],
         [ 5.0625, 13.3750, 12.1875,  ...,  6.3750, 10.2500,  7.5938]],

        [[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-5.8125,  1.5781,  3.9219,  ..., -4.7812, -2.1094, -0.9258],
         [-4.3125,  9.6250,  8.3750,  ...,  0.2715,  4.7812,  4.3750],
         [ 5.1875, 13.1875, 12.0625,  ...,  6.2188, 10.1875,  7.0000]]],
       device='cuda:0'),)
(tensor([[[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-5.3750,  1.3984,  4.2188,  ..., -4.7188, -2.1250, -1.0000],
         [-3.4844,  9.6875,  9.0625,  ...,  0.6133,  5.4062,  4.8125],
         [ 5.4688, 13.1875, 12.1875,  ...,  6.1562, 10.1250,  7.5000]],

        [[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-5.4688,  2.0938,  4.5625,  ..., -4.3125, -1.8281, -0.9023],
         [-3.6562, 10.5000,  9.4375,  ...,  0.8750,  5.0312,  4.7812],
         [ 5.6562, 13.6875, 12.1875,  ...,  5.8125,  9.8750,  7.8750]]],
       device='cuda:0'),)
(tensor([[[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-5.0625,  2.0469,  4.5000,  ..., -3.9531, -1.3281, -0.3125],
         [-4.3438,  9.8750,  8.4375,  ...,  0.6992,  5.6562,  5.1562],
         [ 5.3438, 13.3125, 12.1250,  ...,  6.3750, 10.3750,  7.6250]],

        [[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-5.4375,  1.5547,  4.0938,  ..., -4.7188, -2.2031, -0.8359],
         [-4.2812,  9.8125,  7.7812,  ...,  0.2168,  4.7188,  4.5312],
         [ 5.4062, 12.9375, 11.8125,  ...,  5.7188,  9.6875,  7.1562]]],
       device='cuda:0'),)
(tensor([[[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-4.6250,  2.5469,  5.0000,  ..., -4.0938, -1.3828, -0.1279],
         [-4.0000,  9.8125,  8.2500,  ...,  0.2490,  4.5938,  4.6875],
         [ 5.9062, 13.4375, 12.6250,  ...,  6.3125, 10.1875,  7.5938]],

        [[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-4.9375,  2.2500,  5.1250,  ..., -4.3750, -1.6484, -0.8516],
         [-2.6406, 11.2500,  9.3750,  ...,  1.1484,  5.5312,  4.8438],
         [ 5.5312, 13.5000, 12.7500,  ...,  6.2812, 10.2500,  7.3438]]],
       device='cuda:0'),)
(tensor([[[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-5.4062,  1.7422,  4.0625,  ..., -4.5312, -2.0469, -0.7930],
         [-4.1562, 10.1250,  8.7500,  ...,  0.9141,  5.3438,  5.0625],
         [ 5.2812, 12.8750, 12.0625,  ...,  6.0000, 10.0000,  7.2188]],

        [[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-5.4062,  2.2344,  4.5000,  ..., -4.3125, -1.7422, -0.4160],
         [-4.5312,  9.7500,  9.1250,  ...,  0.6055,  5.3438,  4.9375],
         [ 5.2500, 13.3750, 12.1875,  ...,  6.0938, 10.0000,  7.7188]]],
       device='cuda:0'),)
(tensor([[[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-5.2812,  1.9297,  4.4062,  ..., -4.3750, -1.8828, -0.7227],
         [-3.5781,  9.6875,  9.1875,  ...,  0.6328,  5.2188,  4.9062],
         [ 5.2188, 12.6875, 11.8750,  ...,  5.8750,  9.7500,  7.2500]],

        [[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-4.6875,  2.0938,  4.6562,  ..., -4.1562, -1.6016, -0.5117],
         [-3.0781, 10.1875,  9.4375,  ...,  0.8164,  5.3125,  5.0312],
         [ 4.8750, 13.3125, 12.1250,  ...,  6.3125, 10.1250,  7.2812]]],
       device='cuda:0'),)
(tensor([[[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-5.2188,  1.7031,  4.5000,  ..., -4.5000, -1.9531, -0.8516],
         [-3.3594,  9.9375,  9.1875,  ...,  0.7109,  5.4062,  4.9062],
         [ 5.5312, 13.2500, 12.2500,  ...,  6.1562, 10.1250,  7.5312]],

        [[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-5.4375,  1.7188,  4.1250,  ..., -4.4062, -1.6406, -0.6875],
         [-4.6250,  9.8125,  8.6250,  ...,  0.5781,  5.4688,  4.8125],
         [ 5.4062, 13.3750, 12.2500,  ...,  6.3750, 10.5000,  7.3750]]],
       device='cuda:0'),)
(tensor([[[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-5.7188,  1.2969,  4.5625,  ..., -4.4688, -1.9766, -1.0000],
         [-3.9844,  9.7500,  8.9375,  ...,  0.8008,  5.2500,  4.8125],
         [ 4.9062, 13.0625, 12.2500,  ...,  6.2812, 10.3750,  7.1875]],

        [[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-5.2188,  1.9375,  4.0312,  ..., -4.3750, -1.7891, -0.6094],
         [-4.6562,  9.8750,  8.6250,  ...,  0.3887,  4.9375,  4.6875],
         [ 5.3125, 13.4375, 12.3750,  ...,  6.3125, 10.1875,  7.3438]]],
       device='cuda:0'),)
(tensor([[[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-5.5625,  1.7969,  4.0625,  ..., -4.6875, -2.0469, -0.8320],
         [-4.0938,  9.6875,  8.5000,  ...,  0.3555,  4.8125,  4.4375],
         [ 5.2188, 13.1250, 12.0625,  ...,  6.1562, 10.1250,  7.0000]],

        [[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-4.4688,  2.9844,  5.1875,  ..., -3.5781, -0.7891, -0.2812],
         [-2.5625, 11.5000, 10.2500,  ...,  1.7266,  6.3750,  5.3438],
         [ 5.5625, 13.8750, 12.7500,  ...,  6.8125, 10.6250,  7.6875]]],
       device='cuda:0'),)
(tensor([[[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-4.7812,  2.6875,  4.9375,  ..., -3.9688, -1.5469, -0.1592],
         [-3.8750, 10.1250,  9.1875,  ...,  0.7656,  5.1250,  5.1875],
         [ 5.4062, 13.0000, 12.2500,  ...,  6.1250,  9.8125,  7.4375]],

        [[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-4.9375,  1.8672,  4.2188,  ..., -4.3125, -1.9297, -0.6250],
         [-4.3750, 10.1250,  8.5000,  ...,  0.7969,  5.5000,  5.2188],
         [ 5.3438, 13.0625, 12.1875,  ...,  5.9062,  9.9375,  7.4375]]],
       device='cuda:0'),)
(tensor([[[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-5.5938,  1.9688,  4.5312,  ..., -4.3125, -1.7500, -0.7344],
         [-3.7188, 10.0625,  9.1250,  ...,  0.5156,  5.1250,  4.8125],
         [ 5.4062, 13.8125, 12.1250,  ...,  6.0000,  9.9375,  7.8438]],

        [[-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         [-9.6250, -6.0938, -1.4609,  ..., -9.5625, -4.3750, -2.0781],
         ...,
         [-4.6250,  2.9062,  4.7812,  ..., -3.7188, -0.8125, -0.1660],
         [-3.4688, 10.7500,  8.6875,  ...,  1.1719,  6.2188,  5.1562],
         [ 5.7500, 13.1875, 12.4375,  ...,  6.5000, 10.5625,  7.2188]]],
       device='cuda:0'),)
{'eval_loss': 0.007518022786825895, 'eval_runtime': 34.966, 'eval_samples_per_second': 6.749, 'eval_steps_per_second': 0.429, 'epoch': 0.34}

======================================== [DEBUGGING AT GLOBAL STEP: 40] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is correct because it was obtained by removing one small cube from the original stack.', 'C': 'Option C is incorrect because the cube stack can be obtained by rotating the original stack around the z-axis by 90 degrees.', 'B': 'Option B is incorrect because the cube stack can be obtained by rotating the original stack around the z-axis by 180 degrees.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is correct because it was obtained by removing one small cube from the original stack.', 'C': 'Option C is incorrect because the cube stack can be obtained by rotating the original stack around the z-axis by 90 degrees.', 'B': 'Option B is incorrect because the cube stack can be obtained by rotating the original stack around the z-axis by 180 degrees.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                             | 41/118 [12:39<33:04, 25.77s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 41] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given three views, at least 10 cubes and at most 10 cubes are required to satisfy the constraints.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given three views, at least 10 cubes and at most 10 cubes are required to satisfy the constraints.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                            | 42/118 [12:54<28:27, 22.47s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 42] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given two views, at least 7 cubes and at most 9 cubes are required to satisfy the constraints.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given two views, at least 7 cubes and at most 9 cubes are required to satisfy the constraints.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                           | 43/118 [13:09<25:12, 20.17s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 43] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because the initial arrow can be transformed into the final arrow.', 'DAB': 'Option DAB is incorrect because the initial arrow cannot be transformed into the final arrow.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is correct because the initial arrow can be transformed into the final arrow.', 'DAB': 'Option DAB is incorrect because the initial arrow cannot be transformed into the final arrow.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                          | 44/118 [13:24<22:54, 18.57s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 44] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'C': 'Option C is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.','D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'C': 'Option C is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                         | 45/118 [13:38<21:09, 17.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 45] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'C': 'Option C is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'C': 'Option C is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                        | 46/118 [13:53<19:54, 16.60s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 46] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because it is a horizontally mirrored version of the front-bottom-left view.', 'B': 'Option B is incorrect because it is a vertically mirrored version of the back-bottom-right view.', 'ABCD': 'Assuming the bottom face is the first cell in the second row of the net, then after folding, the front face is cyan, the back face is blue, the left face is green, the right face is red, the top face is yellow, the bottom face is pink.', 'A': 'Option A is correct because it shows the front-top-left view.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is incorrect because it is a horizontally mirrored version of the front-bottom-left view.', 'B': 'Option B is incorrect because it is a vertically mirrored version of the back-bottom-right view.', 'ABCD': 'Assuming the bottom face is the first cell in the second row of the net, then after folding, the front face is cyan, the back face is blue, the left face is green, the right face is red, the top face is yellow, the bottom face is pink.', 'A': 'Option A is correct because it shows the front-top-left view.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                       | 47/118 [14:08<18:59, 16.05s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 47] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because the initial arrow can be transformed into the final arrow.', 'DAB': 'Option DAB is incorrect because the initial arrow cannot be transformed into the final arrow.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is correct because the initial arrow can be transformed into the final arrow.', 'DAB': 'Option DAB is incorrect because the initial arrow cannot be transformed into the final arrow.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                      | 48/118 [14:23<18:15, 15.66s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 48] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because the squares with asymmetric patterns have been rotated, so it cannot form the cube shown in the left image.', 'B': 'Option B is incorrect because the relative positions of three faces match the cube shown in the left image.', 'D': 'Option D is incorrect because the relative positions of three faces match the cube shown in the left image.', 'A': 'Option A is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is correct because the squares with asymmetric patterns have been rotated, so it cannot form the cube shown in the left image.', 'B': 'Option B is incorrect because the relative positions of three faces match the cube shown in the left image.', 'D': 'Option D is incorrect because the relative positions of three faces match the cube shown in the left image.', 'A': 'Option A is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                     | 49/118 [14:37<17:36, 15.31s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 49] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'In this connection, the orange object rotates in the opposite direction to the green object.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'In this connection, the orange object rotates in the opposite direction to the green object.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                    | 50/118 [14:52<17:21, 15.31s/it]

{'loss': 0.0087, 'grad_norm': 0.016046540811657906, 'learning_rate': 3.246287027504237e-06, 'epoch': 0.42}
(tensor([[[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -8.3125,  -2.3438,   1.4453,  ...,  -7.1250,  -5.0625,  -3.5469],
         [-10.9375,   2.4375,   4.0625,  ...,  -4.5938,  -2.0938,  -0.1138],
         [  5.3438,  11.0625,  10.6250,  ...,   4.0938,   8.5625,   5.6250]],

        [[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -8.5000,  -2.3281,   1.4844,  ...,  -7.1875,  -5.2500,  -3.3594],
         [-10.5000,   2.5781,   4.2812,  ...,  -4.4062,  -1.9375,   0.1475],
         [  5.3125,  10.8750,  10.5625,  ...,   4.1875,   8.3750,   5.7812]]],
       device='cuda:0'),)
 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                        | 2/15 [00:02<00:15,  1.20s/it]
(tensor([[[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -8.8125,  -2.6562,   1.3281,  ...,  -7.0312,  -4.9688,  -3.5625],
         [-10.8750,   2.2188,   4.1562,  ...,  -4.4062,  -1.7344,  -0.0728],
         [  5.0625,  10.5625,  10.5625,  ...,   4.0312,   8.5625,   5.4375]],

        [[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -7.5312,  -1.5625,   2.2188,  ...,  -6.3125,  -4.6562,  -2.7969],
         [ -9.3750,   3.9219,   5.6875,  ...,  -3.3281,  -0.8242,   1.1484],
         [  4.8125,  11.3125,  10.9375,  ...,   4.5312,   8.6250,   5.9688]]],
       device='cuda:0'),)
(tensor([[[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -7.3125,  -1.3594,   1.9141,  ...,  -6.3438,  -4.4688,  -2.8125],
         [-10.2500,   3.6875,   4.6875,  ...,  -3.5156,  -0.7656,   0.6133],
         [  4.5625,  10.6250,  10.4375,  ...,   4.4062,   8.4375,   5.3750]],

        [[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -8.6250,  -2.2500,   1.8047,  ...,  -6.6250,  -4.4375,  -3.2969],
         [-10.0625,   3.3125,   5.3438,  ...,  -3.8594,  -1.1016,   0.3516],
         [  5.0625,  11.1875,  11.0000,  ...,   4.0312,   8.3125,   5.9688]]],
       device='cuda:0'),)
(tensor([[[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -7.8438,  -1.6328,   1.9531,  ...,  -6.7188,  -4.6875,  -3.0469],
         [-10.0625,   3.6875,   5.1250,  ...,  -3.6875,  -0.9297,   0.4434],
         [  4.4375,  10.5000,  10.4375,  ...,   4.3125,   8.0625,   5.4375]],

        [[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -7.3438,  -1.2422,   1.9844,  ...,  -6.2812,  -4.4688,  -2.7812],
         [-10.1875,   3.8438,   4.7500,  ...,  -3.4531,  -0.6992,   0.6914],
         [  4.9375,  10.6875,  10.5000,  ...,   4.4688,   8.5625,   5.3750]]],
       device='cuda:0'),)
(tensor([[[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -7.7812,  -1.9141,   1.5156,  ...,  -6.3750,  -4.3750,  -2.7031],
         [-10.6250,   2.7969,   4.6250,  ...,  -4.0625,  -1.4297,   0.6602],
         [  5.1250,  11.3125,  10.8750,  ...,   4.6875,   9.0000,   6.1562]],

        [[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -8.4375,  -2.2656,   1.1562,  ...,  -7.0312,  -5.0312,  -3.2969],
         [-10.0000,   3.3906,   4.9062,  ...,  -3.7656,  -1.0625,   0.4160],
         [  4.5938,  10.8125,  10.3125,  ...,   4.2812,   8.5000,   5.4062]]],
       device='cuda:0'),)
(tensor([[[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -8.2500,  -2.4219,   1.7422,  ...,  -6.8750,  -4.8438,  -3.1406],
         [-10.0000,   2.6875,   5.2188,  ...,  -3.9688,  -1.3047,   0.3691],
         [  5.5000,  11.0000,  11.0000,  ...,   4.3750,   8.6875,   6.0000]],

        [[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -8.5000,  -2.2188,   1.7266,  ...,  -6.7812,  -4.8438,  -3.4219],
         [-10.2500,   3.5469,   5.5000,  ...,  -3.6562,  -1.2969,   0.3496],
         [  5.0625,  11.2500,  10.7500,  ...,   3.8438,   8.2500,   6.0312]]],
       device='cuda:0'),)
(tensor([[[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -7.9062,  -2.2188,   1.5078,  ...,  -6.4688,  -4.3750,  -2.9844],
         [-11.0625,   2.5469,   3.9375,  ...,  -4.1250,  -1.4219,   0.5000],
         [  5.1562,  11.3125,  10.7500,  ...,   4.6875,   9.0625,   6.2188]],

        [[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -8.5625,  -2.1875,   0.9219,  ...,  -7.1562,  -5.0938,  -3.1875],
         [-11.1250,   2.5781,   3.4531,  ...,  -4.6250,  -2.0938,  -0.0479],
         [  5.0312,  10.6250,  10.2500,  ...,   3.9062,   8.0625,   5.6562]]],
       device='cuda:0'),)
(tensor([[[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -8.6250,  -2.3750,   1.2031,  ...,  -7.1562,  -5.1875,  -3.1875],
         [-11.2500,   2.6250,   3.8125,  ...,  -4.4375,  -2.0156,  -0.1387],
         [  4.6875,  10.8125,  10.3750,  ...,   4.0625,   8.0625,   5.7812]],

        [[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -8.8125,  -2.2812,   1.4922,  ...,  -7.2500,  -5.0312,  -3.7500],
         [-10.2500,   3.8594,   4.4688,  ...,  -3.7500,  -1.2578,   0.0278],
         [  5.1562,  11.3125,  11.1250,  ...,   4.4375,   8.5000,   5.5000]]],
       device='cuda:0'),)
(tensor([[[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -7.9062,  -2.3906,   1.2031,  ...,  -6.9375,  -5.0938,  -3.4219],
         [-10.6250,   3.0312,   4.4688,  ...,  -3.7656,  -1.2812,   0.5234],
         [  5.1250,  10.6250,  10.5000,  ...,   4.2188,   8.4375,   5.6562]],

        [[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -8.1250,  -1.7969,   1.7969,  ...,  -6.6250,  -4.6875,  -2.8438],
         [-10.5625,   2.9688,   5.1562,  ...,  -3.7812,  -1.0703,   0.5898],
         [  4.8438,  10.8125,  10.5625,  ...,   4.1250,   8.2500,   5.8438]]],
       device='cuda:0'),)
(tensor([[[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -8.4375,  -2.0625,   1.5938,  ...,  -6.6875,  -4.9375,  -3.1562],
         [ -9.9375,   3.0156,   5.1562,  ...,  -3.7656,  -1.0000,   0.5664],
         [  4.8125,  10.5625,  10.4375,  ...,   4.2188,   8.3125,   5.7812]],

        [[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -7.4375,  -1.9688,   1.8125,  ...,  -6.6562,  -4.5625,  -3.0156],
         [ -9.8750,   3.1406,   5.0938,  ...,  -3.9219,  -1.3594,   0.5234],
         [  4.8750,  11.3750,  10.7500,  ...,   4.5625,   8.8125,   5.9062]]],
       device='cuda:0'),)
(tensor([[[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -8.0625,  -2.0312,   1.9375,  ...,  -6.5938,  -4.6875,  -2.9531],
         [-10.2500,   2.7500,   5.0625,  ...,  -3.8438,  -1.4219,   0.3750],
         [  5.2812,  10.9375,  10.6875,  ...,   4.4688,   8.6875,   6.0938]],

        [[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -8.1875,  -2.1875,   1.1953,  ...,  -6.6875,  -4.6562,  -3.0938],
         [-10.3125,   3.5469,   5.0938,  ...,  -3.4844,  -0.6758,   0.7344],
         [  4.9062,  11.0625,  10.5625,  ...,   4.4062,   8.8750,   5.7500]]],
       device='cuda:0'),)
(tensor([[[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -8.5625,  -2.3594,   1.7422,  ...,  -6.6875,  -4.9062,  -3.2500],
         [ -9.6250,   3.7656,   5.4062,  ...,  -3.2656,  -0.6953,   0.9453],
         [  4.7500,  11.1875,  10.8125,  ...,   4.5938,   8.8750,   5.7188]],

        [[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -8.0625,  -2.0312,   1.1094,  ...,  -6.6875,  -4.7500,  -2.9531],
         [-10.2500,   3.6406,   5.1875,  ...,  -3.5312,  -0.9180,   0.8008],
         [  5.0625,  11.0000,  10.6875,  ...,   4.3125,   8.5625,   5.6875]]],
       device='cuda:0'),)
(tensor([[[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -8.4375,  -2.2031,   1.1250,  ...,  -7.0312,  -5.0625,  -3.2031],
         [ -9.8750,   3.5938,   5.0625,  ...,  -3.6406,  -0.9492,   0.5742],
         [  4.6875,  10.8125,  10.4375,  ...,   4.2500,   8.5000,   5.4375]],

        [[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -8.1875,  -1.7656,   1.4453,  ...,  -6.5312,  -4.2812,  -3.2500],
         [ -9.8125,   4.3750,   5.6562,  ...,  -2.9688,  -0.5234,   0.6602],
         [  5.2188,  11.3750,  11.0625,  ...,   4.7500,   8.8125,   5.6562]]],
       device='cuda:0'),)
(tensor([[[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -7.8438,  -1.4922,   1.7812,  ...,  -6.5000,  -4.6875,  -2.7656],
         [-10.0000,   3.0938,   5.1875,  ...,  -3.7812,  -1.1094,   0.6875],
         [  4.8750,  10.6875,  10.5625,  ...,   4.1250,   8.1875,   5.7812]],

        [[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -7.7188,  -2.4219,   1.1875,  ...,  -6.8750,  -5.0312,  -3.3594],
         [-11.4375,   2.6875,   4.0312,  ...,  -4.0312,  -1.5625,   0.3828],
         [  5.0000,  10.7500,  10.5625,  ...,   4.1875,   8.3750,   5.7500]]],
       device='cuda:0'),)
(tensor([[[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -8.5000,  -2.5156,   1.8438,  ...,  -6.8750,  -4.7812,  -3.3594],
         [-10.1250,   3.2344,   5.3438,  ...,  -3.9062,  -1.2422,   0.4609],
         [  4.9688,  11.2500,  10.7500,  ...,   4.0312,   8.1875,   6.0000]],

        [[-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         [-10.3125,  -6.5938,  -1.8125,  ..., -10.0625,  -5.1250,  -2.4062],
         ...,
         [ -7.8125,  -1.5312,   1.5078,  ...,  -6.4062,  -4.4062,  -3.0156],
         [-10.1875,   4.1250,   4.8438,  ...,  -3.2344,  -0.4043,   0.9570],
         [  5.1250,  10.8750,  10.7500,  ...,   4.5625,   8.8125,   5.5312]]],
       device='cuda:0'),)
{'eval_loss': 0.0009178235777653754, 'eval_runtime': 34.994, 'eval_samples_per_second': 6.744, 'eval_steps_per_second': 0.429, 'epoch': 0.42}
2025-09-29 22:41:32,498 - INFO - vq_config is None. initializing the ChameleonVQConfig with default values.

======================================== [DEBUGGING AT GLOBAL STEP: 50] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option B is correct because it shows the front-bottom-left view.', 'D': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option D is incorrect because it includes rotated non-symmetric faces.', 'A': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option A is incorrect because it includes rotated non-symmetric faces.', 'C': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option C is incorrect because it is a horizontally mirrored version of the front-bottom-right view.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option B is correct because it shows the front-bottom-left view.', 'D': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option D is incorrect because it includes rotated non-symmetric faces.', 'A': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option A is incorrect because it includes rotated non-symmetric faces.', 'C': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option C is incorrect because it is a horizontally mirrored version of the front-bottom-right view.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                   | 51/118 [16:28<44:07, 39.51s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 51] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'The yellow gear directly meshes with the green gear and therefore rotates in the opposite direction. The pink gear, driven through two meshing steps, rotates in the same direction as the green gear.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'The yellow gear directly meshes with the green gear and therefore rotates in the opposite direction. Thepink gear, driven through two meshing steps, rotates in the same direction as the green gear.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                  | 52/118 [16:43<35:21, 32.15s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 52] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is correct because the initial state can be transformed into the final state.', 'ABC': 'Option ABC is incorrect because the initial state cannot be transformed into the final state.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is correct because the initial state can be transformed into the final state.', 'ABC': 'Option ABC is incorrect because the initial state cannot be transformed into the final state.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                 | 53/118 [16:58<29:12, 26.96s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 53] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'In the current state, the orange object pushes the blue object to the left, causing it to rotate counterclockwise.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'In the current state, the orange object pushes the blue object to the left, causing it to rotate counterclockwise.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                | 54/118 [17:13<24:43, 23.19s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 54] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is incorrect because holes in column 2 are missing.', 'D': 'Option D is incorrect because extra holes appear in column 3.', 'A': 'Option A is incorrect because holes that should appear in column 2 appear in column 3.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is incorrect because holes in column 2 are missing.', 'D': 'Option D is incorrect because extra holes appear in column 3.', 'A': 'Option A is incorrect because holes that should appear in column 2 appear in column 3.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                               | 55/118 [17:27<21:40, 20.64s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 55] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given three views, at least 16 cubes and at most 21 cubes are required to satisfy the constraints.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given three views, at least 16 cubes and at most 21 cubes are required to satisfy the constraints.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                              | 56/118 [17:42<19:26, 18.82s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 56] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'B': 'Option B is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'B': 'Option B is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                             | 57/118 [17:57<17:58, 17.68s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 57] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'D': 'Option D is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'D': 'Option D is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                            | 58/118 [18:12<16:52, 16.87s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 58] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is correct because it was obtained by removing one small cube from the original stack.', 'C': 'Option C is incorrect because the cube stack can be obtained by rotating the original stack around the y-axis by 180 degrees.', 'B': 'Option B is incorrect because the cube stack can be obtained by rotating the original stack around the z-axis by 90 degrees.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is correct because it was obtained by removing one small cube from the original stack.', 'C': 'Option C is incorrect because the cube stack can be obtained by rotating the original stack around the y-axis by 180 degrees.', 'B': 'Option B is incorrect because the cube stack can be obtained by rotating the original stack around the z-axis by 90 degrees.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                           | 59/118 [18:26<15:54, 16.18s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 59] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given three views, at least 9 cubes and at most 9 cubes are required to satisfy the constraints.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given three views, at least 9 cubes and at most 9 cubes are required to satisfy the constraints.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                          | 60/118 [18:41<15:15, 15.78s/it]

{'loss': 0.0029, 'grad_norm': 0.19301530718803406, 'learning_rate': 2.5688858559204056e-06, 'epoch': 0.51}
(tensor([[[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [-10.5625,  -4.6562,  -0.4512,  ...,  -7.7812,  -6.8750,  -4.2188],
         [-12.8125,  -1.1875,   0.9531,  ...,  -6.0000,  -4.9688,  -1.4453],
         [  4.3750,   9.7500,   8.8750,  ...,   4.3125,   7.7500,   5.6562]],

        [[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [-10.5000,  -4.2188,  -0.2314,  ...,  -7.6250,  -6.9062,  -3.8438],
         [-12.5000,  -1.0938,   1.1797,  ...,  -5.6875,  -4.9062,  -1.1797],
         [  4.5938,   9.6250,   9.1250,  ...,   4.6250,   7.6250,   5.9375]]],
       device='cuda:0'),)
 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                        | 2/15 [00:02<00:15,  1.21s/it]
(tensor([[[-1.0375e+01, -6.7500e+00, -1.8594e+00,  ..., -1.0000e+01,
          -5.2500e+00, -2.5000e+00],
         [-1.0375e+01, -6.7500e+00, -1.8594e+00,  ..., -1.0000e+01,
          -5.2500e+00, -2.5000e+00],
         [-1.0375e+01, -6.7500e+00, -1.8594e+00,  ..., -1.0000e+01,
          -5.2500e+00, -2.5000e+00],
         ...,
         [-1.1125e+01, -4.9688e+00, -7.3828e-01,  ..., -7.8750e+00,
          -6.9062e+00, -4.2500e+00],
         [-1.2938e+01, -1.1328e+00,  1.0078e+00,  ..., -5.7812e+00,
          -4.5312e+00, -1.2891e+00],
         [ 4.0938e+00,  9.5000e+00,  8.9375e+00,  ...,  4.5000e+00,
           7.8750e+00,  5.5938e+00]],

        [[-1.0375e+01, -6.7500e+00, -1.8594e+00,  ..., -1.0000e+01,
          -5.2500e+00, -2.5000e+00],
         [-1.0375e+01, -6.7500e+00, -1.8594e+00,  ..., -1.0000e+01,
          -5.2500e+00, -2.5000e+00],
         [-1.0375e+01, -6.7500e+00, -1.8594e+00,  ..., -1.0000e+01,
          -5.2500e+00, -2.5000e+00],
         ...,
         [-1.0188e+01, -3.9062e+00,  1.0300e-03,  ..., -7.0625e+00,
          -6.2188e+00, -3.3750e+00],
         [-1.2250e+01, -4.9023e-01,  1.5547e+00,  ..., -5.4375e+00,
          -4.1875e+00, -5.4688e-01],
         [ 4.1875e+00,  1.0062e+01,  9.2500e+00,  ...,  5.0000e+00,
           7.8438e+00,  5.8750e+00]]], device='cuda:0'),)
(tensor([[[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [ -9.7500,  -3.7188,   0.0762,  ...,  -7.1250,  -6.4062,  -3.5625],
         [-12.5625,  -0.2520,   1.7344,  ...,  -5.0938,  -3.9219,  -0.8828],
         [  4.0312,   9.5000,   9.1250,  ...,   4.9062,   7.6875,   5.4688]],

        [[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [-11.0000,  -4.6250,  -0.3965,  ...,  -7.4688,  -6.4062,  -4.0938],
         [-11.8750,  -0.0203,   2.2344,  ...,  -5.1875,  -3.6562,  -0.7930],
         [  4.4375,   9.9375,   9.3125,  ...,   4.5000,   7.5000,   6.0000]]],
       device='cuda:0'),)
(tensor([[[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [-10.5000,  -4.2188,  -0.0566,  ...,  -7.5000,  -6.6562,  -3.8594],
         [-12.4375,   0.1553,   2.3750,  ...,  -4.9062,  -3.7969,  -0.8047],
         [  3.7812,   9.4375,   9.0625,  ...,   4.7188,   7.2500,   5.4375]],

        [[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [ -9.6250,  -3.5938,   0.1055,  ...,  -7.1250,  -6.4062,  -3.5000],
         [-12.5625,  -0.0625,   1.8594,  ...,  -5.0000,  -3.7812,  -0.7969],
         [  4.2188,   9.5000,   9.0625,  ...,   4.8750,   7.7812,   5.4062]]],
       device='cuda:0'),)
(tensor([[[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [-10.0000,  -4.1875,  -0.3730,  ...,  -7.1562,  -6.1562,  -3.3750],
         [-12.4375,  -0.8984,   1.3594,  ...,  -5.6250,  -4.3750,  -0.7422],
         [  4.3125,  10.1875,   9.3750,  ...,   5.1562,   8.1875,   6.2500]],

        [[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [-10.5000,  -4.4062,  -0.6250,  ...,  -7.7812,  -6.8438,  -3.9219],
         [-12.3750,  -0.5352,   1.6172,  ...,  -5.4688,  -4.2188,  -1.0156],
         [  4.0312,  10.0625,   9.1250,  ...,   4.8438,   7.8750,   5.6875]]],
       device='cuda:0'),)
(tensor([[[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [-10.8750,  -4.7188,  -0.3633,  ...,  -7.5000,  -6.7188,  -3.8594],
         [-12.1875,  -1.0312,   1.8672,  ...,  -5.3438,  -4.3438,  -0.8594],
         [  4.4375,   9.5625,   9.3125,  ...,   4.7500,   7.8438,   6.0625]],

        [[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [-10.6875,  -4.3438,  -0.4434,  ...,  -7.5312,  -6.5938,  -4.1562],
         [-11.9375,   0.1206,   2.2188,  ...,  -4.9688,  -3.7969,  -0.5508],
         [  4.4375,   9.9375,   9.0000,  ...,   4.3125,   7.4688,   6.0625]]],
       device='cuda:0'),)
(tensor([[[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [-10.0000,  -4.3438,  -0.2539,  ...,  -7.1562,  -6.1250,  -3.5156],
         [-12.9375,  -1.1328,   0.9570,  ...,  -5.5938,  -4.3438,  -0.8594],
         [  4.3438,  10.2500,   9.2500,  ...,   5.2500,   8.2500,   6.3125]],

        [[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [-10.5000,  -4.1562,  -0.4336,  ...,  -7.5312,  -6.6562,  -3.5781],
         [-12.7500,  -0.7188,   0.9297,  ...,  -5.6250,  -4.6875,  -0.9648],
         [  4.2500,   9.4375,   8.8750,  ...,   4.3438,   7.2812,   5.9062]]],
       device='cuda:0'),)
(tensor([[[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [-10.6250,  -4.4062,  -0.5781,  ...,  -7.5938,  -6.7188,  -3.6719],
         [-12.9375,  -0.6523,   1.0391,  ...,  -5.4375,  -4.5000,  -1.0078],
         [  3.9688,   9.5625,   8.8750,  ...,   4.5000,   7.2500,   5.9375]],

        [[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [-11.3750,  -5.0312,  -0.7734,  ...,  -7.9375,  -7.0625,  -4.5938],
         [-12.3750,  -0.3008,   1.1250,  ...,  -5.2188,  -4.3125,  -1.3672],
         [  4.1562,   9.6875,   9.1875,  ...,   4.6875,   7.5312,   5.3125]]],
       device='cuda:0'),)
(tensor([[[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [-10.3750,  -4.5312,  -0.7070,  ...,  -7.7188,  -6.9062,  -4.0938],
         [-12.6875,  -0.4121,   1.4375,  ...,  -5.2500,  -4.0938,  -0.7227],
         [  4.2812,   9.7500,   9.1250,  ...,   4.9688,   7.8750,   6.0625]],

        [[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [-10.5625,  -4.0938,  -0.1621,  ...,  -7.3438,  -6.6562,  -3.5000],
         [-12.8750,  -0.8828,   1.7500,  ...,  -5.3125,  -4.2500,  -0.7812],
         [  4.1875,   9.8750,   9.2500,  ...,   4.8125,   7.6250,   6.2500]]],
       device='cuda:0'),)
(tensor([[[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [-10.7500,  -4.2188,  -0.2471,  ...,  -7.4688,  -6.7188,  -3.7812],
         [-12.2500,  -0.6719,   1.8672,  ...,  -5.2500,  -4.0625,  -0.8281],
         [  3.9688,   9.5625,   9.0000,  ...,   4.7500,   7.5938,   6.0312]],

        [[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [ -9.6250,  -4.2500,   0.0513,  ...,  -7.3438,  -6.4062,  -3.6250],
         [-12.3125,  -0.7188,   1.7578,  ...,  -5.5625,  -4.4375,  -0.9570],
         [  4.1250,  10.3125,   9.2500,  ...,   5.0312,   8.0000,   6.0000]]],
       device='cuda:0'),)
(tensor([[[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [-10.5625,  -4.1875,  -0.0967,  ...,  -7.1562,  -6.4062,  -3.5938],
         [-12.1250,  -0.6562,   1.7344,  ...,  -5.1562,  -4.2188,  -0.7812],
         [  4.2188,   9.6250,   9.1250,  ...,   4.9375,   7.9688,   6.2188]],

        [[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [-10.2500,  -4.2500,  -0.5156,  ...,  -7.3438,  -6.4375,  -3.7344],
         [-12.6875,  -0.4355,   1.7266,  ...,  -5.1875,  -3.9062,  -0.7773],
         [  4.1875,  10.1250,   9.3125,  ...,   4.8438,   8.1875,   5.9062]]],
       device='cuda:0'),)
(tensor([[[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [-10.7500,  -4.3438,  -0.2832,  ...,  -7.2812,  -6.3438,  -3.7969],
         [-12.1875,  -0.3477,   1.4766,  ...,  -5.0938,  -3.9844,  -0.7422],
         [  4.2812,  10.0000,   9.1875,  ...,   5.1250,   8.1250,   5.7188]],

        [[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [ -9.9375,  -4.0938,  -0.5586,  ...,  -7.4062,  -6.5000,  -3.6250],
         [-12.1250,  -0.1865,   2.0312,  ...,  -5.1875,  -4.0000,  -0.4316],
         [  4.3125,  10.1875,   9.4375,  ...,   4.8125,   7.9375,   5.8438]]],
       device='cuda:0'),)
(tensor([[[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [-10.3125,  -4.3125,  -0.5547,  ...,  -7.7500,  -6.8438,  -3.8125],
         [-12.1250,  -0.3086,   1.8438,  ...,  -5.3438,  -4.0625,  -0.8984],
         [  4.0000,  10.0000,   9.1875,  ...,   4.7500,   7.8750,   5.6875]],

        [[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [-10.6875,  -4.5625,  -0.6484,  ...,  -7.3125,  -6.4062,  -3.9844],
         [-12.0000,  -0.0505,   1.9062,  ...,  -4.7188,  -3.7500,  -0.9766],
         [  4.4375,   9.7500,   9.1250,  ...,   5.0000,   7.8438,   5.5625]]],
       device='cuda:0'),)
(tensor([[[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [ -9.9375,  -3.6562,  -0.0170,  ...,  -7.0938,  -6.3438,  -3.2500],
         [-12.1250,  -0.5547,   1.9219,  ...,  -5.2188,  -4.0625,  -0.4395],
         [  4.1250,   9.5625,   9.1250,  ...,   4.7188,   7.4375,   6.1250]],

        [[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [ -9.8125,  -4.1875,  -0.4375,  ...,  -7.3125,  -6.4375,  -3.6094],
         [-13.3750,  -0.6445,   1.2500,  ...,  -5.4062,  -4.2812,  -0.8164],
         [  4.1875,   9.8125,   9.1875,  ...,   4.9062,   7.6875,   6.1562]]],
       device='cuda:0'),)
(tensor([[[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [-10.7500,  -4.4375,  -0.2891,  ...,  -7.4688,  -6.4062,  -3.8906],
         [-11.6875,   0.0339,   2.0781,  ...,  -5.1562,  -3.7500,  -0.4531],
         [  4.0625,   9.8125,   9.0000,  ...,   4.3750,   7.2812,   5.9062]],

        [[-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         [-10.3750,  -6.7500,  -1.8594,  ..., -10.0000,  -5.2500,  -2.5000],
         ...,
         [-10.1875,  -3.9375,  -0.3770,  ...,  -7.2812,  -6.3438,  -3.8281],
         [-12.2500,   0.3848,   1.9453,  ...,  -4.7500,  -3.3125,  -0.4062],
         [  4.3438,   9.5625,   9.3125,  ...,   4.8125,   8.0000,   5.5000]]],
       device='cuda:0'),)
{'eval_loss': 0.001391563331708312, 'eval_runtime': 35.1217, 'eval_samples_per_second': 6.719, 'eval_steps_per_second': 0.427, 'epoch': 0.51}

======================================== [DEBUGGING AT GLOBAL STEP: 60] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'D': 'Option D is incorrect because it is the cross-section made by a plane perpendicular to the YZ plane and rotated 45 degrees around the x-axis.', 'B': 'Option B is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'D': 'Option D is incorrect because it is the cross-section made by a plane perpendicular to the YZ plane and rotated 45 degrees around the x-axis.', 'B': 'Option B is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                         | 61/118 [19:32<24:55, 26.23s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 61] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because it was obtained by rotating the original image 180 degrees.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 90 degrees and then flipping it horizontally.', 'B': 'Option B is incorrect because it was obtained by rotating the asymmetric patterns in the image.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is correct because it was obtained by rotating the original image 180 degrees.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 90 degrees and then flipping it horizontally.', 'B': 'Option B is incorrect because it was obtained by rotating the asymmetric patterns in the image.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                        | 62/118 [19:47<21:18, 22.83s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 62] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is correct because the squares with asymmetric patterns have been rotated, so it cannot form the cube shown in the left image.', 'C': 'Option C is incorrect because the relative positions of three faces match the cube shown in the left image.', 'D': 'Option D is incorrect because the relative positions of three faces match the cube shown in the left image.', 'A': 'Option A is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is correct because the squares with asymmetric patterns have been rotated, so it cannot form the cube shown in the left image.', 'C': 'Option C is incorrect because the relative positions of three faces match the cube shown in the left image.', 'D': 'Option D is incorrect because the relative positions of three faces match the cube shown in the left image.', 'A': 'Option A is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                       | 63/118 [20:01<18:39, 20.35s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 63] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because one cube is missing, resulting in an incorrect cube stack shape.', 'B': 'Option B is incorrect because one cube is missing, resulting in an incorrect cube stack shape.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is incorrect because one cube is missing, resulting in an incorrect cube stack shape.', 'B': 'Option B is incorrect because one cube is missing, resulting in an incorrect cube stack shape.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                      | 64/118 [20:16<16:46, 18.64s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 64] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is correct because the initial state can be transformed into the final state.', 'ACD': 'Option ACD is incorrect because the initial state cannot be transformed into the final state.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is correct because the initial state can be transformed into the final state.', 'ACD': 'Option ACD is incorrect because the initial state cannot be transformed into the final state.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                     | 65/118 [20:31<15:25, 17.47s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 65] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is correct because two faces have swapped positions, so it cannot form the cube shown in the left image.„ÄÇ', 'D': 'Option D is incorrect because the relative positions of three faces match the cube shown in the left image.', 'C': 'Option C is incorrect because the relative positions of three faces match the cube shown in the left image.', 'B': 'Option B is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is correct because two faces have swapped positions, so it cannot form the cube shown in the left image.„ÄÇ', 'D': 'Option D is incorrect because the relative positions of three faces match the cube shown in the left image.', 'C': 'Option C is incorrect because the relative positions of three faces match the cube shown in the left image.', 'B': 'Option B is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                    | 66/118 [20:46<14:29, 16.72s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 66] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'B': 'Option B is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'B': 'Option B is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                   | 67/118 [21:01<13:44, 16.17s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 67] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because it was obtained by rotating the original image 180 degrees.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it vertically.', 'B': 'Option B is incorrect because it was obtained by rotating the asymmetric patterns in the image.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is correct because it was obtained by rotating the original image 180 degrees.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it vertically.', 'B': 'Option B is incorrect because it was obtained by rotating the asymmetric patterns in the image.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                  | 68/118 [21:15<13:02, 15.65s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 68] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because the internal outlines are missing.', 'B': 'Option B is incorrect because the internal outlines are missing.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is incorrect because the internal outlines are missing.', 'B': 'Option B is incorrect because the internal outlines are missing.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                 | 69/118 [21:30<12:35, 15.41s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 69] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is correct because the squares with asymmetric patterns have been rotated, so it cannot form the cube shown in the left image.', 'A': 'Option A is incorrect because the relative positions of three faces match the cube shown in the left image.', 'C': 'Option C is incorrect because the relative positions of three faces match the cube shown in the left image.', 'D': 'Option D is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is correct because the squares with asymmetric patterns have been rotated, so it cannot form the cube shown in the left image.', 'A': 'Option A is incorrect because the relative positions of three faces match the cube shown in the left image.', 'C': 'Option C is incorrect because the relative positions of three faces match the cube shown in the left image.', 'D': 'Option D is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                | 70/118 [21:45<12:15, 15.32s/it]

{'loss': 0.0055, 'grad_norm': 0.026479627937078476, 'learning_rate': 1.8862862821480023e-06, 'epoch': 0.59}
(tensor([[[-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         ...,
         [-8.6250, -1.4141,  1.3516,  ..., -6.2188, -4.8438, -2.5312],
         [-9.4375,  3.3594,  4.0000,  ..., -2.9062, -2.0156,  0.9766],
         [ 5.9062, 12.2500, 11.3125,  ...,  5.1875,  8.4375,  6.3125]],

        [[-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         ...,
         [-8.5625, -1.1562,  1.4609,  ..., -6.1562, -4.8438, -2.2812],
         [-9.5000,  3.2344,  3.9062,  ..., -2.8438, -2.0781,  1.0625],
         [ 5.9688, 12.0625, 11.5000,  ...,  5.4062,  8.2500,  6.5625]]],
       device='cuda:0'),)
 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                        | 2/15 [00:02<00:15,  1.19s/it]
(tensor([[[ -9.5625,  -6.0625,  -1.3750,  ...,  -9.6250,  -4.5938,  -2.1875],
         [ -9.5625,  -6.0625,  -1.3750,  ...,  -9.6250,  -4.5938,  -2.1875],
         [ -9.5625,  -6.0625,  -1.3750,  ...,  -9.6250,  -4.5938,  -2.1875],
         ...,
         [ -9.4375,  -1.9766,   0.8984,  ...,  -6.4375,  -5.0625,  -2.7812],
         [ -9.8125,   3.0312,   3.7969,  ...,  -2.9062,  -1.9297,   0.9414],
         [  5.5938,  12.0000,  11.3125,  ...,   5.3750,   8.6250,   6.3125]],

        [[ -9.5625,  -6.0625,  -1.3750,  ...,  -9.6250,  -4.5938,  -2.1875],
         [ -9.5625,  -6.0625,  -1.3750,  ...,  -9.6250,  -4.5938,  -2.1875],
         [ -9.5625,  -6.0625,  -1.3750,  ...,  -9.6250,  -4.5938,  -2.1875],
         ...,
         [ -8.5625,  -0.9570,   1.3281,  ...,  -5.7188,  -4.4062,  -1.9766],
         [-10.0000,   3.4219,   3.4844,  ...,  -3.0156,  -1.9609,   1.3047],
         [  5.5312,  12.5625,  11.4375,  ...,   5.8125,   8.4375,   6.5312]]],
       device='cuda:0'),)
(tensor([[[-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         ...,
         [-7.5625, -0.5742,  1.8906,  ..., -5.6562, -4.4062, -1.9297],
         [-9.6875,  3.7500,  4.0312,  ..., -2.5469, -1.4453,  1.2969],
         [ 5.4062, 12.0000, 11.5000,  ...,  5.6875,  8.3125,  6.2188]],

        [[-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         ...,
         [-9.0000, -1.4844,  1.3594,  ..., -5.9688, -4.4062, -2.5781],
         [-8.9375,  4.1875,  4.6875,  ..., -2.4062, -1.1094,  1.3125],
         [ 5.8125, 12.1250, 11.4375,  ...,  5.1875,  8.0000,  6.4375]]],
       device='cuda:0'),)
(tensor([[[-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         ...,
         [-8.3125, -1.0234,  1.7266,  ..., -5.9688, -4.6250, -2.2500],
         [-9.6875,  4.2188,  4.4062,  ..., -2.2344, -1.2734,  1.3438],
         [ 5.1875, 11.8750, 11.3750,  ...,  5.5312,  7.8750,  6.1875]],

        [[-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         ...,
         [-7.6250, -0.5547,  1.8594,  ..., -5.6250, -4.4062, -1.9219],
         [-9.6875,  3.7969,  4.0312,  ..., -2.5938, -1.3750,  1.2734],
         [ 5.5000, 11.9375, 11.3750,  ...,  5.5938,  8.3750,  6.0938]]],
       device='cuda:0'),)
(tensor([[[-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         ...,
         [-8.1875, -1.1406,  1.3047,  ..., -5.8125, -4.4062, -1.9531],
         [-9.7500,  3.1719,  3.7031,  ..., -3.0625, -2.0312,  1.3828],
         [ 5.6562, 12.6875, 11.6250,  ...,  5.9375,  8.6875,  6.9375]],

        [[-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         ...,
         [-8.8750, -1.4922,  0.9531,  ..., -6.4062, -4.9688, -2.5156],
         [-9.5000,  3.5312,  3.9688,  ..., -2.8594, -1.7344,  0.9375],
         [ 5.3438, 12.3125, 11.3750,  ...,  5.5312,  8.5000,  6.3438]]],
       device='cuda:0'),)
(tensor([[[-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         ...,
         [-9.0000, -1.6562,  1.2500,  ..., -6.1875, -4.8750, -2.4688],
         [-9.3750,  3.2656,  4.3750,  ..., -2.5781, -1.7031,  1.2578],
         [ 5.7812, 12.0625, 11.6875,  ...,  5.5312,  8.4375,  6.6250]],

        [[-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         ...,
         [-8.7500, -1.0547,  1.4219,  ..., -5.9062, -4.5625, -2.5156],
         [-8.5000,  4.8750,  5.1562,  ..., -1.8516, -0.9883,  1.7500],
         [ 5.6250, 12.0000, 11.1875,  ...,  4.9062,  7.7500,  6.4062]]],
       device='cuda:0'),)
(tensor([[[ -9.5625,  -6.0625,  -1.3750,  ...,  -9.6250,  -4.5938,  -2.1875],
         [ -9.5625,  -6.0625,  -1.3750,  ...,  -9.6250,  -4.5938,  -2.1875],
         [ -9.5625,  -6.0625,  -1.3750,  ...,  -9.6250,  -4.5938,  -2.1875],
         ...,
         [ -8.1250,  -1.4062,   1.3984,  ...,  -5.8125,  -4.1875,  -2.0625],
         [-10.3750,   2.9531,   3.2969,  ...,  -3.1562,  -1.9844,   1.1172],
         [  5.5625,  12.5625,  11.5000,  ...,   5.8438,   8.7500,   6.8750]],

        [[ -9.5625,  -6.0625,  -1.3750,  ...,  -9.6250,  -4.5938,  -2.1875],
         [ -9.5625,  -6.0625,  -1.3750,  ...,  -9.6250,  -4.5938,  -2.1875],
         [ -9.5625,  -6.0625,  -1.3750,  ...,  -9.6250,  -4.5938,  -2.1875],
         ...,
         [ -8.7500,  -1.2500,   1.1797,  ...,  -6.1875,  -4.8125,  -2.2344],
         [ -9.5625,   3.5625,   3.7031,  ...,  -2.7188,  -1.8750,   1.2578],
         [  5.6562,  11.8750,  11.1250,  ...,   5.1250,   7.9375,   6.5000]]],
       device='cuda:0'),)
(tensor([[[-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         ...,
         [-8.8750, -1.2344,  1.1562,  ..., -6.0938, -4.8125, -2.2031],
         [-9.8750,  3.4688,  3.7188,  ..., -2.7344, -1.8750,  1.1406],
         [ 5.5625, 11.9375, 11.1875,  ...,  5.2812,  7.9375,  6.4688]],

        [[-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         ...,
         [-9.3125, -1.8984,  0.9766,  ..., -6.5312, -5.1562, -3.0312],
         [-9.3125,  4.0938,  3.7812,  ..., -2.3438, -1.5938,  0.9844],
         [ 5.5625, 11.8750, 11.3125,  ...,  5.3750,  8.1250,  6.0000]]],
       device='cuda:0'),)
(tensor([[[-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         ...,
         [-8.4375, -1.5234,  1.0234,  ..., -6.2812, -4.9688, -2.5625],
         [-9.7500,  3.8125,  4.0625,  ..., -2.4531, -1.5000,  1.3984],
         [ 5.6562, 12.1875, 11.5625,  ...,  5.7188,  8.4375,  6.7500]],

        [[-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         ...,
         [-8.3125, -0.7109,  1.8359,  ..., -5.7500, -4.3750, -1.8359],
         [-9.8750,  3.5781,  4.4688,  ..., -2.3750, -1.3359,  1.4609],
         [ 5.5938, 12.3125, 11.7500,  ...,  5.6250,  8.2500,  6.9375]]],
       device='cuda:0'),)
(tensor([[[-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         ...,
         [-8.6250, -1.2578,  1.4609,  ..., -6.0312, -4.7812, -2.3438],
         [-9.1250,  3.6875,  4.5000,  ..., -2.2969, -1.3125,  1.4453],
         [ 5.6562, 12.0000, 11.5000,  ...,  5.6250,  8.2500,  6.7188]],

        [[-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         ...,
         [-7.8438, -1.1875,  1.6094,  ..., -6.0312, -4.5625, -2.1875],
         [-9.4375,  3.4531,  4.0625,  ..., -2.9844, -1.8047,  1.1328],
         [ 5.5625, 12.6875, 11.5625,  ...,  5.7812,  8.5000,  6.6562]]],
       device='cuda:0'),)
(tensor([[[ -9.5625,  -6.0625,  -1.3750,  ...,  -9.6250,  -4.5938,  -2.1875],
         [ -9.5625,  -6.0625,  -1.3750,  ...,  -9.6250,  -4.5938,  -2.1875],
         [ -9.5625,  -6.0625,  -1.3750,  ...,  -9.6250,  -4.5938,  -2.1875],
         ...,
         [ -8.6875,  -1.1484,   1.5156,  ...,  -5.7812,  -4.5312,  -2.1406],
         [ -9.4375,   3.3906,   4.1875,  ...,  -2.4844,  -1.7109,   1.2344],
         [  5.6875,  12.0625,  11.4375,  ...,   5.6875,   8.5625,   6.7812]],

        [[ -9.5625,  -6.0625,  -1.3750,  ...,  -9.6250,  -4.5938,  -2.1875],
         [ -9.5625,  -6.0625,  -1.3750,  ...,  -9.6250,  -4.5938,  -2.1875],
         [ -9.5625,  -6.0625,  -1.3750,  ...,  -9.6250,  -4.5938,  -2.1875],
         ...,
         [ -8.6250,  -1.5391,   0.9180,  ...,  -6.0938,  -4.6250,  -2.3594],
         [-10.0625,   3.5000,   3.9219,  ...,  -2.7656,  -1.5625,   1.1250],
         [  5.4688,  12.5000,  11.5000,  ...,   5.6250,   8.8750,   6.5938]]],
       device='cuda:0'),)
(tensor([[[-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         ...,
         [-9.0625, -1.5156,  1.0234,  ..., -5.9688, -4.6562, -2.4844],
         [-9.6875,  3.5625,  3.5938,  ..., -2.6719, -1.6094,  1.1797],
         [ 5.5312, 12.4375, 11.4375,  ...,  5.8750,  8.7500,  6.3438]],

        [[-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         ...,
         [-8.3750, -1.2578,  0.9570,  ..., -6.0938, -4.7188, -2.2031],
         [-9.6250,  3.6406,  4.2500,  ..., -2.7656, -1.6797,  1.2891],
         [ 5.6875, 12.5625, 11.6875,  ...,  5.5938,  8.5625,  6.5625]]],
       device='cuda:0'),)
(tensor([[[-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         ...,
         [-8.8750, -1.5391,  0.9648,  ..., -6.4688, -5.0938, -2.5000],
         [-9.5000,  3.4844,  4.0938,  ..., -2.8750, -1.7109,  0.9688],
         [ 5.4062, 12.1875, 11.4375,  ...,  5.4688,  8.4375,  6.3438]],

        [[-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         ...,
         [-8.5625, -1.3047,  1.2734,  ..., -5.7188, -4.3750, -2.3906],
         [-8.6875,  4.5625,  4.8125,  ..., -1.7500, -0.9023,  1.4688],
         [ 5.7500, 12.0625, 11.3750,  ...,  5.8438,  8.4375,  6.2188]]],
       device='cuda:0'),)
(tensor([[[ -9.5625,  -6.0625,  -1.3750,  ...,  -9.6250,  -4.5938,  -2.1875],
         [ -9.5625,  -6.0625,  -1.3750,  ...,  -9.6250,  -4.5938,  -2.1875],
         [ -9.5625,  -6.0625,  -1.3750,  ...,  -9.6250,  -4.5938,  -2.1875],
         ...,
         [ -7.9375,  -0.2578,   1.9219,  ...,  -5.4688,  -4.2812,  -1.5469],
         [ -9.1875,   3.7188,   4.6562,  ...,  -2.3594,  -1.4375,   1.7422],
         [  5.6875,  12.2500,  11.7500,  ...,   5.6250,   8.1875,   6.7812]],

        [[ -9.5625,  -6.0625,  -1.3750,  ...,  -9.6250,  -4.5938,  -2.1875],
         [ -9.5625,  -6.0625,  -1.3750,  ...,  -9.6250,  -4.5938,  -2.1875],
         [ -9.5625,  -6.0625,  -1.3750,  ...,  -9.6250,  -4.5938,  -2.1875],
         ...,
         [ -8.0625,  -1.3516,   1.1797,  ...,  -6.0625,  -4.7500,  -2.2812],
         [-10.5625,   3.3906,   3.7500,  ...,  -2.7969,  -1.7734,   1.1875],
         [  5.5938,  12.1875,  11.5625,  ...,   5.6562,   8.3125,   6.7812]]],
       device='cuda:0'),)
(tensor([[[-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         ...,
         [-8.8125, -1.1406,  1.5234,  ..., -5.8750, -4.3750, -2.2656],
         [-8.6875,  4.5312,  4.7500,  ..., -2.1250, -1.0625,  1.8203],
         [ 5.3125, 12.1250, 11.1875,  ...,  5.1250,  7.8125,  6.4375]],

        [[-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         [-9.5625, -6.0625, -1.3750,  ..., -9.6250, -4.5938, -2.1875],
         ...,
         [-8.1875, -0.9648,  1.3594,  ..., -5.8750, -4.4375, -2.3125],
         [-9.6875,  4.2188,  4.0625,  ..., -2.2969, -1.0547,  1.5859],
         [ 5.7812, 12.0000, 11.6250,  ...,  5.6562,  8.6250,  6.2812]]],
       device='cuda:0'),)
{'eval_loss': 0.0013167846482247114, 'eval_runtime': 35.1391, 'eval_samples_per_second': 6.716, 'eval_steps_per_second': 0.427, 'epoch': 0.59}

======================================== [DEBUGGING AT GLOBAL STEP: 70] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given two views, at least 6 cubes and at most 6 cubes are required to satisfy the constraints.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given two views, at least 6 cubes and at most 6 cubes are required to satisfy the constraints.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                               | 71/118 [22:36<20:17, 25.91s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 71] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is incorrect because it is the cross-section made by a plane perpendicular to the YZ plane and rotated 45 degrees around the x-axis.', 'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'A': 'Option A is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is incorrect because it is the cross-section made by a plane perpendicular to the YZ plane and rotated 45 degrees around the x-axis.', 'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'A': 'Option A is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                              | 72/118 [22:51<17:21, 22.64s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 72] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is correct because the initial state can be transformed into the final state.', 'BCD': 'Option BCD is incorrect because the initial state cannot be transformed into the final state.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is correct because the initial state can be transformed into the final state.', 'BCD': 'Option BCD is incorrect because the initial state cannot be transformed into the final state.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                             | 73/118 [23:05<15:10, 20.23s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 73] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'D': 'Option D is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'D': 'Option D is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                            | 74/118 [23:20<13:40, 18.64s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 74] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is correct because the squares with asymmetric patterns have been rotated, so it cannot form the cube shown in the left image.', 'B': 'Option B is incorrect because the relative positions of three faces match the cube shown in the left image.', 'A': 'Option A is incorrect because the relative positions of three faces match the cube shown in the left image.', 'C': 'Option C is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is correct because the squares with asymmetric patterns have been rotated, so it cannot form the cube shown in the left image.', 'B': 'Option B is incorrect because the relative positions of three faces match the cube shown in the left image.', 'A': 'Option A is incorrect because the relative positions of three faces match the cube shown in the left image.', 'C': 'Option C is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                           | 75/118 [23:35<12:31, 17.48s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 75] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is incorrect because the internal outlines are missing.', 'A': 'Option A is incorrect because the internal outlines are missing.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is incorrect because the internal outlines are missing.', 'A': 'Option A is incorrect because the internal outlines are missing.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                          | 76/118 [23:50<11:43, 16.75s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 76] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'B': 'Option B is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'B': 'Option B is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                         | 77/118 [24:05<11:00, 16.11s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 77] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given two views, at least 7 cubes and at most 9 cubes are required to satisfy the constraints.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given two views, at least 7 cubes and at most 9 cubes are required to satisfy the constraints.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                        | 78/118 [24:19<10:29, 15.74s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 78] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because it was obtained by rotating the original image 180 degrees.', 'B': 'Option B is incorrect because it was obtained by rotating the original image 270 degrees and then flipping it horizontally.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 90 degrees and then flipping it vertically.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is correct because it was obtained by rotating the original image 180 degrees.', 'B': 'Option B is incorrect because it was obtained by rotating the original image 270 degrees and then flipping it horizontally.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 90 degrees and then flipping it vertically.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                       | 79/118 [24:34<10:04, 15.49s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 79] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option A is correct because it shows the back-top-left view.', 'B': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option B is incorrect because it includes rotated non-symmetric faces.', 'C': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option C is incorrect because it includes rotated non-symmetric faces.', 'D': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option D is incorrect because it is a vertically mirrored version of the back-top-right view.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option A is correct because it shows the back-top-left view.', 'B': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option B is incorrect because it includes rotated non-symmetric faces.', 'C': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option C is incorrect because it includes rotated non-symmetric faces.', 'D': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option D is incorrect because it is a vertically mirrored version of the back-top-right view.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                      | 80/118 [24:49<09:41, 15.31s/it]

{'loss': 0.0001, 'grad_norm': 0.02775590494275093, 'learning_rate': 1.2500000000000007e-06, 'epoch': 0.68}
(tensor([[[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -9.5625,  -1.9219,   0.6875,  ...,  -6.6875,  -5.3438,  -3.0469],
         [-10.9375,   2.9688,   3.5156,  ...,  -3.4219,  -2.6250,   0.4004],
         [  5.6250,  12.4375,  11.7500,  ...,   5.0312,   8.4375,   6.2500]],

        [[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -9.7500,  -1.8281,   0.6875,  ...,  -6.7500,  -5.5000,  -2.9062],
         [-11.1250,   2.7344,   3.2656,  ...,  -3.4844,  -2.7500,   0.3359],
         [  5.7812,  12.3750,  12.0625,  ...,   5.1875,   8.2500,   6.4375]]],
       device='cuda:0'),)
 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                        | 2/15 [00:02<00:15,  1.21s/it]
(tensor([[[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [-10.3125,  -2.4844,   0.2539,  ...,  -6.8750,  -5.6250,  -3.3281],
         [-11.1875,   2.7031,   3.3594,  ...,  -3.3906,  -2.4688,   0.3984],
         [  5.3750,  12.1875,  11.7500,  ...,   5.2188,   8.5625,   6.2188]],

        [[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -9.6250,  -1.7344,   0.5156,  ...,  -6.5312,  -5.1875,  -2.7031],
         [-11.5000,   2.9531,   2.9375,  ...,  -3.6250,  -2.6719,   0.4590],
         [  5.3438,  12.8750,  11.9375,  ...,   5.6562,   8.3750,   6.3750]]],
       device='cuda:0'),)
(tensor([[[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -8.5625,  -1.4453,   1.1250,  ...,  -6.3750,  -5.1562,  -2.6562],
         [-11.1250,   3.1406,   3.5156,  ...,  -3.3750,  -2.2188,   0.4688],
         [  5.3125,  12.3125,  12.0625,  ...,   5.4688,   8.2500,   6.1562]],

        [[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [-10.0000,  -2.2344,   0.5703,  ...,  -6.6875,  -5.1875,  -3.3281],
         [-10.7500,   3.4844,   3.8750,  ...,  -3.2500,  -2.1562,   0.4102],
         [  5.4062,  12.1250,  11.7500,  ...,   4.8438,   7.6562,   6.1562]]],
       device='cuda:0'),)
(tensor([[[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -9.3125,  -1.8516,   0.9375,  ...,  -6.7812,  -5.4375,  -2.9844],
         [-11.2500,   3.6250,   3.5938,  ...,  -3.1094,  -2.1406,   0.5703],
         [  5.1250,  12.0000,  11.8125,  ...,   5.2812,   7.6875,   6.0000]],

        [[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -8.6250,  -1.3516,   1.1328,  ...,  -6.3750,  -5.1250,  -2.5938],
         [-11.1250,   3.1719,   3.5312,  ...,  -3.3281,  -2.2344,   0.5000],
         [  5.4375,  12.3125,  12.0000,  ...,   5.4375,   8.3750,   6.1250]]],
       device='cuda:0'),)
(tensor([[[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -9.1250,  -1.8516,   0.5938,  ...,  -6.4062,  -5.0000,  -2.5938],
         [-11.4375,   2.4219,   2.9531,  ...,  -3.7969,  -2.8594,   0.4883],
         [  5.1875,  12.8750,  12.0000,  ...,   5.6562,   8.5625,   6.7188]],

        [[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -9.8125,  -2.1094,   0.3027,  ...,  -6.9375,  -5.5625,  -3.0781],
         [-11.0625,   3.0156,   3.2656,  ...,  -3.5000,  -2.4531,   0.2314],
         [  5.0938,  12.5000,  11.8125,  ...,   5.3438,   8.5000,   6.2500]]],
       device='cuda:0'),)
(tensor([[[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -9.9375,  -2.0469,   0.6250,  ...,  -6.6562,  -5.3438,  -2.8594],
         [-11.1250,   2.7031,   3.6719,  ...,  -3.2188,  -2.3594,   0.5352],
         [  5.7188,  12.3750,  12.3125,  ...,   5.3438,   8.4375,   6.5625]],

        [[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -9.9375,  -1.9766,   0.6055,  ...,  -6.7188,  -5.5000,  -3.3750],
         [-10.4375,   4.0312,   4.1875,  ...,  -2.7344,  -2.0781,   0.8711],
         [  5.1562,  11.9375,  11.3750,  ...,   4.5312,   7.4375,   6.0938]]],
       device='cuda:0'),)
(tensor([[[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -9.1875,  -2.0781,   0.5820,  ...,  -6.4688,  -4.9375,  -2.8125],
         [-12.1250,   2.2969,   2.5625,  ...,  -3.8594,  -2.7812,   0.3184],
         [  5.3438,  12.8750,  12.0000,  ...,   5.6562,   8.6250,   6.7500]],

        [[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -9.8125,  -2.0469,   0.4258,  ...,  -6.9062,  -5.6250,  -2.9844],
         [-11.1250,   3.0938,   3.0625,  ...,  -3.4219,  -2.6250,   0.3945],
         [  5.3438,  12.0625,  11.5625,  ...,   4.8438,   7.8438,   6.2188]]],
       device='cuda:0'),)
(tensor([[[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -9.8750,  -2.0000,   0.4414,  ...,  -6.7812,  -5.5000,  -2.9062],
         [-11.5000,   2.8438,   2.9688,  ...,  -3.5000,  -2.6875,   0.2344],
         [  5.1875,  12.1875,  11.5625,  ...,   4.9688,   7.8750,   6.2188]],

        [[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [-10.0000,  -2.4375,   0.4883,  ...,  -7.0625,  -5.6562,  -3.5625],
         [-10.6875,   3.6406,   3.2812,  ...,  -3.0000,  -2.3594,   0.3477],
         [  5.1562,  11.9375,  11.5625,  ...,   5.0625,   7.8750,   5.8125]]],
       device='cuda:0'),)
(tensor([[[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -9.3750,  -2.1875,   0.3203,  ...,  -6.8438,  -5.5938,  -3.2188],
         [-11.4375,   3.0938,   3.3438,  ...,  -3.2500,  -2.2812,   0.5977],
         [  5.3125,  12.3125,  11.9375,  ...,   5.4375,   8.3125,   6.5625]],

        [[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -9.3750,  -1.5156,   1.0391,  ...,  -6.5000,  -5.1250,  -2.5625],
         [-11.3125,   3.0156,   4.1250,  ...,  -3.0938,  -2.1250,   0.7383],
         [  5.5000,  12.6250,  12.2500,  ...,   5.4688,   8.2500,   6.8125]]],
       device='cuda:0'),)
(tensor([[[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -9.6250,  -1.9375,   0.7930,  ...,  -6.6562,  -5.4375,  -2.9688],
         [-10.6875,   3.1719,   4.0625,  ...,  -3.0000,  -2.0469,   0.7031],
         [  5.5000,  12.2500,  12.0000,  ...,   5.3750,   8.1250,   6.5312]],

        [[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -8.8750,  -1.9219,   0.8320,  ...,  -6.6875,  -5.1875,  -2.9531],
         [-11.0000,   2.6875,   3.2500,  ...,  -3.7812,  -2.7188,   0.2012],
         [  5.2188,  12.9375,  11.9375,  ...,   5.5625,   8.5000,   6.5938]]],
       device='cuda:0'),)
(tensor([[[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -9.7500,  -1.7422,   0.8047,  ...,  -6.3438,  -5.0625,  -2.6562],
         [-11.1250,   2.7812,   3.5938,  ...,  -3.1875,  -2.4531,   0.4688],
         [  5.5938,  12.3125,  12.0625,  ...,   5.4062,   8.5000,   6.6250]],

        [[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -9.5625,  -1.9922,   0.3125,  ...,  -6.7188,  -5.1875,  -2.8906],
         [-11.6875,   2.9531,   3.2031,  ...,  -3.4219,  -2.2656,   0.3164],
         [  5.3125,  12.7500,  11.9375,  ...,   5.4375,   8.8125,   6.5312]]],
       device='cuda:0'),)
(tensor([[[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [-10.0000,  -2.2344,   0.3047,  ...,  -6.5938,  -5.2812,  -3.0781],
         [-11.3125,   2.9688,   3.0156,  ...,  -3.3594,  -2.4219,   0.3887],
         [  5.3125,  12.6875,  11.8750,  ...,   5.6562,   8.6875,   6.2812]],

        [[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -9.3750,  -1.7188,   0.3184,  ...,  -6.6250,  -5.2500,  -2.6875],
         [-11.2500,   3.0625,   3.3750,  ...,  -3.4531,  -2.4375,   0.5117],
         [  5.3125,  12.8125,  12.0625,  ...,   5.3750,   8.5000,   6.4688]]],
       device='cuda:0'),)
(tensor([[[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -9.7500,  -2.0625,   0.3281,  ...,  -7.0000,  -5.6250,  -3.0625],
         [-11.0000,   3.1094,   3.4375,  ...,  -3.5312,  -2.3438,   0.3242],
         [  5.1250,  12.5000,  11.8750,  ...,   5.2500,   8.5625,   6.2812]],

        [[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -9.4375,  -2.1250,   0.5352,  ...,  -6.5000,  -5.1875,  -3.2969],
         [-10.1875,   3.8281,   4.1250,  ...,  -2.6562,  -1.8828,   0.6211],
         [  5.5312,  12.1250,  11.6875,  ...,   5.5312,   8.3125,   6.0312]]],
       device='cuda:0'),)
(tensor([[[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -8.9375,  -1.1641,   1.1719,  ...,  -6.2188,  -4.9688,  -2.2812],
         [-10.5000,   3.2656,   4.1875,  ...,  -3.0000,  -2.1406,   1.0078],
         [  5.5000,  12.5625,  12.3125,  ...,   5.4688,   8.1250,   6.7500]],

        [[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -9.0000,  -1.9297,   0.4727,  ...,  -6.6562,  -5.2500,  -2.8438],
         [-12.0625,   2.9219,   3.1250,  ...,  -3.3906,  -2.4531,   0.5312],
         [  5.4062,  12.4375,  12.0000,  ...,   5.3750,   8.2500,   6.6562]]],
       device='cuda:0'),)
(tensor([[[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -9.8750,  -2.0469,   0.6406,  ...,  -6.6562,  -5.2188,  -3.0938],
         [-10.4375,   3.7812,   3.9531,  ...,  -2.9062,  -2.0938,   0.9375],
         [  5.0625,  12.1250,  11.5625,  ...,   4.8125,   7.5938,   6.2188]],

        [[ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         [ -9.8125,  -6.5938,  -1.6406,  ...,  -9.8750,  -4.9062,  -2.5156],
         ...,
         [ -9.0000,  -1.5234,   0.7344,  ...,  -6.4688,  -5.0000,  -2.8906],
         [-11.0625,   3.6250,   3.5625,  ...,  -3.1250,  -1.7656,   0.7539],
         [  5.6250,  12.2500,  12.1875,  ...,   5.4688,   8.6250,   6.2188]]],
       device='cuda:0'),)
{'eval_loss': 0.0012536218855530024, 'eval_runtime': 35.0753, 'eval_samples_per_second': 6.728, 'eval_steps_per_second': 0.428, 'epoch': 0.68}

======================================== [DEBUGGING AT GLOBAL STEP: 80] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option A is correct because it shows the back-bottom-left view.', 'C': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option C is incorrect because it includes rotated non-symmetric faces.', 'D': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option D is incorrect because it is a vertically mirrored version of the back-top-right view.', 'B': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option B is incorrect because it is a vertically mirrored version of the back-bottom-right view.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option A is correct because it shows the back-bottom-left view.', 'C': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option C is incorrect because it includes rotated non-symmetric faces.', 'D': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option D is incorrect because it is a vertically mirrored version of the back-top-right view.', 'B': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option B is incorrect because it is a vertically mirrored version of the back-bottom-right view.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                     | 81/118 [25:40<15:55, 25.83s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 81] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'When the outer gear is fixed, the planet gear revolves in the same direction as the sun gear rotates, but spins in the opposite direction.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'When the outer gear is fixed, the planet gear revolves in the same direction as the sun gear rotates, but spins in the opposite direction.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                    | 82/118 [25:54<13:29, 22.49s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 82] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option B is correct because it shows the front-top-right view.', 'C': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option C is incorrect because it includes rotated non-symmetric faces.', 'D': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option D is incorrect because it is a vertically mirrored version of the back-bottom-right view.', 'A': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option A is incorrect because it is a horizontally mirrored version of the front-bottom-left view.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option B is correct because it shows the front-top-right view.', 'C': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option C is incorrect because it includes rotated non-symmetric faces.', 'D': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option D is incorrect because it is a vertically mirrored version of the back-bottom-right view.', 'A': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option A is incorrect because it is a horizontally mirrored version of the front-bottom-left view.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                   | 83/118 [26:10<11:56, 20.46s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 83] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option D is correct because it shows the back-top-left view.', 'B': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option B is incorrect because it includes rotated non-symmetric faces.', 'A': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option A is incorrect because it is a vertically mirrored version of the front-top-left view.', 'C': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option C is incorrect because it is a vertically mirrored version of the back-bottom-left view.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option D is correct because it shows the back-top-left view.', 'B': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option B is incorrect because it includes rotated non-symmetric faces.', 'A': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option A is incorrect because it is a vertically mirrored version of the front-top-left view.', 'C': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option C is incorrect because it is a vertically mirrored version of the back-bottom-left view.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                  | 84/118 [26:25<10:37, 18.75s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 84] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is incorrect because holes in row 2 are missing.', 'B': 'Option B is incorrect because extra holes appear in row 4.', 'A': 'Option A is incorrect because holes that should appear in row 2 appear in row 4.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is incorrect because holes in row 2 are missing.', 'B': 'Option B is incorrect because extra holes appear in row 4.', 'A': 'Option A is incorrect because holes that should appear in row 2 appear in row 4.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                 | 85/118 [26:39<09:36, 17.48s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 85] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is correct because the initial arrow can be transformed into the final arrow.', 'CAB': 'Option CAB is incorrect because the initial arrow cannot be transformed into the final arrow.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is correct because the initial arrow can be transformed into the final arrow.', 'CAB': 'Option CAB is incorrect because the initial arrow cannot be transformed into the final arrow.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                | 86/118 [26:54<08:50, 16.59s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 86] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is correct because the initial state can be transformed into the target state.', 'BCA': 'Option BCA is incorrect because the initial state cannot be transformed into the target state.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is correct because the initial state can be transformed into the target state.', 'BCA': 'Option BCA is incorrect because the initial state cannot be transformed into the target state.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 87/118 [27:09<08:16, 16.03s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 87] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given two views, at least 11 cubes and at most 19 cubes are required to satisfy the constraints.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given two views, at least 11 cubes and at most 19 cubes are required to satisfy the constraints.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                              | 88/118 [27:23<07:48, 15.60s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 88] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is incorrect because the internal outlines are missing.', 'A': 'Option A is incorrect because the internal outlines are missing.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is incorrect because the internal outlines are missing.', 'A': 'Option A is incorrect because the internal outlines are missing.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 89/118 [27:37<07:20, 15.18s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 89] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is correct because it was obtained by removing one small cube from the original stack.', 'C': 'Option C is incorrect because the cube stack can be obtained by rotating the original stack around the y-axis by 270 degrees.', 'A': 'Option A is incorrect because the cube stack can be obtained by rotating the original stack around the y-axis by 90 degrees.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is correct because it was obtained by removing one small cube from the original stack.', 'C': 'Option C is incorrect because the cube stack can be obtained by rotating the original stack around the y-axis by 270 degrees.', 'A': 'Option A is incorrect because the cube stack can be obtained by rotating the original stack around the y-axis by 90 degrees.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                            | 90/118 [27:52<06:58, 14.96s/it]

{'loss': 0.0001, 'grad_norm': 0.005556132178753614, 'learning_rate': 7.080437170788723e-07, 'epoch': 0.76}
(tensor([[[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [-10.0000,  -2.6719,   0.2402,  ...,  -7.2500,  -5.9062,  -3.5312],
         [-11.8125,   2.1562,   2.9062,  ...,  -4.0938,  -3.3594,  -0.2480],
         [  5.5625,  12.2500,  11.7500,  ...,   4.7812,   8.3125,   6.0625]],

        [[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [-10.1875,  -2.4688,   0.2832,  ...,  -7.1562,  -5.9688,  -3.3438],
         [-11.8125,   2.1250,   2.7031,  ...,  -4.0625,  -3.4062,  -0.1992],
         [  5.5938,  12.1875,  12.0625,  ...,   5.0000,   8.1250,   6.2500]]],
       device='cuda:0'),)
 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                        | 2/15 [00:02<00:15,  1.21s/it]
(tensor([[[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [-10.7500,  -3.0781,  -0.1201,  ...,  -7.3125,  -6.0625,  -3.7031],
         [-12.2500,   1.9062,   2.7188,  ...,  -4.0312,  -3.1875,  -0.2393],
         [  5.1250,  12.0625,  11.7500,  ...,   5.0000,   8.4375,   6.0625]],

        [[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [-10.0000,  -2.4531,   0.1045,  ...,  -7.0000,  -5.6875,  -3.2188],
         [-12.1875,   2.0938,   2.3594,  ...,  -4.3125,  -3.3750,  -0.1738],
         [  5.1562,  12.6875,  11.9375,  ...,   5.4062,   8.1875,   6.1875]]],
       device='cuda:0'),)
(tensor([[[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [ -8.9375,  -1.9688,   0.7969,  ...,  -6.7812,  -5.5625,  -3.0469],
         [-11.8125,   2.4844,   3.0000,  ...,  -3.9688,  -2.8125,  -0.0791],
         [  5.0938,  12.1250,  12.0000,  ...,   5.2500,   8.1250,   6.0000]],

        [[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [-10.4375,  -2.7812,   0.2080,  ...,  -7.1250,  -5.5938,  -3.7656],
         [-11.5000,   2.7656,   3.3594,  ...,  -3.8594,  -2.7969,  -0.1221],
         [  5.1875,  12.0000,  11.8125,  ...,   4.6875,   7.5938,   6.0000]]],
       device='cuda:0'),)
(tensor([[[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [ -9.8125,  -2.4531,   0.5234,  ...,  -7.2500,  -5.9375,  -3.4688],
         [-11.9375,   2.9531,   3.1094,  ...,  -3.7344,  -2.7344,   0.0767],
         [  5.0312,  11.8750,  11.9375,  ...,   5.1250,   7.5938,   5.8750]],

        [[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [ -8.9375,  -2.0156,   0.7617,  ...,  -6.8438,  -5.6562,  -3.1406],
         [-11.8125,   2.5938,   3.0156,  ...,  -3.9531,  -2.7656,  -0.0211],
         [  5.2188,  12.1250,  12.0000,  ...,   5.2188,   8.1875,   5.9062]]],
       device='cuda:0'),)
(tensor([[[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [ -9.5625,  -2.5312,   0.1592,  ...,  -6.9375,  -5.5938,  -3.1562],
         [-12.3750,   1.6406,   2.2812,  ...,  -4.4688,  -3.6562,  -0.1533],
         [  5.0625,  12.6875,  12.0000,  ...,   5.5000,   8.3750,   6.5312]],

        [[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [-10.1250,  -2.7344,  -0.1191,  ...,  -7.4375,  -6.0625,  -3.5312],
         [-12.0000,   2.2344,   2.6719,  ...,  -4.2500,  -3.1094,  -0.3770],
         [  4.9688,  12.3125,  11.8125,  ...,   5.1562,   8.3750,   6.0625]]],
       device='cuda:0'),)
(tensor([[[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [-10.5000,  -2.8438,   0.1396,  ...,  -7.1875,  -5.8438,  -3.4375],
         [-11.8750,   2.0781,   3.0781,  ...,  -3.8281,  -3.0000,  -0.0139],
         [  5.4062,  12.1875,  12.2500,  ...,   5.0938,   8.2500,   6.3125]],

        [[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [-10.1875,  -2.5000,   0.2256,  ...,  -7.0938,  -5.8438,  -3.7812],
         [-11.2500,   3.3281,   3.6875,  ...,  -3.3438,  -2.6719,   0.2676],
         [  5.0625,  11.8750,  11.4375,  ...,   4.4062,   7.3438,   5.9375]]],
       device='cuda:0'),)
(tensor([[[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [ -9.5000,  -2.7188,   0.1924,  ...,  -6.9375,  -5.4375,  -3.2969],
         [-12.8750,   1.6016,   2.0312,  ...,  -4.5000,  -3.5000,  -0.2734],
         [  5.1562,  12.7500,  12.0625,  ...,   5.4688,   8.5000,   6.6250]],

        [[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [-10.1875,  -2.6875,   0.0454,  ...,  -7.3438,  -6.0312,  -3.4531],
         [-11.7500,   2.3906,   2.5625,  ...,  -4.0625,  -3.2188,  -0.1377],
         [  5.1562,  11.8125,  11.5000,  ...,   4.5625,   7.6250,   5.9688]]],
       device='cuda:0'),)
(tensor([[[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [-10.1875,  -2.7656,   0.0486,  ...,  -7.3125,  -6.0625,  -3.5156],
         [-12.3125,   2.1875,   2.4688,  ...,  -4.0938,  -3.3438,  -0.2969],
         [  4.9062,  11.9375,  11.5625,  ...,   4.7812,   7.6250,   6.0312]],

        [[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [-10.4375,  -3.0781,   0.0635,  ...,  -7.5000,  -6.1875,  -4.0938],
         [-11.3125,   2.9531,   2.8281,  ...,  -3.6406,  -2.9844,  -0.2119],
         [  4.9688,  11.8750,  11.6875,  ...,   4.9688,   7.8438,   5.6562]]],
       device='cuda:0'),)
(tensor([[[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [ -9.8750,  -2.8750,  -0.1064,  ...,  -7.3438,  -6.0938,  -3.7344],
         [-12.1250,   2.4219,   2.7500,  ...,  -3.8281,  -2.9531,   0.0776],
         [  5.1250,  12.1875,  11.9375,  ...,   5.2500,   8.1875,   6.3750]],

        [[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [ -9.7500,  -2.0781,   0.6406,  ...,  -6.9375,  -5.5938,  -3.0469],
         [-12.1250,   2.4062,   3.5312,  ...,  -3.6719,  -2.7500,   0.1895],
         [  5.2500,  12.5625,  12.3750,  ...,   5.2812,   8.1250,   6.6875]]],
       device='cuda:0'),)
(tensor([[[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [-10.1250,  -2.4844,   0.3965,  ...,  -7.0938,  -5.8750,  -3.4219],
         [-11.3750,   2.3438,   3.4375,  ...,  -3.7031,  -2.7500,   0.1807],
         [  5.1875,  12.1250,  12.0000,  ...,   5.2188,   7.9688,   6.3125]],

        [[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [ -9.3125,  -2.6562,   0.3555,  ...,  -7.1875,  -5.7812,  -3.4375],
         [-11.7500,   2.0312,   2.7344,  ...,  -4.3750,  -3.3438,  -0.3359],
         [  5.0000,  12.7500,  11.9375,  ...,   5.3438,   8.2500,   6.3750]]],
       device='cuda:0'),)
(tensor([[[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [-10.2500,  -2.5000,   0.3848,  ...,  -6.9062,  -5.6562,  -3.2188],
         [-12.0000,   2.0000,   2.9688,  ...,  -3.8906,  -3.2031,  -0.1094],
         [  5.3750,  12.1250,  12.0000,  ...,   5.1562,   8.2500,   6.4062]],

        [[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [-10.0000,  -2.6250,  -0.0796,  ...,  -7.1562,  -5.7188,  -3.3750],
         [-12.6250,   2.1406,   2.5781,  ...,  -4.1250,  -3.0312,  -0.3047],
         [  5.0312,  12.5000,  11.9375,  ...,   5.2188,   8.6250,   6.3125]]],
       device='cuda:0'),)
(tensor([[[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [-10.5000,  -2.9062,  -0.1167,  ...,  -7.1250,  -5.8125,  -3.5781],
         [-12.1875,   2.3438,   2.5000,  ...,  -3.9219,  -2.9844,  -0.1260],
         [  5.1250,  12.5000,  11.8750,  ...,   5.5000,   8.5000,   6.0625]],

        [[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [ -9.8750,  -2.4375,  -0.1709,  ...,  -7.1250,  -5.7500,  -3.1875],
         [-12.1250,   2.4219,   2.8125,  ...,  -4.0938,  -3.1094,  -0.0889],
         [  5.0938,  12.5000,  12.0625,  ...,   5.1250,   8.3125,   6.2812]]],
       device='cuda:0'),)
(tensor([[[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [-10.0625,  -2.7188,  -0.0771,  ...,  -7.4688,  -6.0625,  -3.4688],
         [-11.9375,   2.3281,   2.8125,  ...,  -4.2188,  -3.0781,  -0.3379],
         [  4.9062,  12.3125,  11.8750,  ...,   5.0625,   8.3750,   6.1250]],

        [[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [ -9.8125,  -2.7656,   0.1396,  ...,  -6.9688,  -5.6875,  -3.8281],
         [-10.9375,   3.1875,   3.6562,  ...,  -3.2188,  -2.5156,   0.1055],
         [  5.2500,  11.8750,  11.7500,  ...,   5.3125,   8.1250,   5.8125]]],
       device='cuda:0'),)
(tensor([[[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [ -9.5000,  -1.8516,   0.6680,  ...,  -6.6875,  -5.5625,  -2.8125],
         [-11.3750,   2.4844,   3.5156,  ...,  -3.6562,  -2.8594,   0.4043],
         [  5.2812,  12.3750,  12.3125,  ...,   5.2500,   7.9688,   6.5312]],

        [[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [ -9.4375,  -2.6094,   0.0952,  ...,  -7.1250,  -5.7500,  -3.3594],
         [-12.9375,   2.1719,   2.5312,  ...,  -4.0625,  -3.1094,  -0.0354],
         [  5.0938,  12.3750,  12.0625,  ...,   5.2188,   8.1250,   6.5312]]],
       device='cuda:0'),)
(tensor([[[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [-10.4375,  -2.6562,   0.2168,  ...,  -7.1250,  -5.7812,  -3.5938],
         [-11.2500,   3.1250,   3.4062,  ...,  -3.5625,  -2.6875,   0.3672],
         [  4.8750,  12.0000,  11.5625,  ...,   4.6250,   7.4688,   6.0312]],

        [[-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         [-10.1875,  -6.4375,  -1.6719,  ...,  -9.9375,  -4.9062,  -2.4062],
         ...,
         [ -9.3750,  -2.1094,   0.3750,  ...,  -6.9375,  -5.4688,  -3.3594],
         [-11.9375,   3.0781,   3.0469,  ...,  -3.7344,  -2.4375,   0.1973],
         [  5.4062,  12.1250,  12.1875,  ...,   5.2812,   8.4375,   6.0000]]],
       device='cuda:0'),)
{'eval_loss': 0.0011893553892150521, 'eval_runtime': 35.1996, 'eval_samples_per_second': 6.705, 'eval_steps_per_second': 0.426, 'epoch': 0.76}

======================================== [DEBUGGING AT GLOBAL STEP: 90] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Assuming the bottom face is the first cell in the second row of the net, then after folding, the front face is blue, the back face is yellow, the left face is green, the right face is cyan, the top face is red, the bottom face is pink.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Assuming the bottom face is the first cell in the second row of the net, then after folding, the front face is blue, the back face is yellow, the left face is green, the right face is cyan, the top face is red, the bottom face is pink.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                           | 91/118 [28:42<11:29, 25.55s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 91] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is correct because two faces have swapped positions, so it cannot form the cube shown in the left image.„ÄÇ', 'C': 'Option C is incorrect because the relative positions of three faces match the cube shown in the left image.', 'A': 'Option A is incorrect because the relative positions of three faces match the cube shown in the left image.', 'D': 'Option D is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is correct because two faces have swapped positions, so it cannot form the cube shown in the left image.„ÄÇ', 'C': 'Option C is incorrect because the relative positions of three faces match the cube shown in the left image.', 'A': 'Option A is incorrect because the relative positions of three faces match the cube shown in the left image.', 'D': 'Option D is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                          | 92/118 [28:57<09:40, 22.34s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 92] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given three views, at least 5 cubes and at most 5 cubes are required to satisfy the constraints.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given three views, at least 5 cubes and at most 5 cubes are required to satisfy the constraints.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 93/118 [29:11<08:19, 19.96s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 93] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because it was obtained by rotating the original image 180 degrees.', 'B': 'Option B is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it horizontally.', 'A': 'Option A is incorrect because it was obtained by rotating the asymmetric patterns in the image.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is correct because it was obtained by rotating the original image 180 degrees.', 'B': 'Option B is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it horizontally.', 'A': 'Option A is incorrect because it was obtained by rotating the asymmetric patterns in the image.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                        | 94/118 [29:26<07:17, 18.25s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 94] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because the initial state can be transformed into the final state.', 'ABD': 'Option ABD is incorrect because the initial state cannot be transformed into the final state.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is correct because the initial state can be transformed into the final state.', 'ABD': 'Option ABD is incorrect because the initial state cannot be transformed into the final state.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 95/118 [29:40<06:33, 17.11s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 95] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is correct because it was obtained by rotating the original image 270 degrees.', 'B': 'Option B is incorrect because it was obtained by rotating the original image 270 degrees and then flipping it horizontally.', 'C': 'Option C is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it vertically.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is correct because it was obtained by rotating the original image 270 degrees.', 'B': 'Option B is incorrect because it was obtained by rotating the original image 270 degrees and then flipping it horizontally.', 'C': 'Option C is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it vertically.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                      | 96/118 [29:55<05:59, 16.35s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 96] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is correct because the initial arrow can be transformed into the final arrow.', 'DAC': 'Option DAC is incorrect because the initial arrow cannot be transformed into the final arrow.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is correct because the initial arrow can be transformed into the final arrow.', 'DAC': 'Option DAC is incorrect because the initial arrow cannot be transformed into the final arrow.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                     | 97/118 [30:09<05:32, 15.81s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 97] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because the internal outlines are missing.', 'B': 'Option B is incorrect because the internal outlines are missing.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is incorrect because the internal outlines are missing.', 'B': 'Option B is incorrect because the internal outlines are missing.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                    | 98/118 [30:24<05:09, 15.47s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 98] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'In this connection, the orange object rotates in the opposite direction to the green object.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'In this connection, the orange object rotates in the opposite direction to the green object.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 99/118 [30:38<04:47, 15.13s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 99] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Meshed gears rotate in opposite directions.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Meshed gears rotate in opposite directions.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 100/118 [30:53<04:30, 15.01s/it]

{'loss': 0.0001, 'grad_norm': 0.0035532894544303417, 'learning_rate': 3.0131562198377763e-07, 'epoch': 0.85}
(tensor([[[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [-10.1875,  -2.9062,   0.0957,  ...,  -7.3438,  -6.0938,  -3.7031],
         [-12.1250,   1.8750,   2.6562,  ...,  -4.3750,  -3.6562,  -0.4824],
         [  5.3125,  12.1875,  11.8125,  ...,   4.7500,   8.2500,   6.0000]],

        [[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [-10.3750,  -2.7500,   0.1592,  ...,  -7.4062,  -6.2188,  -3.5781],
         [-12.0625,   1.6719,   2.4375,  ...,  -4.4375,  -3.7656,  -0.4375],
         [  5.5625,  12.1250,  12.1250,  ...,   4.9375,   8.0000,   6.1250]]],
       device='cuda:0'),)
 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                        | 2/15 [00:02<00:15,  1.21s/it]
(tensor([[[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [-11.0000,  -3.4688,  -0.3438,  ...,  -7.5625,  -6.3125,  -4.0000],
         [-12.5625,   1.5625,   2.4844,  ...,  -4.3125,  -3.4844,  -0.4824],
         [  5.0000,  11.8750,  11.7500,  ...,   4.9062,   8.3125,   5.9375]],

        [[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [-10.1250,  -2.7344,  -0.0452,  ...,  -7.1875,  -5.8750,  -3.4219],
         [-12.6250,   1.7812,   2.1562,  ...,  -4.5938,  -3.7031,  -0.3594],
         [  4.9688,  12.4375,  11.8750,  ...,   5.2812,   8.0625,   6.0938]]],
       device='cuda:0'),)
(tensor([[[-9.8750e+00, -6.4375e+00, -1.6641e+00,  ..., -9.7500e+00,
          -4.8438e+00, -2.2500e+00],
         [-9.8750e+00, -6.4375e+00, -1.6641e+00,  ..., -9.7500e+00,
          -4.8438e+00, -2.2500e+00],
         [-9.8750e+00, -6.4375e+00, -1.6641e+00,  ..., -9.7500e+00,
          -4.8438e+00, -2.2500e+00],
         ...,
         [-9.2500e+00, -2.2344e+00,  6.0938e-01,  ..., -7.0312e+00,
          -5.7500e+00, -3.2500e+00],
         [-1.2125e+01,  2.2969e+00,  2.7969e+00,  ..., -4.2188e+00,
          -3.0625e+00, -3.0469e-01],
         [ 5.1250e+00,  1.2000e+01,  1.2062e+01,  ...,  5.1562e+00,
           8.0000e+00,  5.9062e+00]],

        [[-9.8750e+00, -6.4375e+00, -1.6641e+00,  ..., -9.7500e+00,
          -4.8438e+00, -2.2500e+00],
         [-9.8750e+00, -6.4375e+00, -1.6641e+00,  ..., -9.7500e+00,
          -4.8438e+00, -2.2500e+00],
         [-9.8750e+00, -6.4375e+00, -1.6641e+00,  ..., -9.7500e+00,
          -4.8438e+00, -2.2500e+00],
         ...,
         [-1.0625e+01, -3.0469e+00,  2.0599e-03,  ..., -7.3438e+00,
          -5.8750e+00, -4.0312e+00],
         [-1.1938e+01,  2.3750e+00,  3.1250e+00,  ..., -4.1562e+00,
          -3.1094e+00, -4.2188e-01],
         [ 5.1875e+00,  1.1938e+01,  1.1812e+01,  ...,  4.5938e+00,
           7.4688e+00,  5.9375e+00]]], device='cuda:0'),)
(tensor([[[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [-10.0000,  -2.7969,   0.3047,  ...,  -7.4688,  -6.1875,  -3.7188],
         [-12.1875,   2.6250,   2.8750,  ...,  -4.0000,  -3.0000,  -0.2090],
         [  4.9375,  11.8750,  11.9375,  ...,   5.1250,   7.5625,   5.7812]],

        [[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [ -9.1250,  -2.2031,   0.5938,  ...,  -7.0312,  -5.8438,  -3.2812],
         [-12.1250,   2.4375,   2.8906,  ...,  -4.0938,  -2.9531,  -0.2041],
         [  5.1250,  12.0000,  12.0000,  ...,   5.1250,   8.1250,   5.8125]]],
       device='cuda:0'),)
(tensor([[[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [ -9.7500,  -2.8906,  -0.0442,  ...,  -7.1250,  -5.7812,  -3.4219],
         [-12.6875,   1.2734,   2.0625,  ...,  -4.8125,  -3.9531,  -0.4766],
         [  5.0312,  12.6250,  12.0625,  ...,   5.4062,   8.3125,   6.5000]],

        [[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [-10.4375,  -3.0469,  -0.2812,  ...,  -7.6250,  -6.2812,  -3.7344],
         [-12.3125,   1.8516,   2.4062,  ...,  -4.5312,  -3.4688,  -0.6836],
         [  4.7812,  12.1875,  11.8125,  ...,   5.0625,   8.2500,   5.9688]]],
       device='cuda:0'),)
(tensor([[[-9.8750e+00, -6.4375e+00, -1.6641e+00,  ..., -9.7500e+00,
          -4.8438e+00, -2.2500e+00],
         [-9.8750e+00, -6.4375e+00, -1.6641e+00,  ..., -9.7500e+00,
          -4.8438e+00, -2.2500e+00],
         [-9.8750e+00, -6.4375e+00, -1.6641e+00,  ..., -9.7500e+00,
          -4.8438e+00, -2.2500e+00],
         ...,
         [-1.0625e+01, -3.1094e+00, -2.0905e-03,  ..., -7.3125e+00,
          -6.0625e+00, -3.6094e+00],
         [-1.2250e+01,  1.6953e+00,  2.7969e+00,  ..., -4.1875e+00,
          -3.4062e+00, -3.0859e-01],
         [ 5.3438e+00,  1.2000e+01,  1.2250e+01,  ...,  4.9375e+00,
           8.1250e+00,  6.2188e+00]],

        [[-9.8750e+00, -6.4375e+00, -1.6641e+00,  ..., -9.7500e+00,
          -4.8438e+00, -2.2500e+00],
         [-9.8750e+00, -6.4375e+00, -1.6641e+00,  ..., -9.7500e+00,
          -4.8438e+00, -2.2500e+00],
         [-9.8750e+00, -6.4375e+00, -1.6641e+00,  ..., -9.7500e+00,
          -4.8438e+00, -2.2500e+00],
         ...,
         [-1.0438e+01, -2.7656e+00,  1.0498e-02,  ..., -7.3125e+00,
          -6.0625e+00, -4.0312e+00],
         [-1.1750e+01,  3.1094e+00,  3.4688e+00,  ..., -3.5469e+00,
          -2.9688e+00,  7.3730e-02],
         [ 4.9062e+00,  1.1812e+01,  1.1438e+01,  ...,  4.3125e+00,
           7.2812e+00,  5.8438e+00]]], device='cuda:0'),)
(tensor([[[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [ -9.7500,  -2.9688,   0.0287,  ...,  -7.1562,  -5.5938,  -3.4688],
         [-13.2500,   1.2109,   1.7891,  ...,  -4.8125,  -3.7812,  -0.5977],
         [  5.1562,  12.6875,  12.0625,  ...,   5.4375,   8.4375,   6.5000]],

        [[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [-10.4375,  -3.0156,  -0.1079,  ...,  -7.5625,  -6.3125,  -3.6875],
         [-12.1875,   2.0469,   2.3438,  ...,  -4.2500,  -3.5312,  -0.3926],
         [  5.0625,  11.7500,  11.5000,  ...,   4.4688,   7.5938,   5.8750]]],
       device='cuda:0'),)
(tensor([[[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [-10.4375,  -2.8906,  -0.0610,  ...,  -7.4375,  -6.2500,  -3.6250],
         [-12.5625,   1.8516,   2.2500,  ...,  -4.4062,  -3.6250,  -0.5391],
         [  4.8438,  11.8750,  11.5625,  ...,   4.7500,   7.5938,   5.9375]],

        [[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [-10.5625,  -3.2812,  -0.0913,  ...,  -7.6250,  -6.3750,  -4.2812],
         [-11.7500,   2.6719,   2.5781,  ...,  -3.8750,  -3.2500,  -0.4512],
         [  4.8750,  11.6875,  11.6250,  ...,   4.8438,   7.7500,   5.5625]]],
       device='cuda:0'),)
(tensor([[[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [-10.0625,  -3.1562,  -0.2773,  ...,  -7.5625,  -6.3438,  -3.9219],
         [-12.5000,   2.1406,   2.5625,  ...,  -4.0625,  -3.2031,  -0.1650],
         [  4.9375,  12.0625,  12.0000,  ...,   5.1250,   8.1250,   6.2812]],

        [[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [ -9.9375,  -2.3750,   0.4883,  ...,  -7.0938,  -5.7812,  -3.1875],
         [-12.4375,   1.9609,   3.2344,  ...,  -4.0312,  -3.1562,  -0.1758],
         [  5.3125,  12.3750,  12.3750,  ...,   5.1562,   8.0000,   6.5938]]],
       device='cuda:0'),)
(tensor([[[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [-10.2500,  -2.8281,   0.2109,  ...,  -7.3438,  -6.0938,  -3.6719],
         [-11.7500,   2.0469,   3.2188,  ...,  -3.9531,  -3.0312,  -0.1514],
         [  5.1875,  12.0000,  12.0000,  ...,   5.0938,   7.9062,   6.2500]],

        [[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [ -9.5625,  -2.8594,   0.2324,  ...,  -7.3750,  -5.9688,  -3.5781],
         [-12.1875,   1.7891,   2.5156,  ...,  -4.6250,  -3.6250,  -0.5312],
         [  5.0000,  12.6875,  12.0000,  ...,   5.2812,   8.2500,   6.3438]]],
       device='cuda:0'),)
(tensor([[[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [-10.3750,  -2.8125,   0.2236,  ...,  -7.1250,  -5.9062,  -3.4531],
         [-12.2500,   1.7656,   2.8281,  ...,  -4.0938,  -3.3750,  -0.3262],
         [  5.1562,  12.0000,  11.9375,  ...,   5.0625,   8.1875,   6.2500]],

        [[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [-10.1875,  -2.9375,  -0.2480,  ...,  -7.3125,  -5.9062,  -3.5781],
         [-13.0625,   1.7578,   2.2656,  ...,  -4.4688,  -3.3594,  -0.6445],
         [  5.0000,  12.3750,  11.9375,  ...,   5.1562,   8.5625,   6.2500]]],
       device='cuda:0'),)
(tensor([[[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [-10.6250,  -3.1250,  -0.2246,  ...,  -7.2500,  -5.9375,  -3.7188],
         [-12.5000,   1.8594,   2.2188,  ...,  -4.3750,  -3.4062,  -0.4961],
         [  5.0625,  12.4375,  11.9375,  ...,   5.4062,   8.4375,   5.9688]],

        [[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [ -9.9375,  -2.5625,  -0.2344,  ...,  -7.1875,  -5.9062,  -3.3125],
         [-12.4375,   2.0156,   2.5000,  ...,  -4.4375,  -3.4844,  -0.4121],
         [  4.9375,  12.5000,  12.0625,  ...,   5.0938,   8.3125,   6.2500]]],
       device='cuda:0'),)
(tensor([[[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [-10.3125,  -3.0312,  -0.2236,  ...,  -7.6562,  -6.3438,  -3.7656],
         [-12.2500,   2.0781,   2.5625,  ...,  -4.5000,  -3.3281,  -0.6094],
         [  4.8750,  12.1875,  11.8750,  ...,   5.0000,   8.2500,   6.0000]],

        [[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [-10.0000,  -2.9844,  -0.0253,  ...,  -7.0938,  -5.9062,  -4.0000],
         [-11.3125,   2.9844,   3.4375,  ...,  -3.4219,  -2.6719,  -0.0967],
         [  5.1562,  11.8750,  11.7500,  ...,   5.2500,   8.1250,   5.7500]]],
       device='cuda:0'),)
(tensor([[[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [ -9.5000,  -2.0469,   0.5469,  ...,  -6.8750,  -5.7188,  -2.9375],
         [-11.7500,   2.2344,   3.3125,  ...,  -3.9219,  -3.1094,   0.1582],
         [  5.1875,  12.3125,  12.3125,  ...,   5.1875,   7.9375,   6.5000]],

        [[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [ -9.5625,  -2.9219,  -0.0747,  ...,  -7.3438,  -6.0000,  -3.6406],
         [-13.1250,   1.8438,   2.3594,  ...,  -4.3750,  -3.4375,  -0.3359],
         [  5.0000,  12.1250,  12.0625,  ...,   5.0938,   8.0000,   6.3750]]],
       device='cuda:0'),)
(tensor([[[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [-10.5625,  -2.9531,   0.0322,  ...,  -7.3438,  -6.0000,  -3.8281],
         [-11.6875,   2.7188,   3.1406,  ...,  -3.8750,  -3.0156,   0.0835],
         [  4.8750,  11.8750,  11.5625,  ...,   4.5625,   7.3750,   5.9688]],

        [[ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         [ -9.8750,  -6.4375,  -1.6641,  ...,  -9.7500,  -4.8438,  -2.2500],
         ...,
         [ -9.5625,  -2.4062,   0.1836,  ...,  -7.1562,  -5.7500,  -3.5625],
         [-12.0625,   2.7656,   2.9062,  ...,  -3.9062,  -2.5469,   0.0347],
         [  5.2188,  12.0625,  12.2500,  ...,   5.1562,   8.3750,   5.9375]]],
       device='cuda:0'),)
{'eval_loss': 0.001197473960928619, 'eval_runtime': 35.1383, 'eval_samples_per_second': 6.716, 'eval_steps_per_second': 0.427, 'epoch': 0.85}
2025-09-29 22:57:32,460 - INFO - vq_config is None. initializing the ChameleonVQConfig with default values.

======================================== [DEBUGGING AT GLOBAL STEP: 100] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is incorrect because the red cubes are not in the correct position in the view.', 'A': 'Option A is incorrect because the shape matches the right view instead of the left view, and the red cubes are not in the correct position.', 'C': 'Option C is incorrect because the image shows the right view of the cube stack instead of the left view.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is incorrect because the red cubes are not in the correct position in the view.', 'A': 'Option A is incorrect because the shape matches the right view instead of the left view, and the red cubes are not in the correct position.', 'C': 'Option C is incorrect because the image shows the right view of the cube stack instead of the left view.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 101/118 [32:28<11:05, 39.12s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 101] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is correct because it was obtained by removing one small cube from the original stack.', 'B': 'Option B is incorrect because the cube stack can be obtained by rotating the original stack around the x-axis by 270 degrees.', 'C': 'Option C is incorrect because the cube stack can be obtained by rotating the original stack around the x-axis by 90 degrees.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is correct because it was obtained by removing one small cube from the original stack.', 'B': 'Option B is incorrect because the cube stack can be obtained by rotating the original stack around the x-axis by 270 degrees.', 'C': 'Option C is incorrect because the cube stack can be obtained by rotating the original stack around the x-axis by 90 degrees.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 102/118 [32:43<08:28, 31.81s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 102] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because holes in row 5 are missing.', 'D': 'Option D is incorrect because extra holes appear in row 2.', 'B': 'Option B is incorrect because holes that should appear in row 5 appear in row 2.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is incorrect because holes in row 5 are missing.', 'D': 'Option D is incorrect because extra holes appear in row 2.', 'B': 'Option B is incorrect because holes that should appear in row 5 appear in row 2.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 103/118 [32:57<06:38, 26.58s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 103] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'D': 'Option D is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'D': 'Option D is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 104/118 [33:12<05:20, 22.93s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 104] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is correct because the initial state can be transformed into the final state.', 'BCD': 'Option BCD is incorrect because the initial state cannot be transformed into the final state.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is correct because the initial state can be transformed into the final state.', 'BCD': 'Option BCD is incorrect because the initial state cannot be transformed into the final state.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 105/118 [33:26<04:24, 20.37s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 105] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'C': 'Option C is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'C': 'Option C is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 106/118 [33:40<03:42, 18.54s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 106] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is correct because the relative positions of three faces match the cube shown in the left image.', 'D': 'Option D is incorrect because the squares with asymmetric patterns have been rotated.', 'B': 'Option B is incorrect because the squares with asymmetric patterns have been rotated.', 'C': 'Option C is incorrect because two faces have swapped positions.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is correct because the relative positions of three faces match the cube shown in the left image.', 'D': 'Option D is incorrect because the squares with asymmetric patterns have been rotated.', 'B': 'Option B is incorrect because the squares with asymmetric patterns have been rotated.', 'C': 'Option C is incorrect because two faces have swapped positions.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 107/118 [33:55<03:10, 17.30s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 107] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is correct because it was obtained by rotating the original image 180 degrees.', 'C': 'Option C is incorrect because it was obtained by rotating the original image 90 degrees and then flipping it vertically.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 270 degrees and then flipping it horizontally.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is correct because it was obtained by rotating the original image 180 degrees.', 'C': 'Option C is incorrect because it was obtained by rotating the original image 90 degrees and then flipping it vertically.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 270 degrees and then flipping it horizontally.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 108/118 [34:09<02:44, 16.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 108] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is correct because the relative positions of three faces match the cube shown in the left image.', 'B': 'Option B is incorrect because the squares with asymmetric patterns have been rotated.', 'C': 'Option C is incorrect because the squares with asymmetric patterns have been rotated.', 'D': 'Option D is incorrect because two faces have swapped positions.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is correct because the relative positions of three faces match the cube shown in the left image.', 'B': 'Option B is incorrect because the squares with asymmetric patterns have been rotated.', 'C': 'Option C is incorrect because the squares with asymmetric patterns have been rotated.', 'D': 'Option D is incorrect because two faces have swapped positions.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 109/118 [34:24<02:22, 15.84s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 109] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because it was obtained by removing one small cube from the original stack.', 'B': 'Option B is incorrect because the cube stack can be obtained by rotating the original stack around the y-axis by 270 degrees.', 'A': 'Option A is incorrect because the cube stack can be obtained by rotating the original stack around the x-axis by 270 degrees.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is correct because it was obtained by removing one small cube from the original stack.', 'B': 'Option B is incorrect because the cube stack can be obtained by rotating the original stack around the y-axis by 270 degrees.', 'A': 'Option A is incorrect because the cube stack can be obtained by rotating the original stack around the x-axis by 270 degrees.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 110/118 [34:38<02:03, 15.39s/it]

{'loss': 0.0054, 'grad_norm': 0.0034349116031080484, 'learning_rate': 6.050904343141095e-08, 'epoch': 0.93}
(tensor([[[ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         ...,
         [-10.1875,  -2.9219,   0.0623,  ...,  -7.4062,  -6.0938,  -3.7344],
         [-12.2500,   1.7656,   2.5781,  ...,  -4.5000,  -3.6719,  -0.5586],
         [  5.3125,  12.1875,  11.8125,  ...,   4.7500,   8.2500,   6.0000]],

        [[ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         ...,
         [-10.2500,  -2.7812,   0.1328,  ...,  -7.4375,  -6.2188,  -3.6094],
         [-12.1250,   1.7656,   2.4688,  ...,  -4.4375,  -3.7031,  -0.4277],
         [  5.5312,  12.0625,  12.1250,  ...,   4.8750,   8.0000,   6.1250]]],
       device='cuda:0'),)
 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                        | 2/15 [00:02<00:15,  1.21s/it]
(tensor([[[-9.5625e+00, -6.4375e+00, -1.5312e+00,  ..., -9.7500e+00,
          -4.8750e+00, -2.4531e+00],
         [-9.5625e+00, -6.4375e+00, -1.5312e+00,  ..., -9.7500e+00,
          -4.8750e+00, -2.4531e+00],
         [-9.5625e+00, -6.4375e+00, -1.5312e+00,  ..., -9.7500e+00,
          -4.8750e+00, -2.4531e+00],
         ...,
         [-1.0875e+01, -3.4062e+00, -3.2227e-01,  ..., -7.5625e+00,
          -6.2812e+00, -3.9844e+00],
         [-1.2562e+01,  1.5625e+00,  2.5000e+00,  ..., -4.3750e+00,
          -3.4688e+00, -5.1953e-01],
         [ 5.0938e+00,  1.2000e+01,  1.1812e+01,  ...,  4.9062e+00,
           8.3125e+00,  5.9375e+00]],

        [[-9.5625e+00, -6.4375e+00, -1.5312e+00,  ..., -9.7500e+00,
          -4.8750e+00, -2.4531e+00],
         [-9.5625e+00, -6.4375e+00, -1.5312e+00,  ..., -9.7500e+00,
          -4.8750e+00, -2.4531e+00],
         [-9.5625e+00, -6.4375e+00, -1.5312e+00,  ..., -9.7500e+00,
          -4.8750e+00, -2.4531e+00],
         ...,
         [-1.0188e+01, -2.7031e+00,  3.0708e-04,  ..., -7.1875e+00,
          -5.8125e+00, -3.3906e+00],
         [-1.2625e+01,  1.8516e+00,  2.1562e+00,  ..., -4.5625e+00,
          -3.6406e+00, -3.7109e-01],
         [ 5.0000e+00,  1.2500e+01,  1.1938e+01,  ...,  5.2500e+00,
           8.1250e+00,  6.1250e+00]]], device='cuda:0'),)
(tensor([[[-9.5625e+00, -6.4375e+00, -1.5312e+00,  ..., -9.7500e+00,
          -4.8750e+00, -2.4531e+00],
         [-9.5625e+00, -6.4375e+00, -1.5312e+00,  ..., -9.7500e+00,
          -4.8750e+00, -2.4531e+00],
         [-9.5625e+00, -6.4375e+00, -1.5312e+00,  ..., -9.7500e+00,
          -4.8750e+00, -2.4531e+00],
         ...,
         [-9.1250e+00, -2.2969e+00,  6.0547e-01,  ..., -7.0312e+00,
          -5.8125e+00, -3.3438e+00],
         [-1.2125e+01,  2.2344e+00,  2.7812e+00,  ..., -4.2500e+00,
          -3.0625e+00, -3.2812e-01],
         [ 5.0938e+00,  1.2062e+01,  1.2062e+01,  ...,  5.0938e+00,
           8.0625e+00,  5.9062e+00]],

        [[-9.5625e+00, -6.4375e+00, -1.5312e+00,  ..., -9.7500e+00,
          -4.8750e+00, -2.4531e+00],
         [-9.5625e+00, -6.4375e+00, -1.5312e+00,  ..., -9.7500e+00,
          -4.8750e+00, -2.4531e+00],
         [-9.5625e+00, -6.4375e+00, -1.5312e+00,  ..., -9.7500e+00,
          -4.8750e+00, -2.4531e+00],
         ...,
         [-1.0625e+01, -3.0469e+00,  9.7046e-03,  ..., -7.3438e+00,
          -5.8750e+00, -4.0312e+00],
         [-1.1875e+01,  2.4531e+00,  3.1406e+00,  ..., -4.1562e+00,
          -3.0312e+00, -4.7266e-01],
         [ 5.1250e+00,  1.2000e+01,  1.1875e+01,  ...,  4.5625e+00,
           7.4688e+00,  5.9375e+00]]], device='cuda:0'),)
(tensor([[[ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         ...,
         [-10.0000,  -2.8438,   0.2793,  ...,  -7.5312,  -6.1875,  -3.7656],
         [-12.3125,   2.5625,   2.8594,  ...,  -4.0938,  -3.0156,  -0.2656],
         [  4.9688,  11.8125,  11.9375,  ...,   5.0938,   7.5625,   5.7812]],

        [[ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         ...,
         [ -9.1250,  -2.2188,   0.6094,  ...,  -7.0312,  -5.7812,  -3.2969],
         [-12.1250,   2.3750,   2.7969,  ...,  -4.1875,  -3.0000,  -0.2539],
         [  5.1875,  12.0625,  12.0000,  ...,   5.0938,   8.1250,   5.8125]]],
       device='cuda:0'),)
(tensor([[[-9.5625e+00, -6.4375e+00, -1.5312e+00,  ..., -9.7500e+00,
          -4.8750e+00, -2.4531e+00],
         [-9.5625e+00, -6.4375e+00, -1.5312e+00,  ..., -9.7500e+00,
          -4.8750e+00, -2.4531e+00],
         [-9.5625e+00, -6.4375e+00, -1.5312e+00,  ..., -9.7500e+00,
          -4.8750e+00, -2.4531e+00],
         ...,
         [-9.7500e+00, -2.7500e+00,  8.2397e-03,  ..., -7.1250e+00,
          -5.7188e+00, -3.3594e+00],
         [-1.2688e+01,  1.3359e+00,  2.0625e+00,  ..., -4.8125e+00,
          -3.8594e+00, -4.5508e-01],
         [ 5.0312e+00,  1.2562e+01,  1.2062e+01,  ...,  5.3750e+00,
           8.3750e+00,  6.5312e+00]],

        [[-9.5625e+00, -6.4375e+00, -1.5312e+00,  ..., -9.7500e+00,
          -4.8750e+00, -2.4531e+00],
         [-9.5625e+00, -6.4375e+00, -1.5312e+00,  ..., -9.7500e+00,
          -4.8750e+00, -2.4531e+00],
         [-9.5625e+00, -6.4375e+00, -1.5312e+00,  ..., -9.7500e+00,
          -4.8750e+00, -2.4531e+00],
         ...,
         [-1.0312e+01, -3.0156e+00, -2.8516e-01,  ..., -7.6250e+00,
          -6.2188e+00, -3.7344e+00],
         [-1.2125e+01,  2.0312e+00,  2.4375e+00,  ..., -4.4688e+00,
          -3.3438e+00, -6.4062e-01],
         [ 4.8750e+00,  1.2250e+01,  1.1750e+01,  ...,  5.0625e+00,
           8.3125e+00,  5.9688e+00]]], device='cuda:0'),)
(tensor([[[ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         ...,
         [-10.5625,  -3.1406,   0.0210,  ...,  -7.3750,  -6.0000,  -3.6250],
         [-12.3750,   1.5781,   2.7812,  ...,  -4.3125,  -3.4375,  -0.4180],
         [  5.4062,  12.0000,  12.3125,  ...,   4.9688,   8.1250,   6.2188]],

        [[ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         ...,
         [-10.3750,  -2.7969,   0.0288,  ...,  -7.3125,  -6.0938,  -4.0000],
         [-11.5000,   3.1562,   3.5312,  ...,  -3.5312,  -2.8906,   0.1050],
         [  5.0312,  11.8125,  11.5625,  ...,   4.3125,   7.3125,   5.9062]]],
       device='cuda:0'),)
(tensor([[[ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         ...,
         [ -9.6250,  -3.0156,   0.0408,  ...,  -7.1562,  -5.5625,  -3.5000],
         [-13.1875,   1.2891,   1.8281,  ...,  -4.7500,  -3.7031,  -0.5352],
         [  5.0000,  12.6250,  12.0000,  ...,   5.3125,   8.3750,   6.5000]],

        [[ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         ...,
         [-10.3125,  -2.9844,  -0.0835,  ...,  -7.5938,  -6.2500,  -3.6719],
         [-12.2500,   2.0000,   2.2500,  ...,  -4.4062,  -3.5781,  -0.4375],
         [  4.9688,  11.6250,  11.5000,  ...,   4.4375,   7.5625,   5.8438]]],
       device='cuda:0'),)
(tensor([[[ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         ...,
         [-10.3125,  -2.9062,  -0.0488,  ...,  -7.4688,  -6.1562,  -3.5938],
         [-12.5000,   1.9141,   2.2500,  ...,  -4.4062,  -3.5625,  -0.5391],
         [  4.8750,  11.9375,  11.6250,  ...,   4.6875,   7.6562,   5.9688]],

        [[ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         ...,
         [-10.6250,  -3.3438,  -0.1406,  ...,  -7.7500,  -6.4062,  -4.3750],
         [-11.8125,   2.7344,   2.6406,  ...,  -3.8750,  -3.2344,  -0.4453],
         [  5.0000,  11.6875,  11.6875,  ...,   4.8750,   7.7812,   5.5938]]],
       device='cuda:0'),)
(tensor([[[ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         ...,
         [ -9.9375,  -3.0625,  -0.2080,  ...,  -7.5312,  -6.2500,  -3.8594],
         [-12.4375,   2.1562,   2.5625,  ...,  -4.1250,  -3.2344,  -0.2334],
         [  4.9375,  12.0625,  11.9375,  ...,   5.1875,   8.1250,   6.3125]],

        [[ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         ...,
         [ -9.9375,  -2.3438,   0.4629,  ...,  -7.1562,  -5.8125,  -3.2188],
         [-12.4375,   1.9922,   3.2031,  ...,  -4.0625,  -3.1406,  -0.1553],
         [  5.1562,  12.3750,  12.3750,  ...,   5.1562,   8.0625,   6.5938]]],
       device='cuda:0'),)
(tensor([[[ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         ...,
         [-10.1875,  -2.8125,   0.2236,  ...,  -7.2812,  -6.0312,  -3.5938],
         [-11.8125,   2.0938,   3.1719,  ...,  -3.9844,  -3.0312,  -0.1465],
         [  5.2812,  11.9375,  12.0625,  ...,   5.0312,   7.8750,   6.2188]],

        [[ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         ...,
         [ -9.5625,  -2.9062,   0.1992,  ...,  -7.4375,  -5.9688,  -3.7031],
         [-12.1250,   1.6250,   2.4844,  ...,  -4.7500,  -3.6406,  -0.6406],
         [  5.0000,  12.6250,  12.0000,  ...,   5.2188,   8.2500,   6.3125]]],
       device='cuda:0'),)
(tensor([[[ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         ...,
         [-10.4375,  -2.8906,   0.1729,  ...,  -7.1562,  -5.9062,  -3.5156],
         [-12.1875,   1.7109,   2.7969,  ...,  -4.1875,  -3.4219,  -0.3848],
         [  5.2812,  12.0000,  12.0625,  ...,   5.0312,   8.1875,   6.2812]],

        [[ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         ...,
         [-10.0625,  -2.9375,  -0.2412,  ...,  -7.3750,  -5.8125,  -3.6094],
         [-13.0000,   1.8750,   2.3125,  ...,  -4.4375,  -3.2500,  -0.5547],
         [  4.9375,  12.3750,  11.9375,  ...,   5.0938,   8.5625,   6.2188]]],
       device='cuda:0'),)
(tensor([[[ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         ...,
         [-10.6250,  -3.2188,  -0.2676,  ...,  -7.3750,  -6.0625,  -3.8125],
         [-12.4375,   1.8906,   2.2188,  ...,  -4.3750,  -3.3438,  -0.4824],
         [  5.0625,  12.3750,  11.9375,  ...,   5.3750,   8.4375,   6.0000]],

        [[ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         ...,
         [ -9.9375,  -2.6719,  -0.2598,  ...,  -7.2500,  -5.8750,  -3.3438],
         [-12.3750,   2.2188,   2.5625,  ...,  -4.3438,  -3.2969,  -0.2656],
         [  5.0312,  12.4375,  12.0625,  ...,   5.0625,   8.3125,   6.1875]]],
       device='cuda:0'),)
(tensor([[[-9.5625e+00, -6.4375e+00, -1.5312e+00,  ..., -9.7500e+00,
          -4.8750e+00, -2.4531e+00],
         [-9.5625e+00, -6.4375e+00, -1.5312e+00,  ..., -9.7500e+00,
          -4.8750e+00, -2.4531e+00],
         [-9.5625e+00, -6.4375e+00, -1.5312e+00,  ..., -9.7500e+00,
          -4.8750e+00, -2.4531e+00],
         ...,
         [-1.0375e+01, -3.0625e+00, -2.7930e-01,  ..., -7.7188e+00,
          -6.3438e+00, -3.7812e+00],
         [-1.2250e+01,  2.0469e+00,  2.5156e+00,  ..., -4.5000e+00,
          -3.3281e+00, -5.7422e-01],
         [ 4.9375e+00,  1.2188e+01,  1.1938e+01,  ...,  4.9375e+00,
           8.2500e+00,  6.0312e+00]],

        [[-9.5625e+00, -6.4375e+00, -1.5312e+00,  ..., -9.7500e+00,
          -4.8750e+00, -2.4531e+00],
         [-9.5625e+00, -6.4375e+00, -1.5312e+00,  ..., -9.7500e+00,
          -4.8750e+00, -2.4531e+00],
         [-9.5625e+00, -6.4375e+00, -1.5312e+00,  ..., -9.7500e+00,
          -4.8750e+00, -2.4531e+00],
         ...,
         [-9.8125e+00, -2.9219e+00, -1.1063e-03,  ..., -7.0938e+00,
          -5.8125e+00, -3.9062e+00],
         [-1.1375e+01,  2.8906e+00,  3.3750e+00,  ..., -3.5156e+00,
          -2.7188e+00, -1.5820e-01],
         [ 5.2500e+00,  1.2000e+01,  1.1875e+01,  ...,  5.2500e+00,
           8.1875e+00,  5.7812e+00]]], device='cuda:0'),)
(tensor([[[ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         ...,
         [ -9.6250,  -2.1250,   0.5078,  ...,  -6.9375,  -5.7500,  -3.0156],
         [-11.7500,   2.2188,   3.2812,  ...,  -3.9219,  -3.0781,   0.1816],
         [  5.0938,  12.2500,  12.3750,  ...,   5.1250,   7.8750,   6.4375]],

        [[ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         ...,
         [ -9.5625,  -2.9219,  -0.0898,  ...,  -7.3438,  -5.9375,  -3.6406],
         [-13.1250,   1.9219,   2.3281,  ...,  -4.3750,  -3.4062,  -0.2773],
         [  5.0625,  12.1875,  12.0625,  ...,   5.0625,   8.0625,   6.4375]]],
       device='cuda:0'),)
(tensor([[[ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         ...,
         [-10.6250,  -2.8750,   0.0267,  ...,  -7.3438,  -6.0000,  -3.8438],
         [-11.5625,   2.8125,   3.2031,  ...,  -3.7812,  -2.9844,   0.0781],
         [  4.7188,  11.9375,  11.5625,  ...,   4.5000,   7.3750,   5.9375]],

        [[ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         [ -9.5625,  -6.4375,  -1.5312,  ...,  -9.7500,  -4.8750,  -2.4531],
         ...,
         [ -9.5625,  -2.4062,   0.1875,  ...,  -7.1562,  -5.7188,  -3.5625],
         [-12.0625,   2.7500,   2.8281,  ...,  -4.0000,  -2.6250,  -0.0718],
         [  5.2188,  12.0000,  12.1875,  ...,   5.1250,   8.3125,   5.8750]]],
       device='cuda:0'),)
{'eval_loss': 0.0007647691527381539, 'eval_runtime': 34.9133, 'eval_samples_per_second': 6.76, 'eval_steps_per_second': 0.43, 'epoch': 0.93}

======================================== [DEBUGGING AT GLOBAL STEP: 110] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is correct because the relative positions of three faces match the cube shown in the left image.', 'C': 'Option C is incorrect because the squares with asymmetric patterns have been rotated.', 'A': 'Option A is incorrect because the squares with asymmetric patterns have been rotated.', 'B': 'Option B is incorrect because two faces have swapped positions.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is correct because the relative positions of three faces match the cube shown in the left image.', 'C': 'Option C is incorrect because the squares with asymmetric patterns have been rotated.', 'A': 'Option A is incorrect because the squares with asymmetric patterns have been rotated.', 'B': 'Option B is incorrect because two faces have swapped positions.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 111/118 [35:28<03:00, 25.79s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 111] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is incorrect because holes in row 2 are missing.', 'C': 'Option C is incorrect because extra holes appear in row 3.', 'A': 'Option A is incorrect because holes that should appear in row 2 appear in row 3.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is incorrect because holes in row 2 are missing.', 'C': 'Option C is incorrect because extra holes appear in row 3.', 'A': 'Option A is incorrect because holes that should appear in row 2 appear in row 3.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 112/118 [35:43<02:14, 22.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 112] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'The green rod only drives the blue gear to rotate clockwise.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'The green rod only drives the blue gear to rotate clockwise.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 113/118 [35:57<01:39, 19.99s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 113] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': "In this case, the green shaft rotates in the same direction as the green gear's own rotation."} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': "In this case, the green shaft rotates in the same direction as the green gear's own rotation."} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 114/118 [36:11<01:13, 18.32s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 114] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'In this system, the pink rod and the orange object are effectively meshed, so the orange object rotates in the opposite direction of the pink rod.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'In this system, the pink rod and the orange object are effectively meshed, so the orange object rotates in the opposite direction of the pink rod.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 115/118 [36:26<00:51, 17.20s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 115] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'C': 'Option C is incorrect because it is the cross-section made by a plane perpendicular to the YZ plane and rotated 135 degrees around the x-axis.', 'D': 'Option D is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'C': 'Option C is incorrect because it is the cross-section made by a plane perpendicular to the YZ plane and rotated 135 degrees around the x-axis.', 'D': 'Option D is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 116/118 [36:41<00:32, 16.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 116] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is correct because the initial state can be transformed into the target state.', 'ACD': 'Option BCD is incorrect because the initial state cannot be transformed into the target state.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is correct because the initial state can be transformed into the target state.', 'ACD': 'Option BCD is incorrect because the initial state cannot be transformed into the target state.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 117/118 [36:55<00:15, 15.76s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


======================================== [DEBUGGING AT GLOBAL STEP: 117] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because one cube is missing, resulting in an incorrect cube stack shape.', 'B': 'Option B is incorrect because one cube is missing, resulting in an incorrect cube stack shape.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is incorrect because one cube is missing, resulting in an incorrect cube stack shape.', 'B': 'Option B is incorrect because one cube is missing, resulting in an incorrect cube stack shape.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate output for debugging: 'NoneType' object has no attribute 'shape'[0m
--- Full Traceback ---
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 264, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
----------------------
===========================================================================================================
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 118/118 [37:09<00:00, 15.28s/it]2025-09-29 23:03:11,666 - INFO - vq_config is None. initializing the ChameleonVQConfig with default values.
2025-09-29 23:03:11,666 - INFO - vq_config is None. initializing the ChameleonVQConfig with default values.
2025-09-29 23:03:11,700 - INFO - vq_config is None. initializing the ChameleonVQConfig with default values.
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 118/118 [37:48<00:00, 19.23s/it]

{'train_runtime': 2270.849, 'train_samples_per_second': 0.416, 'train_steps_per_second': 0.052, 'train_loss': 1.8149843772841712, 'epoch': 1.0}
2025-09-29 23:03:40,089 - INFO -

‚úÖ [Success] Training completed successfully!
2025-09-29 23:03:40,089 - INFO - Saving final model...
2025-09-29 23:03:51,704 - INFO - vq_config is None. initializing the ChameleonVQConfig with default values.
2025-09-29 23:03:51,704 - INFO - vq_config is None. initializing the ChameleonVQConfig with default values.
2025-09-29 23:03:51,739 - INFO - vq_config is None. initializing the ChameleonVQConfig with default values.
2025-09-29 23:04:12,597 - INFO - Final model and processor saved to /data1/oujingfeng/project/twgi/checkpoints/orthus-7b-sft-v4
