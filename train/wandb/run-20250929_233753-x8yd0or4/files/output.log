[34m[1mwandb[0m: [33mWARNING[0m Serializing object of type dict that is 1922480 bytes
  0%|                                                                                                                                | 0/118 [00:00<?, ?it/s]2025-09-29 23:37:56,125 - WARNING - `use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.

======================================== [DEBUGGING AT GLOBAL STEP: 0] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because it is a vertically mirrored version of the back-bottom-left view.', 'C': 'Option C is incorrect because it is a horizontally mirrored version of the front-top-right view.', 'ABCD': 'Assuming the bottom face is the first cell in the second row of the net, then after folding, the front face is cyan, the back face is red, the left face is green, the right face is blue, the top face is yellow, the bottom face is pink.', 'B': 'Option B is correct because it shows the back-bottom-right view.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
[91mCould not generate and log output at step 0: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
  1%|‚ñà                                                                                                                       | 1/118 [00:18<36:12, 18.57s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 1] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'The counterclockwise rotation of the green object drives the orange object to rotate clockwise, which in turn pulls the weight upward.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 1: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
  2%|‚ñà‚ñà                                                                                                                      | 2/118 [00:33<32:10, 16.64s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 2] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'C': 'Option C is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 2: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
  3%|‚ñà‚ñà‚ñà                                                                                                                     | 3/118 [00:49<30:42, 16.02s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 3] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option D is correct because it shows the back-bottom-right view.', 'B': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option B is incorrect because it includes rotated non-symmetric faces.', 'C': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option C is incorrect because it includes rotated non-symmetric faces.', 'A': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option A is incorrect because it is a horizontally mirrored version of the back-top-left view.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 3: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
  3%|‚ñà‚ñà‚ñà‚ñà                                                                                                                    | 4/118 [01:04<29:37, 15.59s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 4] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because the initial arrow can be transformed into the final arrow.', 'BDA': 'Option BDA is incorrect because the initial arrow cannot be transformed into the final arrow.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 4: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
  4%|‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                                   | 5/118 [01:19<29:08, 15.47s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 5] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is incorrect because holes in column 1 are missing.', 'A': 'Option A is incorrect because extra holes appear in column 2.', 'D': 'Option D is incorrect because holes that should appear in column 1 appear in column 2.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 5: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
  5%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                                  | 6/118 [01:34<28:40, 15.36s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 6] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given three views, at least 4 cubes and at most 4 cubes are required to satisfy the constraints.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 6: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
  6%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                                 | 7/118 [01:49<28:10, 15.23s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 7] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because it was obtained by rotating the original image 180 degrees.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it horizontally.', 'B': 'Option B is incorrect because it was obtained by rotating the original image 90 degrees and then flipping it vertically.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 7: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                               | 8/118 [02:04<27:53, 15.21s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 8] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is incorrect because one cube is missing, resulting in an incorrect cube stack shape.', 'C': 'Option C is incorrect because one cube is missing, resulting in an incorrect cube stack shape.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 8: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                              | 9/118 [02:19<27:29, 15.13s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 9] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'CDB': 'Option CDB is incorrect because this net could be a valid net for the given cube, as the positions of cyan, pink, and blue match the shown cube.', 'A': 'Option A is correct because this net cannot be a valid net for the given cube, as the positions of yellow and cyan are reversed.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m cube cube[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 9: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
  8%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                             | 10/118 [02:34<27:03, 15.03s/it]
{'loss': 19.7621, 'grad_norm': 68.2237777709961, 'learning_rate': 4.965903258506806e-06, 'epoch': 0.08}
(tensor([[[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -2.8438,  -1.6953,   5.1875,  ...,  -6.4688,  -2.7031,  -2.3594],
         [ -2.1562,  -1.2812,   5.6875,  ...,  -5.9062,  -2.0156,  -1.5781],
         [ -1.7031,  -1.3750,   6.5625,  ...,  -5.7188,  -0.5391,  -0.9141]],

        [[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -3.1562,  -1.8516,   4.9688,  ...,  -7.0625,  -3.0625,  -3.4219],
         [ -2.4688,  -1.7188,   5.7500,  ...,  -6.0000,  -2.1094,  -2.2812],
         [ -1.6172,  -1.5469,   6.6562,  ...,  -5.7812,  -0.6641,  -1.4375]]],
       device='cuda:0'),)
 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                        | 2/15 [00:02<00:15,  1.19s/it]
(tensor([[[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -2.9062,  -2.0156,   5.3438,  ...,  -6.5625,  -2.6406,  -2.2188],
         [ -2.0156,  -1.4688,   5.9375,  ...,  -5.9062,  -1.8984,  -1.2812],
         [ -1.6250,  -1.4922,   6.6875,  ...,  -5.7500,  -0.5664,  -0.8359]],

        [[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -3.2812,  -2.3281,   5.0312,  ...,  -6.6250,  -3.0469,  -3.0781],
         [ -2.6250,  -1.8594,   5.5938,  ...,  -5.9375,  -2.2344,  -2.0938],
         [ -1.7344,  -1.5625,   6.6875,  ...,  -5.5000,  -0.7539,  -1.2578]]],
       device='cuda:0'),)
(tensor([[[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -3.1719,  -2.4844,   4.8750,  ...,  -6.8750,  -3.3438,  -3.8906],
         [ -2.5938,  -2.1094,   5.2812,  ...,  -6.3750,  -2.5312,  -2.9688],
         [ -1.7500,  -2.0312,   6.3438,  ...,  -5.8750,  -0.8320,  -1.3906]],

        [[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -3.2188,  -2.2031,   4.9062,  ...,  -6.4688,  -2.6406,  -3.9844],
         [ -2.7812,  -1.9922,   5.3125,  ...,  -5.9375,  -2.1250,  -3.1719],
         [ -1.5156,  -1.6797,   6.3438,  ...,  -5.2188,  -0.5391,  -2.3438]]],
       device='cuda:0'),)
(tensor([[[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -2.5469,  -2.4531,   4.8125,  ...,  -6.7500,  -3.2812,  -4.3125],
         [ -2.1875,  -1.9844,   5.3750,  ...,  -6.0938,  -2.4062,  -3.0625],
         [ -1.4062,  -1.9453,   6.4062,  ...,  -5.8125,  -0.7578,  -2.2344]],

        [[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -3.3750,  -2.4688,   4.8125,  ...,  -7.0312,  -3.3750,  -3.8438],
         [ -2.8125,  -2.0781,   5.1562,  ...,  -6.5000,  -2.5469,  -2.9219],
         [ -2.0781,  -2.0000,   6.2188,  ...,  -6.0625,  -0.7617,  -1.2344]]],
       device='cuda:0'),)
(tensor([[[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -3.3750,  -2.4219,   4.9375,  ...,  -6.9062,  -2.7344,  -3.0312],
         [ -2.9531,  -2.0312,   5.4375,  ...,  -6.3125,  -2.0469,  -2.2188],
         [ -2.1719,  -2.0000,   6.2500,  ...,  -5.9062,  -0.6680,  -1.6328]],

        [[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -3.4219,  -2.1719,   5.0000,  ...,  -6.7188,  -2.8594,  -3.0625],
         [ -2.8125,  -1.7188,   5.4688,  ...,  -6.0625,  -1.9219,  -2.3125],
         [ -2.2031,  -1.6953,   6.5000,  ...,  -5.6562,  -0.3066,  -1.2891]]],
       device='cuda:0'),)
(tensor([[[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -3.0000,  -2.2656,   5.3125,  ...,  -6.6250,  -2.9375,  -2.8906],
         [ -2.3750,  -1.8984,   5.9375,  ...,  -6.0938,  -2.0938,  -2.0625],
         [ -1.5625,  -1.7031,   6.7500,  ...,  -5.7812,  -0.6562,  -1.3047]],

        [[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -3.3906,  -2.4688,   4.6250,  ...,  -6.6250,  -2.7656,  -3.9062],
         [ -2.8125,  -2.0312,   5.0938,  ...,  -6.0625,  -2.0781,  -3.0469],
         [ -1.5859,  -1.7578,   6.0625,  ...,  -5.4688,  -0.6719,  -2.2344]]],
       device='cuda:0'),)
(tensor([[[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -3.5000,  -2.3281,   5.0625,  ...,  -6.7188,  -2.6406,  -3.2344],
         [ -2.9844,  -1.9141,   5.5625,  ...,  -6.1250,  -1.9531,  -2.3750],
         [ -2.0781,  -1.8438,   6.3750,  ...,  -5.6562,  -0.4395,  -1.6172]],

        [[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -2.8906,  -2.0938,   5.1562,  ...,  -6.6250,  -2.7188,  -2.9844],
         [ -2.3438,  -1.7812,   5.6250,  ...,  -6.1250,  -1.9844,  -2.1094],
         [ -1.5469,  -1.7188,   6.6875,  ...,  -5.7188,  -0.5273,  -1.2891]]],
       device='cuda:0'),)
(tensor([[[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -2.8906,  -2.1875,   5.1250,  ...,  -6.5938,  -2.7344,  -3.0469],
         [ -2.3750,  -1.8516,   5.5938,  ...,  -6.1250,  -2.0000,  -2.2344],
         [ -1.4297,  -1.7891,   6.6250,  ...,  -5.7188,  -0.5977,  -1.3828]],

        [[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -3.4844,  -2.0781,   5.0312,  ...,  -6.8438,  -2.9219,  -4.0938],
         [ -3.2031,  -1.7188,   5.3438,  ...,  -6.4062,  -2.3594,  -3.3906],
         [ -2.3438,  -1.9531,   6.4375,  ...,  -6.0312,  -0.7305,  -2.2031]]],
       device='cuda:0'),)
(tensor([[[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -2.8750,  -2.3594,   5.0938,  ...,  -7.1250,  -2.6719,  -3.0625],
         [ -2.3594,  -1.9688,   5.5000,  ...,  -6.4688,  -1.9453,  -2.0938],
         [ -1.9141,  -1.8594,   6.3438,  ...,  -5.9062,  -0.5391,  -1.2656]],

        [[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -3.2344,  -2.3281,   5.0938,  ...,  -6.5312,  -2.8125,  -3.3594],
         [ -2.7500,  -2.0156,   5.6875,  ...,  -5.9062,  -2.1562,  -2.4688],
         [ -2.1719,  -1.7578,   6.4062,  ...,  -5.4062,  -0.5352,  -1.4609]]],
       device='cuda:0'),)
(tensor([[[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -3.0781,  -2.4062,   5.0000,  ...,  -6.7812,  -2.8281,  -3.2656],
         [ -2.4375,  -1.9531,   5.5625,  ...,  -6.0938,  -2.0156,  -2.3125],
         [ -2.0312,  -1.8281,   6.2812,  ...,  -5.6875,  -0.4863,  -1.5000]],

        [[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -3.5312,  -2.2656,   4.8438,  ...,  -6.9375,  -2.9062,  -3.2500],
         [ -2.8438,  -1.8516,   5.3750,  ...,  -6.2812,  -2.0781,  -2.3906],
         [ -2.2500,  -1.9375,   6.3125,  ...,  -5.9375,  -0.5000,  -1.4375]]],
       device='cuda:0'),)
(tensor([[[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -2.9531,  -2.2969,   5.2812,  ...,  -6.6875,  -2.9062,  -2.9219],
         [ -2.4531,  -1.9609,   5.8438,  ...,  -6.2188,  -2.1094,  -2.0625],
         [ -1.7266,  -1.7266,   6.6250,  ...,  -5.7812,  -0.6133,  -1.2031]],

        [[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -3.8594,  -2.2031,   5.2188,  ...,  -6.5938,  -2.6719,  -2.9219],
         [ -3.1094,  -1.7344,   5.8750,  ...,  -5.8750,  -1.8438,  -2.1250],
         [ -2.1719,  -1.6250,   6.6562,  ...,  -5.5000,  -0.2197,  -1.3125]]],
       device='cuda:0'),)
(tensor([[[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -2.9844,  -2.3438,   5.0938,  ...,  -6.5938,  -2.9375,  -2.9219],
         [ -2.1406,  -1.8594,   5.6562,  ...,  -5.9062,  -2.1094,  -1.9062],
         [ -1.3828,  -1.7188,   6.6562,  ...,  -5.6875,  -0.6250,  -1.2188]],

        [[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -3.7031,  -2.2969,   5.0312,  ...,  -6.7188,  -2.7969,  -2.8594],
         [ -3.1719,  -1.8750,   5.6250,  ...,  -6.0938,  -1.9531,  -2.0000],
         [ -2.2812,  -1.7344,   6.4688,  ...,  -5.7188,  -0.4668,  -1.1953]]],
       device='cuda:0'),)
(tensor([[[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -3.3750,  -2.0781,   5.1250,  ...,  -6.7188,  -2.8125,  -2.9219],
         [ -2.7812,  -1.6172,   5.6250,  ...,  -6.0938,  -1.9062,  -2.1094],
         [ -2.0469,  -1.6797,   6.6250,  ...,  -5.7500,  -0.3828,  -1.1406]],

        [[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -3.2500,  -1.9766,   5.1562,  ...,  -6.7812,  -2.9375,  -3.4844],
         [ -3.0000,  -1.6562,   5.5625,  ...,  -6.2500,  -2.2812,  -2.7812],
         [ -1.9297,  -1.9219,   6.4688,  ...,  -5.9375,  -0.8125,  -2.0312]]],
       device='cuda:0'),)
(tensor([[[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -3.3750,  -2.2969,   4.9062,  ...,  -6.7188,  -2.8750,  -3.3438],
         [ -2.8906,  -1.8906,   5.4688,  ...,  -6.0312,  -2.0938,  -2.4844],
         [ -2.6562,  -1.7578,   6.0938,  ...,  -5.6250,  -0.6250,  -1.5547]],

        [[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -3.0312,  -2.2344,   5.0938,  ...,  -6.9688,  -2.6406,  -3.4062],
         [ -2.4375,  -1.8516,   5.5938,  ...,  -6.2812,  -2.0156,  -2.4531],
         [ -1.7812,  -1.7266,   6.3750,  ...,  -5.7500,  -0.5664,  -1.5391]]],
       device='cuda:0'),)
(tensor([[[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -3.3594,  -2.2656,   4.9375,  ...,  -6.4375,  -2.6875,  -3.3438],
         [ -2.9844,  -1.9141,   5.2500,  ...,  -6.0000,  -2.1250,  -2.6719],
         [ -1.8438,  -1.6641,   6.1562,  ...,  -5.3438,  -0.6484,  -1.8594]],

        [[-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         [-18.5000, -16.1250,  -8.9375,  ..., -17.8750, -12.8750, -10.8750],
         ...,
         [ -3.4375,  -2.4844,   5.0000,  ...,  -7.0625,  -3.0625,  -3.5000],
         [ -2.7656,  -2.1562,   5.3750,  ...,  -6.5312,  -2.3438,  -2.6719],
         [ -2.0625,  -1.9844,   6.3438,  ...,  -6.0312,  -0.6289,  -1.5156]]],
       device='cuda:0'),)
{'eval_loss': 5.270649433135986, 'eval_runtime': 35.3332, 'eval_samples_per_second': 6.679, 'eval_steps_per_second': 0.425, 'epoch': 0.08}

======================================== [DEBUGGING AT GLOBAL STEP: 10] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option A is correct because it shows the back-top-left view.', 'D': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option D is incorrect because it includes rotated non-symmetric faces.', 'B': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option B is incorrect because it includes rotated non-symmetric faces.', 'C': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option C is incorrect because it is a horizontally mirrored version of the back-top-right view.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m''''''' second row right face its rightmetry''' cell the row net right face is its rightsymmetric faces' bottom face first cell the second row net right face is its rightrored mirtopleft answeransweransweransweranswer>answeransweranswer[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 10: 'NoneType' object has no attribute 'shape'[0m
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                            | 11/118 [03:25<46:25, 26.03s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 11] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is correct because the cube stack can be obtained by rotating the original stack around the y-axis by 270 degrees.', 'C': 'Option C is incorrect because it is a horizontally mirrored version of the original cube stack.', 'B': 'Option B is incorrect because it was obtained by removing one small cube from the original stack.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m''''''OptionOptionA incorrect incorrect cube cube cube cube cube cube cube cube cube cube cube cube cube axis'''''''''OptionOptionC incorrect incorrect incorrect incorrect incorrect horizontallyrored mir mir mir cube cube cube cube''''''''''OptionOptionB incorrect incorrect incorrect incorrect incorrect cube cube cube cube cube cube cube'''' answer answer answeransweransweransweranswer>>>answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 11: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                           | 12/118 [03:40<40:05, 22.69s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 12] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given three views, at least 12 cubes and at most 17 cubes are required to satisfy the constraints.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABC''''' Given given, givenleastleast1 cubes cubes cubes least cubes cubes cubes cubes cubes cubes cubes satisfy satisfy constraints constraints constraints''' answer answer answer answer<answer>><<answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 12: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 11%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                          | 13/118 [03:55<35:34, 20.33s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 13] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because holes in row 2 are missing.', 'B': 'Option B is incorrect because extra holes appear in row 3.', 'A': 'Option A is incorrect because holes that should appear in row 2 appear in row 3.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'''::'Option C is incorrect because holes row row  are missing.'''''':''Option B is incorrect because extra holes row row rows''' '''::'Option A is incorrect because holes appear in row row row appear in row row.''} The final answer is is<answer>D<<answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 13: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                         | 14/118 [04:10<32:27, 18.73s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 14] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is correct because the initial state can be transformed into the target state.', 'DAC': 'Option DAC is incorrect because the initial state cannot be transformed into the target state.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m' B'::'Option B is correct because the initial state can can transformed into into target state.', 'DAC': 'Option DAC is incorrect because the initial state cannot can transformed into into target state''} The final answer is is<answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 14: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                       | 15/118 [04:25<30:07, 17.55s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 15] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'The counterclockwise rotation of the orange shaft drives the internal boundary of the green object back and forth, causing it to move horizontally.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': ' The counterclock clock rotation of the orange shaft drives the internal boundary of the green object back and forth, causing it to move horizontally.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 15: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                      | 16/118 [04:40<28:34, 16.81s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 16] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because the squares with asymmetric patterns have been rotated, so it cannot form the cube shown in the left image.', 'B': 'Option B is incorrect because the relative positions of three faces match the cube shown in the left image.', 'A': 'Option A is incorrect because the relative positions of three faces match the cube shown in the left image.', 'D': 'Option D is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is correct because the squares with asymmetric patterns have been rotated, so it cannot form the cube shown in in left image.', 'B': 'Option B is incorrect because the relative positions of three faces match the cube shown in in left image.',,'A': 'Option A is incorrect because the relative positions of three faces match the cube shown in in left image.', 'D': 'OptionD is incorrect because the relative positions of three faces match the cube shown in in left image.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 16: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                     | 17/118 [04:55<27:19, 16.23s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 17] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Assuming the bottom face is the first cell in the second row of the net, then after folding, the front face is pink, the back face is red, the left face is green, the right face is blue, the top face is yellow, the bottom face is cyan.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Ass assuming the bottom face is the first cell in the second row of the net, then after folding, the front face is pink, the back face is red, the left face is green, the right face is blue, the top face is yellow, the bottom face is cyan.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 17: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                    | 18/118 [05:10<26:32, 15.92s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 18] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because it was obtained by rotating the original image 270 degrees.', 'B': 'Option B is incorrect because it was obtained by rotating the asymmetric patterns in the image.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it horizontally.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is correct because it was obtained by rotating the original image 270 degrees.', 'B': 'Option B is incorrect because it was obtained by rotating the asymmetric patterns in the image.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it horizontally.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 18: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                   | 19/118 [05:25<25:46, 15.62s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 19] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given three views, at least 13 cubes and at most 15 cubes are required to satisfy the constraints.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given three views, at least 13 cubes and at most 15 cubes are required to satisfy the constraints.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 19: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                  | 20/118 [05:40<25:16, 15.47s/it]
{'loss': 1.4658, 'grad_norm': 1.9726135730743408, 'learning_rate': 4.760892901743944e-06, 'epoch': 0.17}
(tensor([[[-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         ...,
         [ -7.6875,   0.2617,   2.7656,  ...,  -6.6562,  -4.2500,  -3.3125],
         [ -7.4062,   9.2500,   6.7500,  ...,  -0.0928,   1.2812,   3.2031],
         [  0.9414,  10.9375,   8.6875,  ...,   4.0625,   6.9062,   4.8750]],

        [[-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         ...,
         [ -7.5312,   0.6758,   2.7031,  ...,  -6.3438,  -4.0000,  -2.6562],
         [ -6.6562,   9.9375,   7.0625,  ...,   0.4199,   1.9375,   3.6406],
         [  0.8672,  10.6875,   8.5625,  ...,   3.9688,   6.5625,   4.6250]]],
       device='cuda:0'),)
 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                        | 2/15 [00:02<00:15,  1.19s/it]
(tensor([[[-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         ...,
         [ -8.0625,  -0.1494,   2.5156,  ...,  -6.5312,  -4.3125,  -3.5312],
         [ -7.6250,   9.0625,   6.6875,  ...,   0.0160,   1.2891,   3.2812],
         [  0.6641,  11.0000,   8.8125,  ...,   4.3438,   7.0000,   5.2188]],

        [[-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         ...,
         [ -8.0625,   0.5195,   2.4375,  ...,  -6.6250,  -4.0312,  -2.8906],
         [ -7.3125,   9.2500,   6.5000,  ...,  -0.2793,   1.4922,   3.7969],
         [ -0.6992,  10.2500,   8.3125,  ...,   4.3750,   5.8750,   5.0938]]],
       device='cuda:0'),)
(tensor([[[-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         ...,
         [ -6.5625,   2.6094,   3.8906,  ...,  -5.2500,  -2.7656,  -1.4297],
         [ -6.0625,  10.1875,   7.7500,  ...,   0.4395,   1.9453,   4.0312],
         [  0.7266,  11.3125,   9.1250,  ...,   4.5938,   6.5938,   5.1875]],

        [[-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         ...,
         [ -8.6250,  -0.0325,   2.0781,  ...,  -6.4375,  -4.0000,  -3.2344],
         [ -7.6875,   8.7500,   6.0938,  ...,  -0.1211,   1.1641,   3.0156],
         [  0.5352,  10.3750,   8.1250,  ...,   4.4375,   6.3438,   5.2812]]],
       device='cuda:0'),)
(tensor([[[-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         ...,
         [ -8.5625,   1.1719,   2.4219,  ...,  -6.5000,  -4.3125,  -2.7344],
         [ -7.7500,   8.8750,   6.5312,  ...,  -0.5430,   0.7148,   2.8594],
         [  0.1211,  10.6875,   8.6250,  ...,   4.0312,   6.1250,   4.6875]],

        [[-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         ...,
         [ -6.4062,   2.6875,   3.8906,  ...,  -5.1875,  -2.6562,  -1.4453],
         [ -6.0000,  10.1875,   7.7812,  ...,   0.4297,   1.9688,   4.0312],
         [  0.8281,  11.2500,   9.1250,  ...,   4.5625,   6.6875,   5.1875]]],
       device='cuda:0'),)
(tensor([[[-1.3688e+01, -9.7500e+00, -4.5938e+00,  ..., -1.2938e+01,
          -7.5938e+00, -5.3438e+00],
         [-1.3688e+01, -9.7500e+00, -4.5938e+00,  ..., -1.2938e+01,
          -7.5938e+00, -5.3438e+00],
         [-1.3688e+01, -9.7500e+00, -4.5938e+00,  ..., -1.2938e+01,
          -7.5938e+00, -5.3438e+00],
         ...,
         [-8.2500e+00,  3.9258e-01,  2.5625e+00,  ..., -6.6250e+00,
          -3.9688e+00, -2.9688e+00],
         [-7.0625e+00,  9.8125e+00,  6.8750e+00,  ..., -4.7913e-03,
           1.7422e+00,  3.5938e+00],
         [ 2.2168e-01,  1.0938e+01,  8.5625e+00,  ...,  4.7500e+00,
           6.2500e+00,  5.0938e+00]],

        [[-1.3688e+01, -9.7500e+00, -4.5938e+00,  ..., -1.2938e+01,
          -7.5938e+00, -5.3438e+00],
         [-1.3688e+01, -9.7500e+00, -4.5938e+00,  ..., -1.2938e+01,
          -7.5938e+00, -5.3438e+00],
         [-1.3688e+01, -9.7500e+00, -4.5938e+00,  ..., -1.2938e+01,
          -7.5938e+00, -5.3438e+00],
         ...,
         [-7.8125e+00,  7.2656e-01,  2.5312e+00,  ..., -6.5938e+00,
          -3.7812e+00, -2.7812e+00],
         [-7.8125e+00,  9.5000e+00,  6.6875e+00,  ...,  5.3711e-03,
           1.6094e+00,  3.0625e+00],
         [-1.4062e-01,  1.0688e+01,  8.3750e+00,  ...,  4.1250e+00,
           6.6250e+00,  4.4062e+00]]], device='cuda:0'),)
(tensor([[[-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         ...,
         [ -7.7500,   0.2373,   2.5938,  ...,  -6.2812,  -3.9062,  -2.9062],
         [ -7.0938,   9.5625,   7.0938,  ...,   0.3223,   1.8516,   3.5469],
         [  0.7148,  10.5625,   8.6875,  ...,   4.0312,   6.4375,   4.8125]],

        [[-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         ...,
         [ -8.6875,  -0.4238,   1.6797,  ...,  -6.8750,  -4.4688,  -3.6719],
         [ -8.1875,   8.5625,   5.8125,  ...,  -0.4824,   0.9609,   3.0469],
         [  1.2031,  10.6875,   8.3125,  ...,   4.3750,   6.5625,   6.0312]]],
       device='cuda:0'),)
(tensor([[[-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         ...,
         [ -8.2500,   0.5742,   2.6406,  ...,  -6.4688,  -3.7656,  -2.7188],
         [ -6.7812,  10.0000,   7.1562,  ...,   0.2500,   2.0312,   3.5000],
         [  0.6836,  11.0625,   8.6875,  ...,   4.7500,   6.5625,   5.2500]],

        [[-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         ...,
         [ -7.7188,   0.5625,   2.5156,  ...,  -6.5000,  -4.0625,  -2.7188],
         [ -6.7812,   9.6250,   6.8750,  ...,   0.2012,   1.7266,   3.4062],
         [  0.7539,  10.3750,   8.3125,  ...,   3.7500,   6.2500,   4.7188]]],
       device='cuda:0'),)
(tensor([[[-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         ...,
         [ -7.7500,   0.4961,   2.4531,  ...,  -6.5938,  -4.0625,  -2.8594],
         [ -6.9688,   9.5000,   6.8438,  ...,   0.1475,   1.6719,   3.3906],
         [  0.6328,  10.3750,   8.3125,  ...,   3.8438,   6.1875,   4.7188]],

        [[-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         ...,
         [ -7.6250,   1.2266,   3.0625,  ...,  -5.7812,  -3.7500,  -2.4531],
         [ -7.3125,   9.5625,   6.8438,  ...,   0.4180,   1.2500,   3.4531],
         [  0.3516,  11.1875,   8.5625,  ...,   4.5625,   6.5938,   5.0938]]],
       device='cuda:0'),)
(tensor([[[-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         ...,
         [ -7.4062,   0.8242,   2.6875,  ...,  -6.1875,  -3.7656,  -2.6562],
         [ -7.1250,   9.8750,   7.1250,  ...,   0.4473,   1.9453,   3.5625],
         [  0.6836,  11.0625,   8.6875,  ...,   4.2188,   6.4062,   5.2812]],

        [[-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         ...,
         [ -7.3438,   1.1719,   2.7812,  ...,  -6.1875,  -3.5156,  -2.2812],
         [ -7.7188,   9.0625,   6.5938,  ...,  -0.1260,   1.5156,   3.2188],
         [  0.2412,  11.0000,   8.6875,  ...,   4.6875,   6.5000,   5.8125]]],
       device='cuda:0'),)
(tensor([[[-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         ...,
         [ -8.0625,   0.5625,   2.4375,  ...,  -6.4688,  -3.8906,  -2.8750],
         [ -7.5938,   9.3750,   6.7188,  ...,   0.0381,   1.7344,   3.4062],
         [  0.4688,  10.8125,   8.4375,  ...,   4.2812,   6.2188,   5.4062]],

        [[-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         ...,
         [ -7.9062,   0.6836,   2.7656,  ...,  -6.3750,  -3.9844,  -2.6719],
         [ -6.4062,  10.1250,   7.4688,  ...,   0.4609,   2.0469,   3.7344],
         [  0.5312,  11.1250,   8.6250,  ...,   4.2812,   6.5312,   5.0000]]],
       device='cuda:0'),)
(tensor([[[-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         ...,
         [ -7.8125,   0.3711,   2.7031,  ...,  -6.1562,  -3.8125,  -2.8906],
         [ -6.8438,   9.8125,   7.1875,  ...,   0.4844,   2.0469,   3.6406],
         [  0.4824,  10.7500,   8.6875,  ...,   4.2500,   6.5938,   5.0000]],

        [[-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         ...,
         [ -8.0625,   0.4531,   2.3594,  ...,  -6.6250,  -3.6562,  -2.7969],
         [ -7.8125,   9.4375,   6.7500,  ...,  -0.1250,   1.7109,   3.1719],
         [ -0.1670,  10.6875,   8.6250,  ...,   4.3438,   6.8438,   4.7188]]],
       device='cuda:0'),)
(tensor([[[-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         ...,
         [ -8.1875,   0.1338,   2.4062,  ...,  -6.5312,  -4.0625,  -3.2656],
         [ -7.4062,   9.1875,   6.5312,  ...,   0.1357,   1.6406,   3.4219],
         [ -0.4609,  10.3125,   8.3750,  ...,   4.1562,   6.1562,   4.9375]],

        [[-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         ...,
         [ -7.7812,   0.5742,   2.4844,  ...,  -6.5625,  -3.7188,  -2.8594],
         [ -7.7500,   9.6250,   6.7188,  ...,  -0.1611,   1.7031,   3.4531],
         [ -0.3105,  10.5000,   8.5625,  ...,   4.3750,   6.4062,   4.6875]]],
       device='cuda:0'),)
(tensor([[[-1.3688e+01, -9.7500e+00, -4.5938e+00,  ..., -1.2938e+01,
          -7.5938e+00, -5.3438e+00],
         [-1.3688e+01, -9.7500e+00, -4.5938e+00,  ..., -1.2938e+01,
          -7.5938e+00, -5.3438e+00],
         [-1.3688e+01, -9.7500e+00, -4.5938e+00,  ..., -1.2938e+01,
          -7.5938e+00, -5.3438e+00],
         ...,
         [-7.8125e+00,  5.0781e-01,  2.5156e+00,  ..., -6.7812e+00,
          -3.9844e+00, -3.0000e+00],
         [-7.7188e+00,  9.5000e+00,  6.7812e+00,  ...,  3.7842e-03,
           1.5703e+00,  3.0781e+00],
         [ 6.6895e-02,  1.0562e+01,  8.4375e+00,  ...,  3.9375e+00,
           6.5938e+00,  4.3438e+00]],

        [[-1.3688e+01, -9.7500e+00, -4.5938e+00,  ..., -1.2938e+01,
          -7.5938e+00, -5.3438e+00],
         [-1.3688e+01, -9.7500e+00, -4.5938e+00,  ..., -1.2938e+01,
          -7.5938e+00, -5.3438e+00],
         [-1.3688e+01, -9.7500e+00, -4.5938e+00,  ..., -1.2938e+01,
          -7.5938e+00, -5.3438e+00],
         ...,
         [-7.6250e+00,  1.3203e+00,  3.0781e+00,  ..., -5.3750e+00,
          -3.4219e+00, -2.3594e+00],
         [-7.1562e+00,  9.2500e+00,  7.1562e+00,  ...,  3.7891e-01,
           1.3359e+00,  3.4219e+00],
         [ 2.0410e-01,  1.1188e+01,  8.6875e+00,  ...,  4.5000e+00,
           6.8125e+00,  5.1562e+00]]], device='cuda:0'),)
(tensor([[[-1.3688e+01, -9.7500e+00, -4.5938e+00,  ..., -1.2938e+01,
          -7.5938e+00, -5.3438e+00],
         [-1.3688e+01, -9.7500e+00, -4.5938e+00,  ..., -1.2938e+01,
          -7.5938e+00, -5.3438e+00],
         [-1.3688e+01, -9.7500e+00, -4.5938e+00,  ..., -1.2938e+01,
          -7.5938e+00, -5.3438e+00],
         ...,
         [-7.4375e+00,  1.1094e+00,  2.6250e+00,  ..., -6.2812e+00,
          -3.6562e+00, -2.4531e+00],
         [-7.6562e+00,  9.5000e+00,  6.5312e+00,  ..., -7.4219e-02,
           1.5234e+00,  3.5625e+00],
         [ 7.6294e-03,  1.0562e+01,  8.4375e+00,  ...,  4.3125e+00,
           5.7812e+00,  5.5938e+00]],

        [[-1.3688e+01, -9.7500e+00, -4.5938e+00,  ..., -1.2938e+01,
          -7.5938e+00, -5.3438e+00],
         [-1.3688e+01, -9.7500e+00, -4.5938e+00,  ..., -1.2938e+01,
          -7.5938e+00, -5.3438e+00],
         [-1.3688e+01, -9.7500e+00, -4.5938e+00,  ..., -1.2938e+01,
          -7.5938e+00, -5.3438e+00],
         ...,
         [-7.1250e+00,  1.1406e+00,  2.8281e+00,  ..., -6.0625e+00,
          -3.4531e+00, -2.3125e+00],
         [-6.7812e+00,  1.0125e+01,  7.0938e+00,  ...,  4.5117e-01,
           2.1094e+00,  3.6562e+00],
         [ 7.3828e-01,  1.1188e+01,  8.7500e+00,  ...,  4.3750e+00,
           6.4062e+00,  5.4062e+00]]], device='cuda:0'),)
(tensor([[[-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         ...,
         [ -8.8125,  -0.2754,   1.9688,  ...,  -6.6250,  -4.4062,  -3.5312],
         [ -8.2500,   8.9375,   5.9062,  ...,  -0.3555,   0.8945,   3.2031],
         [  0.8555,  10.6875,   8.3750,  ...,   4.4375,   6.4375,   5.6875]],

        [[-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         [-13.6875,  -9.7500,  -4.5938,  ..., -12.9375,  -7.5938,  -5.3438],
         ...,
         [ -6.7500,   2.0469,   3.6406,  ...,  -5.4375,  -2.8125,  -2.0156],
         [ -6.6562,   9.6875,   7.6250,  ...,   0.2441,   1.7656,   3.6875],
         [  0.7344,  11.1875,   9.2500,  ...,   4.7188,   6.5625,   5.0000]]],
       device='cuda:0'),)
{'eval_loss': 0.025980347767472267, 'eval_runtime': 35.2321, 'eval_samples_per_second': 6.698, 'eval_steps_per_second': 0.426, 'epoch': 0.17}

======================================== [DEBUGGING AT GLOBAL STEP: 20] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given two views, at least 13 cubes and at most 22 cubes are required to satisfy the constraints.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given two views, at least 13 cubes and at most 22 cubes are required to satisfy the constraints.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 20: 'NoneType' object has no attribute 'shape'[0m
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                 | 21/118 [06:31<42:14, 26.12s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 21] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is incorrect because the red cubes are not in the correct position in the view.', 'A': 'Option A is incorrect because the shape matches the right view instead of the left view, and the red cubes are not in the correct position.', 'B': 'Option B is incorrect because the image shows the right view of the cube stack instead of the left view.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is incorrect because the red cubes are not in the correct position in the view.', 'A': 'Option A is incorrect because the shape matches the right view instead of the left view, and the red cubes are not in the correct position.', 'B': 'Option B is incorrect because the image shows the right view of the cube stack instead of the left view.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 21: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                | 22/118 [06:46<36:22, 22.74s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 22] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because the red cubes are not in the correct position in the view.', 'B': 'Option B is incorrect because the shape matches the right view instead of the left view, and the red cubes are not in the correct position.', 'D': 'Option D is incorrect because the image shows the right view of the cube stack instead of the left view.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is incorrect because the red cubes are not in the correct position in the view.', 'B': 'Option B is incorrect because the shape matches the right view instead of the left view, and the red cubes are not in the correct position.', 'D': 'Option D is incorrect because the image shows the right view of the cube stack instead of the left view.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 22: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                               | 23/118 [07:01<32:20, 20.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 23] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is correct because it was obtained by rotating the original image 90 degrees.', 'C': 'Option C is incorrect because it was obtained by rotating the original image 90 degrees and then flipping it horizontally.', 'B': 'Option B is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it vertically.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is correct because it was obtained by rotating the original image 90 degrees.', 'C': 'Option C is incorrect because it was obtained by rotating the original image 90 degrees and then flipping it horizontally.', 'B': 'Option B is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it vertically.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 23: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                              | 24/118 [07:16<29:26, 18.79s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 24] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given two views, at least 12 cubes and at most 18 cubes are required to satisfy the constraints.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given two views, at least 12 cubes and at most 18 cubes are required to satisfy the constraints.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 24: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                             | 25/118 [07:31<27:25, 17.69s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 25] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is incorrect because holes in column 2 are missing.', 'C': 'Option C is incorrect because extra holes appear in column 1.', 'B': 'Option B is incorrect because holes that should appear in column 2 appear in column 1.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is incorrect because holes in column 2 are missing.', 'C': 'Option C is incorrect because extra holes appear in column 1.', 'B': 'Option B is incorrect because holes that should appear in column 2 appear in column 1.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 25: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                            | 26/118 [07:46<25:48, 16.83s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 26] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is incorrect because holes in row 3 are missing.', 'A': 'Option A is incorrect because extra holes appear in row 1.', 'B': 'Option B is incorrect because holes that should appear in row 3 appear in row 1.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is incorrect because holes in row 3 are missing.', 'A': 'Option A is incorrect because extra holes appear in row 1.', 'B': 'Option B is incorrect because holes that should appear in row 3 appear in row 1.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 26: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                           | 27/118 [08:00<24:37, 16.24s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 27] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given three views, at least 11 cubes and at most 13 cubes are required to satisfy the constraints.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given three views, at least 11 cubes and at most 13 cubes are required to satisfy the constraints.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 27: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                          | 28/118 [08:16<23:49, 15.89s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 28] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given two views, at least 7 cubes and at most 9 cubes are required to satisfy the constraints.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given two views, at least 7 cubes and at most 9 cubes are required to satisfy the constraints.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 28: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                         | 29/118 [08:30<23:08, 15.60s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 29] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because the internal outlines are missing.', 'B': 'Option B is incorrect because the internal outlines are missing.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is incorrect because the internal outlines are missing.', 'B': 'Option B is incorrect because the internal outlines are missing.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 29: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                                        | 30/118 [08:45<22:37, 15.42s/it]
{'loss': 0.0032, 'grad_norm': 0.029467584565281868, 'learning_rate': 4.385266524442241e-06, 'epoch': 0.25}
(tensor([[[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [-10.6875,  -0.5078,   1.3594,  ...,  -7.5625,  -6.4688,  -4.6562],
         [ -6.3750,   7.6875,   5.7812,  ...,  -1.9609,  -0.8945,   1.4375],
         [  2.5312,  11.6875,  10.0000,  ...,   4.2188,   7.5938,   5.7812]],

        [[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [-10.4375,  -0.6172,   1.3594,  ...,  -7.7188,  -6.7188,  -4.6250],
         [ -5.6875,   8.1875,   5.8438,  ...,  -1.6328,  -0.4629,   1.7500],
         [  2.2656,  11.7500,  10.1875,  ...,   4.4062,   7.4062,   5.9062]]],
       device='cuda:0'),)
 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                        | 2/15 [00:02<00:15,  1.19s/it]
(tensor([[[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [-11.1875,  -1.1875,   1.0078,  ...,  -7.7188,  -6.9062,  -5.1875],
         [ -6.4062,   7.6562,   5.9062,  ...,  -1.6797,  -0.8047,   1.5078],
         [  2.5156,  11.7500,  10.2500,  ...,   4.3125,   7.7812,   5.8750]],

        [[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [-10.3750,  -0.0913,   1.3203,  ...,  -7.5312,  -6.3750,  -4.6562],
         [ -7.1250,   8.1875,   5.6250,  ...,  -1.9141,  -0.8281,   1.6797],
         [  1.4062,  12.3125,  10.2500,  ...,   4.6250,   7.2812,   6.1250]]],
       device='cuda:0'),)
(tensor([[[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [ -9.3750,   0.8281,   2.2031,  ...,  -6.6562,  -5.3750,  -3.5781],
         [ -5.1562,   9.9375,   7.0000,  ...,  -0.0718,   0.9805,   2.8906],
         [  1.3516,  12.6250,  10.5000,  ...,   4.9375,   8.1250,   6.2188]],

        [[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [-11.7500,  -1.3906,   0.4668,  ...,  -7.8125,  -7.0938,  -5.4062],
         [ -7.0938,   7.6250,   5.2188,  ...,  -2.1562,  -1.3984,   1.0469],
         [  2.2812,  12.0625,   9.8750,  ...,   4.2500,   7.1250,   6.0625]]],
       device='cuda:0'),)
(tensor([[[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [-10.6250,   0.3691,   1.6953,  ...,  -7.0938,  -6.0000,  -4.0000],
         [ -6.4062,   8.7500,   6.1562,  ...,  -1.0469,  -0.4688,   1.8672],
         [  1.5781,  12.3125,  10.3750,  ...,   4.7812,   7.7812,   6.0312]],

        [[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [ -9.3750,   0.8359,   2.2188,  ...,  -6.7188,  -5.4062,  -3.5938],
         [ -5.3750,   9.9375,   6.9375,  ...,  -0.1621,   0.7539,   2.8438],
         [  1.2891,  12.6250,  10.5625,  ...,   4.9375,   8.1875,   6.1562]]],
       device='cuda:0'),)
(tensor([[[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [-10.9375,  -0.9219,   1.1172,  ...,  -7.6875,  -6.5625,  -4.9062],
         [ -7.0938,   8.6250,   5.8438,  ...,  -1.6094,  -0.6602,   1.7969],
         [  1.3672,  12.0625,  10.0000,  ...,   4.5312,   7.4375,   6.0312]],

        [[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [-10.6875,  -0.4375,   1.3594,  ...,  -7.5000,  -6.2812,  -4.5938],
         [ -6.2500,   8.8125,   6.0625,  ...,  -1.2422,  -0.2275,   1.8438],
         [  1.8125,  12.0000,  10.1250,  ...,   4.5625,   7.7812,   5.7812]]],
       device='cuda:0'),)
(tensor([[[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [-10.8125,  -1.0859,   1.0000,  ...,  -7.7812,  -6.8438,  -5.0000],
         [ -5.8438,   8.0000,   5.9688,  ...,  -1.4609,  -0.1855,   1.7500],
         [  2.2344,  11.7500,  10.3125,  ...,   4.6250,   7.6250,   6.0625]],

        [[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [-11.3750,  -1.5312,   0.2715,  ...,  -8.1875,  -7.4688,  -5.8125],
         [ -7.5000,   7.8438,   5.2812,  ...,  -1.8984,  -1.3672,   1.2734],
         [  2.4688,  11.9375,   9.8125,  ...,   4.1250,   7.0625,   6.2188]]],
       device='cuda:0'),)
(tensor([[[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [-11.3750,  -1.2188,   0.8672,  ...,  -7.9062,  -6.7188,  -5.0625],
         [ -6.8438,   8.7500,   5.9688,  ...,  -1.5000,  -0.5273,   1.7266],
         [  1.6953,  12.1875,  10.0625,  ...,   4.6250,   7.7500,   6.1875]],

        [[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [-10.0000,  -0.5391,   1.5547,  ...,  -7.5312,  -6.5625,  -4.5625],
         [ -5.5625,   9.0000,   6.2500,  ...,  -1.1719,  -0.3789,   1.9062],
         [  1.9922,  11.9375,  10.1875,  ...,   4.4688,   7.4062,   6.0312]]],
       device='cuda:0'),)
(tensor([[[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [ -9.9375,  -0.3926,   1.6328,  ...,  -7.5000,  -6.4375,  -4.5625],
         [ -5.6875,   8.9375,   6.2188,  ...,  -1.2969,  -0.4844,   1.8047],
         [  2.0312,  12.0000,  10.2500,  ...,   4.6562,   7.5312,   6.2188]],

        [[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [-10.4375,  -0.3125,   1.4453,  ...,  -7.3750,  -6.4375,  -4.5938],
         [ -5.9062,   9.5000,   6.5312,  ...,  -0.7305,  -0.2002,   2.0938],
         [  1.7031,  12.0000,  10.2500,  ...,   4.5938,   7.6875,   5.8438]]],
       device='cuda:0'),)
(tensor([[[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [-10.6250,  -1.2891,   0.6836,  ...,  -8.0000,  -7.2188,  -5.3750],
         [ -6.0312,   9.0625,   6.2188,  ...,  -0.7656,  -0.0894,   2.1250],
         [  1.7031,  12.3125,  10.2500,  ...,   4.5625,   7.8438,   6.2812]],

        [[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [-10.9375,  -0.3965,   1.0469,  ...,  -7.5938,  -6.5000,  -4.5938],
         [ -6.5625,   8.8125,   6.0625,  ...,  -1.3750,  -0.4883,   1.8594],
         [  2.0156,  12.2500,  10.2500,  ...,   4.5625,   7.5938,   6.3750]]],
       device='cuda:0'),)
(tensor([[[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [-11.0625,  -0.7969,   0.9102,  ...,  -7.6562,  -6.7500,  -4.9688],
         [ -6.0938,   8.7500,   6.1562,  ...,  -1.1016,  -0.1235,   2.0156],
         [  2.0469,  11.9375,  10.0625,  ...,   4.3438,   7.4062,   6.1250]],

        [[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [-10.5625,  -0.9922,   1.2031,  ...,  -7.9062,  -6.7500,  -5.0000],
         [ -6.3438,   8.8125,   6.1875,  ...,  -1.3281,  -0.4473,   1.9141],
         [  1.3281,  12.0000,  10.0000,  ...,   4.5312,   7.6250,   5.9375]]],
       device='cuda:0'),)
(tensor([[[-1.1500e+01, -7.0312e+00, -2.5469e+00,  ..., -1.0562e+01,
          -5.2500e+00, -2.9375e+00],
         [-1.1500e+01, -7.0312e+00, -2.5469e+00,  ..., -1.0562e+01,
          -5.2500e+00, -2.9375e+00],
         [-1.1500e+01, -7.0312e+00, -2.5469e+00,  ..., -1.0562e+01,
          -5.2500e+00, -2.9375e+00],
         ...,
         [-1.0750e+01, -1.0547e+00,  1.0859e+00,  ..., -7.7500e+00,
          -6.8438e+00, -5.0938e+00],
         [-5.4688e+00,  8.4375e+00,  6.2812e+00,  ..., -1.1328e+00,
          -4.5166e-03,  1.9219e+00],
         [ 2.2969e+00,  1.1938e+01,  1.0375e+01,  ...,  4.6562e+00,
           7.6250e+00,  6.2500e+00]],

        [[-1.1500e+01, -7.0312e+00, -2.5469e+00,  ..., -1.0562e+01,
          -5.2500e+00, -2.9375e+00],
         [-1.1500e+01, -7.0312e+00, -2.5469e+00,  ..., -1.0562e+01,
          -5.2500e+00, -2.9375e+00],
         [-1.1500e+01, -7.0312e+00, -2.5469e+00,  ..., -1.0562e+01,
          -5.2500e+00, -2.9375e+00],
         ...,
         [-1.0875e+01, -9.5703e-01,  1.0234e+00,  ..., -7.6562e+00,
          -6.5000e+00, -4.9062e+00],
         [-6.6250e+00,  8.7500e+00,  6.1562e+00,  ..., -1.3672e+00,
          -3.2812e-01,  1.6562e+00],
         [ 1.8594e+00,  1.2312e+01,  1.0438e+01,  ...,  4.6250e+00,
           7.9375e+00,  6.0312e+00]]], device='cuda:0'),)
(tensor([[[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [-10.7500,  -0.8164,   1.0078,  ...,  -7.6875,  -6.6875,  -5.1562],
         [ -6.4688,   8.0625,   5.7500,  ...,  -1.5469,  -0.6016,   1.5156],
         [  1.5234,  12.1875,  10.3125,  ...,   4.6562,   7.6250,   6.0938]],

        [[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [-10.7500,  -0.6758,   1.1797,  ...,  -7.5938,  -6.5312,  -4.7812],
         [ -6.8125,   8.5625,   6.0938,  ...,  -1.5312,  -0.4570,   1.8594],
         [  1.6719,  12.0625,  10.3125,  ...,   4.5312,   7.5000,   5.7812]]],
       device='cuda:0'),)
(tensor([[[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [-10.6250,  -0.5117,   1.3984,  ...,  -7.5312,  -6.4375,  -4.6250],
         [ -6.1875,   8.9375,   6.1562,  ...,  -1.2812,  -0.3262,   1.8125],
         [  2.0000,  12.0000,  10.1875,  ...,   4.4375,   7.7812,   5.7812]],

        [[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [-10.6875,  -0.0693,   1.4766,  ...,  -6.8125,  -6.1562,  -4.4375],
         [ -5.4688,   9.3125,   6.7500,  ...,  -0.2119,   0.4023,   2.5000],
         [  1.8594,  12.4375,  10.2500,  ...,   5.0000,   8.1250,   6.2500]]],
       device='cuda:0'),)
(tensor([[[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [-10.5000,  -0.3711,   1.1562,  ...,  -7.5625,  -6.5625,  -4.5938],
         [ -6.4062,   9.0625,   6.1562,  ...,  -1.2266,  -0.3887,   2.2031],
         [  1.6250,  11.9375,  10.0625,  ...,   4.3438,   7.1562,   6.1250]],

        [[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [-10.5625,  -1.0234,   0.8398,  ...,  -7.8438,  -6.9375,  -5.1250],
         [ -6.2500,   9.4375,   6.2500,  ...,  -0.9961,  -0.1504,   2.1562],
         [  1.8047,  12.5625,  10.3125,  ...,   4.5312,   7.6875,   6.3750]]],
       device='cuda:0'),)
(tensor([[[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [-11.2500,  -1.1875,   0.5742,  ...,  -7.9062,  -7.1250,  -5.4062],
         [ -7.7812,   7.5938,   5.1250,  ...,  -2.2812,  -1.6094,   1.1875],
         [  2.1875,  11.9375,   9.9375,  ...,   4.1250,   6.9688,   6.0625]],

        [[-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         [-11.5000,  -7.0312,  -2.5469,  ..., -10.5625,  -5.2500,  -2.9375],
         ...,
         [-10.3125,  -0.3770,   1.4844,  ...,  -7.2500,  -6.1562,  -4.5000],
         [ -5.8750,   9.4375,   6.9062,  ...,  -0.2715,   0.6719,   2.5781],
         [  1.1328,  12.4375,  10.6875,  ...,   4.9375,   8.1875,   6.2188]]],
       device='cuda:0'),)
{'eval_loss': 0.009481791406869888, 'eval_runtime': 35.2447, 'eval_samples_per_second': 6.696, 'eval_steps_per_second': 0.426, 'epoch': 0.25}

======================================== [DEBUGGING AT GLOBAL STEP: 30] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Assuming the bottom face is the first cell in the second row of the net, then after folding, the front face is pink, the back face is green, the left face is red, the right face is blue, the top face is cyan, the bottom face is yellow.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Assuming the bottom face is the first cell in the second row of the net, then after folding, the front face is pink, the back face is green, the left face is red, the right face is blue, the top face is cyan, the bottom face is yellow.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 30: 'NoneType' object has no attribute 'shape'[0m
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                                       | 31/118 [09:36<37:46, 26.05s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 31] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because holes in column 3 are missing.', 'C': 'Option C is incorrect because extra holes appear in column 4.', 'D': 'Option D is incorrect because holes that should appear in column 3 appear in column 4.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is incorrect because holes in column 3 are missing.', 'C': 'Option C is incorrect because extra holes appear in column 4.', 'D': 'Option D is incorrect because holes that should appear in column 3 appear in column 4.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 31: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                                      | 32/118 [09:51<32:35, 22.74s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 32] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because the red cubes are not in the correct position in the view.', 'B': 'Option B is incorrect because the shape matches the right view instead of the left view, and the red cubes are not in the correct position.', 'D': 'Option D is incorrect because the image shows the right view of the cube stack instead of the left view.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is incorrect because the red cubes are not in the correct position in the view.', 'B': 'Option B is incorrect because the shape matches the right view instead of the left view, and the red cubes are not in the correct position.', 'D':'Option D is incorrect because the image shows the right view of the cube stack instead of the left view.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 32: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                                     | 33/118 [10:06<28:57, 20.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 33] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because holes in row 2 are missing.', 'C': 'Option C is incorrect because extra holes appear in row 4.', 'D': 'Option D is incorrect because holes that should appear in row 2 appear in row 4.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is incorrect because holes in row 2 are missing.', 'C': 'Option C is incorrect because extra holes appear in row 4.', 'D': 'Option D is incorrect because holes that should appear in row 2 appear in row 4.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 33: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                                    | 34/118 [10:21<26:14, 18.75s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 34] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is incorrect because it is the cross-section made by a plane perpendicular to the YZ plane and rotated 135 degrees around the x-axis.', 'D': 'Option D is incorrect because it is the cross-section made by a plane perpendicular to the YZ plane and rotated 45 degrees around the x-axis.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'C': 'Option C is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is incorrect because it is the cross-section made by a plane perpendicular to the YZ plane andated 135 degrees around the x-axis.', 'D': 'Option D is incorrect because it is the cross-section made by a plane perpendicular to the YZ plane and rotated 45 degrees around the x-axis.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'C': 'Option C is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 34: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                                   | 35/118 [10:36<24:24, 17.65s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 35] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because the internal outlines are missing.', 'C': 'Option C is incorrect because the image is a horizontally or vertically mirrored version of an incorrect view.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is incorrect because the internal outlines are missing.', 'C': 'Option C is incorrect because the image is a horizontally or vertically mirrored version of an incorrect view.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 35: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                                  | 36/118 [10:51<22:59, 16.82s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 36] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because the internal outlines are missing.', 'A': 'Option A is incorrect because the internal outlines are missing.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is incorrect because the internal outlines are missing.', 'A': 'Option A is incorrect because the internal outlines are missing.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 36: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                                 | 37/118 [11:06<21:59, 16.29s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 37] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is correct because it was obtained by rotating the original image 180 degrees.', 'C': 'Option C is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it vertically.', 'A': 'Option A is incorrect because it was obtained by rotating the asymmetric patterns in the image.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is correct because it was obtained by rotating the original image 180 degrees.', 'C': 'Option C is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it vertically.', 'A': 'Option A is incorrect because it was obtained by rotating the asymmetric patterns in the image.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 37: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                                | 38/118 [11:21<21:07, 15.85s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 38] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because holes in row 3 are missing.', 'A': 'Option A is incorrect because extra holes appear in row 2.', 'B': 'Option B is incorrect because holes that should appear in row 3 appear in row 2.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is incorrect because holes in row 3 are missing.', 'A': 'Option A is incorrect because extra holes appear in row 2.', 'B': 'Option B is incorrect because holes that should appear in row 3 appear in row 2.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 38: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                               | 39/118 [11:36<20:40, 15.70s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 39] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is correct because it was obtained by rotating the original image 180 degrees.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it horizontally.', 'C': 'Option C is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it vertically.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is correct because it was obtained by rotating the original image 180 degrees.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it horizontally.', 'C': 'Option C is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it vertically.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 39: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                              | 40/118 [11:51<20:04, 15.45s/it]
{'loss': 0.0194, 'grad_norm': 0.6158662438392639, 'learning_rate': 3.8673703953060685e-06, 'epoch': 0.34}
(tensor([[[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -6.7188,   1.3516,   2.5469,  ...,  -5.9062,  -3.2500,  -2.1406],
         [ -3.2812,  12.0625,   8.1250,  ...,   0.6562,   3.1250,   4.5000],
         [  6.0625,  13.0000,  11.5000,  ...,   5.2812,   9.9375,   6.7812]],

        [[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -6.9062,   1.2500,   2.4844,  ...,  -6.0938,  -3.5781,  -2.2188],
         [ -2.7969,  12.5625,   8.3750,  ...,   1.1172,   3.6875,   4.8125],
         [  5.7188,  13.3125,  11.7500,  ...,   5.6562,  10.0000,   7.0312]]],
       device='cuda:0'),)
 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                        | 2/15 [00:02<00:15,  1.18s/it]
(tensor([[[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -7.3438,   0.8789,   2.0938,  ...,  -5.9375,  -3.6875,  -2.4531],
         [ -3.2188,  12.3750,   8.0000,  ...,   0.9375,   3.3125,   4.7812],
         [  6.0625,  13.5625,  11.8125,  ...,   5.7500,  10.3750,   7.1250]],

        [[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -6.5625,   1.2031,   2.1094,  ...,  -6.0625,  -3.8281,  -2.5781],
         [ -3.1250,  13.0625,   7.9688,  ...,   0.8047,   3.3906,   4.9062],
         [  5.1562,  13.8125,  11.8125,  ...,   5.8438,   9.8125,   7.1875]]],
       device='cuda:0'),)
(tensor([[[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -6.1875,   2.8281,   3.1562,  ...,  -4.9062,  -2.5781,  -1.1094],
         [ -2.0312,  14.0000,   8.8125,  ...,   2.2188,   4.7500,   5.5312],
         [  4.2812,  13.6250,  11.6250,  ...,   5.9688,  10.3125,   7.0312]],

        [[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -7.8750,   1.1719,   1.8281,  ...,  -5.6250,  -3.6719,  -2.5000],
         [ -3.2969,  12.6250,   7.7812,  ...,   0.5469,   2.9375,   4.5938],
         [  6.0000,  13.7500,  11.4375,  ...,   5.6875,   9.9375,   7.4688]]],
       device='cuda:0'),)
(tensor([[[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -6.8750,   2.7812,   3.0312,  ...,  -4.9688,  -2.5938,  -1.0547],
         [ -2.7656,  13.1250,   8.5000,  ...,   1.7578,   3.8281,   5.0938],
         [  5.1875,  14.0000,  11.9375,  ...,   6.2500,  10.6250,   7.3438]],

        [[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -6.5625,   2.6250,   2.9531,  ...,  -5.0938,  -2.8125,  -1.2500],
         [ -2.1094,  14.1250,   8.8750,  ...,   2.3281,   4.7500,   5.6562],
         [  4.3438,  13.5625,  11.6250,  ...,   5.9688,  10.3125,   7.0625]]],
       device='cuda:0'),)
(tensor([[[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -7.1250,   1.2422,   2.2500,  ...,  -5.6250,  -3.3438,  -2.1406],
         [ -3.1719,  13.5625,   8.1875,  ...,   1.4297,   3.8281,   5.2500],
         [  4.8125,  13.6875,  11.5000,  ...,   6.0000,  10.1250,   7.5312]],

        [[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -7.4688,   1.1016,   2.1875,  ...,  -6.1562,  -3.7188,  -2.3594],
         [ -3.8125,  12.3750,   7.9062,  ...,   0.7734,   3.1094,   4.2500],
         [  5.2500,  13.3125,  11.4375,  ...,   5.6875,  10.0625,   6.8750]]],
       device='cuda:0'),)
(tensor([[[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -7.4375,   0.2852,   1.7422,  ...,  -6.5000,  -4.2500,  -2.8438],
         [ -2.7500,  12.4375,   8.1250,  ...,   1.0312,   3.7031,   4.7500],
         [  5.6875,  13.3125,  11.7500,  ...,   5.7188,  10.0625,   7.2500]],

        [[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -7.4062,   1.2891,   1.9531,  ...,  -5.7812,  -3.9688,  -2.7031],
         [ -3.1094,  13.0000,   8.1875,  ...,   0.9766,   3.1562,   4.8125],
         [  6.3125,  13.8125,  11.4375,  ...,   5.6250,   9.8750,   7.5938]]],
       device='cuda:0'),)
(tensor([[[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -7.6562,   0.8750,   2.0000,  ...,  -5.9062,  -3.5156,  -2.4688],
         [ -3.2969,  13.2500,   8.1250,  ...,   1.1797,   3.6562,   5.0000],
         [  5.0000,  13.7500,  11.6250,  ...,   6.0938,  10.3750,   7.6875]],

        [[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -6.1562,   1.5156,   2.6406,  ...,  -5.8438,  -3.2656,  -1.8984],
         [ -2.6094,  13.2500,   8.4375,  ...,   1.4219,   3.7812,   4.9688],
         [  5.9375,  13.5625,  11.8125,  ...,   5.7500,  10.1250,   7.4062]]],
       device='cuda:0'),)
(tensor([[[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -6.1875,   1.5547,   2.6406,  ...,  -5.9062,  -3.3125,  -2.0156],
         [ -2.5156,  13.2500,   8.4375,  ...,   1.4531,   3.8906,   5.0000],
         [  5.6562,  13.5625,  11.8125,  ...,   5.8125,  10.0625,   7.4375]],

        [[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -7.2188,   1.0078,   2.1250,  ...,  -6.3125,  -3.9688,  -2.7031],
         [ -2.9531,  13.4375,   8.3750,  ...,   1.4531,   3.5781,   4.6562],
         [  5.2500,  13.0625,  11.6250,  ...,   5.2812,   9.8750,   6.4062]]],
       device='cuda:0'),)
(tensor([[[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -7.3750,   1.1172,   1.8984,  ...,  -5.9688,  -4.0312,  -2.4531],
         [ -2.2031,  14.1250,   8.6250,  ...,   2.1406,   4.3438,   5.6875],
         [  5.2812,  14.0000,  11.8125,  ...,   6.1562,  10.5625,   7.7188]],

        [[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -7.5312,   1.3984,   2.1250,  ...,  -5.9375,  -3.7188,  -2.2500],
         [ -3.1094,  13.3750,   8.3750,  ...,   1.3125,   3.6719,   5.1250],
         [  5.2188,  13.6875,  11.5000,  ...,   5.8125,  10.1250,   7.5312]]],
       device='cuda:0'),)
(tensor([[[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -7.8125,   1.0859,   1.9297,  ...,  -6.0938,  -4.0312,  -2.4844],
         [ -2.7188,  13.3125,   8.3125,  ...,   1.4688,   3.8750,   5.1875],
         [  5.4375,  13.4375,  11.5000,  ...,   5.7500,  10.0625,   7.3750]],

        [[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -6.7500,   1.6719,   2.6406,  ...,  -5.5625,  -2.9844,  -1.7969],
         [ -2.8438,  13.6875,   8.5625,  ...,   1.8828,   4.1562,   5.3750],
         [  4.7500,  13.6250,  11.6250,  ...,   6.0312,  10.1875,   7.3750]]],
       device='cuda:0'),)
(tensor([[[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -7.3438,   0.4980,   1.8828,  ...,  -6.3750,  -4.1250,  -2.7656],
         [ -2.6094,  12.5000,   8.2500,  ...,   1.1328,   3.7344,   4.7500],
         [  5.8438,  13.4375,  11.8125,  ...,   5.8125,  10.1250,   7.3750]],

        [[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -7.8750,   0.4590,   1.7031,  ...,  -6.3438,  -4.1250,  -2.9062],
         [ -3.6562,  12.7500,   8.0000,  ...,   0.8086,   3.2031,   4.5625],
         [  5.4375,  13.7500,  11.6875,  ...,   5.8125,  10.3125,   7.2500]]],
       device='cuda:0'),)
(tensor([[[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -7.2500,   0.5938,   1.7266,  ...,  -6.3750,  -4.1875,  -3.0469],
         [ -3.2969,  12.4375,   7.7188,  ...,   0.7695,   3.1875,   4.4375],
         [  5.2500,  13.7500,  11.8750,  ...,   5.9062,  10.1875,   7.1875]],

        [[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -7.1562,   0.9453,   2.0781,  ...,  -6.0000,  -3.8281,  -2.5156],
         [ -3.5156,  13.0000,   8.1875,  ...,   1.0547,   3.4219,   4.9375],
         [  5.1562,  13.6250,  11.6250,  ...,   5.8125,  10.0000,   7.0938]]],
       device='cuda:0'),)
(tensor([[[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -7.4062,   1.1172,   2.2031,  ...,  -6.1562,  -3.7500,  -2.3750],
         [ -3.5781,  12.5625,   8.1250,  ...,   0.9297,   3.2031,   4.4375],
         [  5.2500,  13.3125,  11.5000,  ...,   5.6250,  10.0625,   6.9062]],

        [[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -7.1250,   1.2422,   2.1406,  ...,  -5.7188,  -3.8125,  -2.6250],
         [ -1.8828,  14.0000,   8.9375,  ...,   2.2344,   4.5312,   5.5000],
         [  5.3125,  13.5625,  11.5000,  ...,   5.9375,  10.4375,   7.0000]]],
       device='cuda:0'),)
(tensor([[[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -7.1562,   1.6562,   2.3281,  ...,  -5.7812,  -3.7500,  -2.0625],
         [ -2.8906,  13.5625,   8.5000,  ...,   1.4766,   3.8125,   5.4375],
         [  5.1875,  13.5625,  11.4375,  ...,   5.7812,   9.8125,   7.4062]],

        [[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -7.3750,   1.3672,   2.0781,  ...,  -5.8438,  -3.7812,  -2.2188],
         [ -2.6250,  14.2500,   8.5625,  ...,   1.8359,   4.1562,   5.6562],
         [  5.3438,  14.1250,  11.8125,  ...,   6.0625,  10.4375,   7.7500]]],
       device='cuda:0'),)
(tensor([[[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -7.3750,   1.5078,   2.0938,  ...,  -5.5625,  -3.5781,  -2.3281],
         [ -3.2188,  13.0625,   8.0000,  ...,   0.8750,   3.1875,   4.9375],
         [  6.0938,  13.8125,  11.5625,  ...,   5.5938,   9.8125,   7.4688]],

        [[-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         [-10.4375,  -5.9375,  -1.6875,  ...,  -9.6250,  -4.4062,  -2.1094],
         ...,
         [ -6.9062,   1.3125,   2.3125,  ...,  -5.6875,  -3.6250,  -2.2812],
         [ -1.7891,  14.1875,   8.8750,  ...,   2.3594,   4.9375,   5.5625],
         [  4.4062,  13.5625,  11.9375,  ...,   6.0625,  10.4375,   7.2188]]],
       device='cuda:0'),)
{'eval_loss': 0.0045464965514838696, 'eval_runtime': 35.3029, 'eval_samples_per_second': 6.685, 'eval_steps_per_second': 0.425, 'epoch': 0.34}

======================================== [DEBUGGING AT GLOBAL STEP: 40] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is correct because it was obtained by removing one small cube from the original stack.', 'C': 'Option C is incorrect because the cube stack can be obtained by rotating the original stack around the z-axis by 90 degrees.', 'B': 'Option B is incorrect because the cube stack can be obtained by rotating the original stack around the z-axis by 180 degrees.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is correct because it was obtained by removing one small cube from the original stack.', 'C': 'Option C is incorrect because the cube stack can be obtained by rotating the original stack around the z-axis by 90 degrees.', 'B': 'Option B is incorrect because the cube stack can be obtained by rotating the original stack around the z-axis by 180 degrees.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 40: 'NoneType' object has no attribute 'shape'[0m
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                             | 41/118 [12:42<33:29, 26.10s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 41] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given three views, at least 10 cubes and at most 10 cubes are required to satisfy the constraints.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given three views, at least 10 cubes and at most 10 cubes are required to satisfy the constraints.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 41: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                            | 42/118 [12:57<28:50, 22.77s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 42] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given two views, at least 7 cubes and at most 9 cubes are required to satisfy the constraints.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given two views, at least 7 cubes and at most 9 cubes are required to satisfy the constraints.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 42: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                           | 43/118 [13:12<25:31, 20.41s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 43] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because the initial arrow can be transformed into the final arrow.', 'DAB': 'Option DAB is incorrect because the initial arrow cannot be transformed into the final arrow.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is correct because the initial arrow can be transformed into the final arrow.', 'DAAB': 'Option DAB is incorrect because the initial arrow cannot be transformed into the final arrow.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 43: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                          | 44/118 [13:27<23:12, 18.82s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 44] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'C': 'Option C is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'C': 'Option C is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 44: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                         | 45/118 [13:42<21:29, 17.67s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 45] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'C': 'Option C is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'C': 'Option C is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 45: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                        | 46/118 [13:57<20:14, 16.87s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 46] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because it is a horizontally mirrored version of the front-bottom-left view.', 'B': 'Option B is incorrect because it is a vertically mirrored version of the back-bottom-right view.', 'ABCD': 'Assuming the bottom face is the first cell in the second row of the net, then after folding, the front face is cyan, the back face is blue, the left face is green, the right face is red, the top face is yellow, the bottom face is pink.', 'A': 'Option A is correct because it shows the front-top-left view.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is incorrect because it is a horizontally mirrored version of the front-bottom-left view.', 'B': 'Option B is incorrect because it is a vertically mirrored version of the back-bottom-right view.', 'ABCD': 'Assuming the bottom face is the first cell in the second row of the net, then after folding, the front face is cyan, the back face is blue, the left face is green, the right face is red, the top face is yellow, the bottom face is pink.', 'A': 'Option A is correct because it shows the front-top-left view.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 46: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                       | 47/118 [14:12<19:15, 16.28s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 47] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because the initial arrow can be transformed into the final arrow.', 'DAB': 'Option DAB is incorrect because the initial arrow cannot be transformed into the final arrow.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is correct because the initial arrow can be transformed into the final arrow.', 'DAB': 'Option DB is incorrect because the initial arrow cannot be transformed into the final arrow.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 47: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                      | 48/118 [14:27<18:32, 15.90s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 48] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because the squares with asymmetric patterns have been rotated, so it cannot form the cube shown in the left image.', 'B': 'Option B is incorrect because the relative positions of three faces match the cube shown in the left image.', 'D': 'Option D is incorrect because the relative positions of three faces match the cube shown in the left image.', 'A': 'Option A is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is correct because the squares with asymmetric patterns have been rotated, so it cannot form the cube shown in the left image.', 'B': 'Option B is incorrect because the relative positions of three faces match the cube shown in the left image.', 'D': 'Option D is incorrect because the relative positions of three faces match the cube shown in the left image.', 'A': 'Option A is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 48: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                     | 49/118 [14:42<17:59, 15.64s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 49] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'In this connection, the orange object rotates in the opposite direction to the green object.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'In this connection, the orange object rotates in the opposite direction to the green object.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 49: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                    | 50/118 [14:57<17:27, 15.41s/it]
{'loss': 0.0047, 'grad_norm': 0.023912467062473297, 'learning_rate': 3.246287027504237e-06, 'epoch': 0.42}
(tensor([[[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -7.3750,   1.0703,   1.6797,  ...,  -5.6250,  -4.0312,  -1.8906],
         [ -9.0625,   7.7500,   4.9375,  ...,  -2.6406,  -2.1875,   1.9844],
         [  5.5938,  11.7500,   9.8125,  ...,   4.4688,   8.6875,   6.0000]],

        [[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -7.5938,   1.0312,   1.6094,  ...,  -5.7500,  -4.4688,  -2.0312],
         [ -9.0625,   8.0000,   5.1250,  ...,  -2.3125,  -2.0312,   2.2344],
         [  5.2500,  12.1875,  10.1250,  ...,   4.8125,   8.7500,   6.3125]]],
       device='cuda:0'),)
 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                        | 2/15 [00:02<00:15,  1.18s/it]
(tensor([[[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -7.9062,   0.8867,   1.4609,  ...,  -5.5000,  -4.1562,  -1.9531],
         [ -8.7500,   8.5000,   5.1875,  ...,  -1.9062,  -1.5156,   2.6719],
         [  5.5312,  12.2500,  10.1250,  ...,   4.8438,   9.1250,   6.3125]],

        [[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -6.9688,   0.9141,   1.4297,  ...,  -5.7500,  -4.4375,  -2.1094],
         [ -8.5000,   8.7500,   5.0625,  ...,  -2.4062,  -1.8203,   2.7969],
         [  4.6875,  12.4375,  10.1250,  ...,   4.9688,   8.5625,   6.3438]]],
       device='cuda:0'),)
(tensor([[[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -6.5625,   2.3281,   2.5000,  ...,  -4.7812,  -3.3281,  -0.9492],
         [ -7.9375,   9.1875,   5.8438,  ...,  -1.3750,  -0.8320,   2.9219],
         [  4.6875,  12.1875,  10.3125,  ...,   5.2500,   9.1875,   6.2188]],

        [[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -7.5938,   1.7656,   1.6328,  ...,  -5.0312,  -3.7969,  -1.6562],
         [ -8.6875,   8.4375,   5.0312,  ...,  -2.2812,  -1.7656,   2.5312],
         [  5.8125,  12.3750,   9.8750,  ...,   4.7812,   8.5000,   6.6250]]],
       device='cuda:0'),)
(tensor([[[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -7.1562,   2.4375,   2.5000,  ...,  -4.6250,  -3.2500,  -0.7852],
         [ -8.2500,   9.0625,   5.7812,  ...,  -1.3359,  -0.9883,   2.8906],
         [  4.5938,  12.1875,  10.2500,  ...,   5.1875,   8.8750,   6.1250]],

        [[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -6.7188,   1.8906,   2.2031,  ...,  -5.1250,  -3.7188,  -1.2656],
         [ -7.9688,   9.0000,   5.6875,  ...,  -1.5391,  -1.0312,   2.7656],
         [  4.8125,  11.9375,  10.1875,  ...,   5.0938,   9.0000,   6.0000]]],
       device='cuda:0'),)
(tensor([[[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -7.2500,   1.0547,   1.6875,  ...,  -5.2500,  -3.8438,  -1.6875],
         [ -8.9375,   8.6250,   5.0938,  ...,  -2.1250,  -1.7656,   2.9219],
         [  4.7500,  12.5625,  10.1250,  ...,   5.2188,   8.8125,   6.7188]],

        [[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -7.7500,   0.7383,   1.4219,  ...,  -5.7500,  -4.4062,  -2.0938],
         [ -9.5000,   7.7500,   4.8438,  ...,  -2.4844,  -2.2031,   1.8594],
         [  4.9688,  12.0000,   9.8750,  ...,   4.8750,   8.8125,   6.0625]]],
       device='cuda:0'),)
(tensor([[[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -8.1250,   0.6172,   1.2656,  ...,  -5.7188,  -4.5625,  -2.1875],
         [ -8.5625,   8.4375,   5.2812,  ...,  -1.9375,  -1.5156,   2.5938],
         [  5.3438,  12.1875,  10.1875,  ...,   4.9375,   9.0625,   6.5312]],

        [[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -7.2812,   1.7578,   1.7109,  ...,  -5.1250,  -4.0625,  -1.7812],
         [ -8.4375,   8.8125,   5.3125,  ...,  -2.0312,  -1.5391,   2.8125],
         [  5.9062,  12.5000,   9.8750,  ...,   4.8125,   8.5000,   6.7812]]],
       device='cuda:0'),)
(tensor([[[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -7.3125,   1.1094,   1.6406,  ...,  -5.3125,  -3.8125,  -1.7422],
         [ -9.0625,   8.5000,   5.0000,  ...,  -2.2188,  -1.8594,   2.5938],
         [  5.0000,  12.6250,  10.2500,  ...,   5.2500,   9.0625,   6.8750]],

        [[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -6.7188,   1.4766,   1.8906,  ...,  -5.3750,  -3.9531,  -1.4922],
         [ -8.5625,   8.5625,   5.2500,  ...,  -2.0938,  -1.7109,   2.4688],
         [  5.6875,  12.3750,  10.3125,  ...,   4.9062,   8.9375,   6.6562]]],
       device='cuda:0'),)
(tensor([[[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -6.7812,   1.3359,   1.8438,  ...,  -5.4688,  -4.0625,  -1.6562],
         [ -8.6875,   8.4375,   5.1875,  ...,  -2.0938,  -1.7188,   2.4375],
         [  5.5938,  12.4375,  10.2500,  ...,   5.0000,   8.8750,   6.6875]],

        [[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -7.5312,   1.0156,   1.6562,  ...,  -5.6562,  -4.2812,  -2.0781],
         [ -8.5000,   9.1250,   5.5625,  ...,  -1.6953,  -1.1016,   2.4844],
         [  5.1875,  11.8125,  10.1875,  ...,   4.6875,   8.8125,   5.7188]]],
       device='cuda:0'),)
(tensor([[[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -7.8750,   1.0391,   1.4219,  ...,  -5.5938,  -4.4688,  -1.9297],
         [ -8.3125,   9.0000,   5.3438,  ...,  -1.7266,  -1.3984,   2.8125],
         [  5.1562,  12.7500,  10.4375,  ...,   5.3438,   9.3125,   6.9062]],

        [[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -7.9062,   1.4453,   1.6953,  ...,  -5.4688,  -4.2812,  -1.7734],
         [ -8.9375,   8.5000,   5.2188,  ...,  -2.1719,  -1.8438,   2.7344],
         [  5.1250,  12.4375,  10.0625,  ...,   5.0625,   8.7500,   6.7812]]],
       device='cuda:0'),)
(tensor([[[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -7.9688,   1.2109,   1.5625,  ...,  -5.5312,  -4.3438,  -1.8125],
         [ -8.4375,   8.6875,   5.3750,  ...,  -1.8828,  -1.2891,   2.7812],
         [  5.3438,  12.3125,  10.0000,  ...,   4.9688,   8.8125,   6.6562]],

        [[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -6.9062,   1.3750,   2.0156,  ...,  -5.1562,  -3.6562,  -1.4844],
         [ -8.8750,   8.6250,   5.3438,  ...,  -1.7500,  -1.5000,   2.6250],
         [  4.8438,  12.4375,  10.2500,  ...,   5.2188,   8.8750,   6.5312]]],
       device='cuda:0'),)
(tensor([[[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -8.0625,   0.6055,   1.3047,  ...,  -5.7500,  -4.6250,  -2.2344],
         [ -8.5625,   8.3125,   5.2812,  ...,  -1.9453,  -1.5547,   2.5625],
         [  5.4062,  12.4375,  10.3125,  ...,   5.0625,   9.0625,   6.7500]],

        [[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -7.8438,   0.8320,   1.3125,  ...,  -5.5625,  -4.2812,  -2.0469],
         [ -9.4375,   8.1875,   4.9062,  ...,  -2.3906,  -2.1094,   2.2500],
         [  5.1562,  12.3750,  10.0625,  ...,   5.0000,   9.0625,   6.4375]]],
       device='cuda:0'),)
(tensor([[[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -7.5625,   0.3086,   1.1406,  ...,  -6.0000,  -4.8438,  -2.4844],
         [ -8.6250,   8.3125,   4.9688,  ...,  -2.2188,  -1.7578,   2.3750],
         [  4.9688,  12.2500,  10.1875,  ...,   5.0000,   8.8750,   6.2188]],

        [[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -7.3750,   1.0391,   1.5391,  ...,  -5.4062,  -4.0938,  -1.8438],
         [ -9.1250,   8.5000,   5.0625,  ...,  -2.2500,  -1.8828,   2.6562],
         [  5.0312,  12.3125,  10.0625,  ...,   5.0312,   8.8125,   6.3438]]],
       device='cuda:0'),)
(tensor([[[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -7.8125,   0.7773,   1.4922,  ...,  -5.7500,  -4.4062,  -2.0625],
         [ -9.3750,   7.8750,   4.9688,  ...,  -2.4531,  -2.1094,   1.9766],
         [  5.0938,  11.9375,   9.9375,  ...,   4.8125,   8.8125,   6.0625]],

        [[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -7.4062,   1.6641,   1.8516,  ...,  -4.8750,  -3.8281,  -1.5000],
         [ -7.7812,   9.6250,   5.9688,  ...,  -0.8477,  -0.3457,   3.3281],
         [  5.1875,  12.4375,  10.1875,  ...,   5.2500,   9.2500,   6.3125]]],
       device='cuda:0'),)
(tensor([[[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -7.1250,   1.6016,   1.8906,  ...,  -5.2812,  -4.0312,  -1.4922],
         [ -8.5000,   9.0625,   5.4688,  ...,  -1.8906,  -1.5000,   3.1250],
         [  5.1250,  12.5000,  10.1250,  ...,   5.0625,   8.6250,   6.7188]],

        [[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -7.3125,   1.5547,   1.7500,  ...,  -5.3125,  -4.0625,  -1.6406],
         [ -8.5000,   8.9375,   5.2500,  ...,  -1.9766,  -1.6172,   2.8438],
         [  5.2500,  12.8750,  10.3750,  ...,   5.1875,   9.1250,   6.9688]]],
       device='cuda:0'),)
(tensor([[[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -7.2500,   1.7422,   1.8281,  ...,  -4.9375,  -3.7969,  -1.5703],
         [ -8.1875,   9.1250,   5.3125,  ...,  -1.9375,  -1.5078,   3.0938],
         [  5.8125,  12.4375,  10.0000,  ...,   4.7812,   8.4375,   6.6562]],

        [[-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         [-10.6250,  -6.1562,  -1.7656,  ...,  -9.7500,  -4.5938,  -2.1875],
         ...,
         [ -6.4062,   3.1719,   2.9375,  ...,  -4.0312,  -2.3125,  -0.4102],
         [ -6.8438,  10.8750,   6.4062,  ...,  -0.2090,   0.6523,   4.1875],
         [  5.5000,  13.3750,  10.8750,  ...,   6.1562,  10.3125,   7.0312]]],
       device='cuda:0'),)
{'eval_loss': 0.00301387719810009, 'eval_runtime': 35.2349, 'eval_samples_per_second': 6.698, 'eval_steps_per_second': 0.426, 'epoch': 0.42}
2025-09-29 23:53:38,298 - INFO - vq_config is None. initializing the ChameleonVQConfig with default values.

======================================== [DEBUGGING AT GLOBAL STEP: 50] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option B is correct because it shows the front-bottom-left view.', 'D': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option D is incorrect because it includes rotated non-symmetric faces.', 'A': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option A is incorrect because it includes rotated non-symmetric faces.', 'C': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option C is incorrect because it is a horizontally mirrored version of the front-bottom-right view.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option B is correct because it shows the front-bottom-left view.', 'D': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option D is incorrect because it includes rotated non-symmetric faces.', 'A': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option A is incorrect because it includes rotated non-symmetric faces.', 'C': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option C is incorrect because it is a horizontally mirrored version of the front-bottom-right view.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
[91mCould not generate and log output at step 50: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                   | 51/118 [16:25<41:23, 37.07s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 51] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'The yellow gear directly meshes with the green gear and therefore rotates in the opposite direction. The pink gear, driven through two meshing steps, rotates in the same direction as the green gear.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'The yellow gear directly meshes with the green gear and therefore rotates in the opposite direction. The pink gear, driven through two meshing steps, rotates in the same direction as the green gear.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 51: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                  | 52/118 [16:40<33:34, 30.52s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 52] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is correct because the initial state can be transformed into the final state.', 'ABC': 'Option ABC is incorrect because the initial state cannot be transformed into the final state.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is correct because the initial state can be transformed into the final state.', 'ABC': 'Option ABC is incorrect because the initial state cannot be transformed into the final state.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 52: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                 | 53/118 [16:55<27:56, 25.79s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 53] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'In the current state, the orange object pushes the blue object to the left, causing it to rotate counterclockwise.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'In the current state, the orange object pushes the blue object to the left, causing it to rotate counterclockwise.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 53: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                | 54/118 [17:09<23:58, 22.47s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 54] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is incorrect because holes in column 2 are missing.', 'D': 'Option D is incorrect because extra holes appear in column 3.', 'A': 'Option A is incorrect because holes that should appear in column 2 appear in column 3.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is incorrect because holes in column 2 are missing.', 'D': 'Option D is incorrect because extra holes appear in column 3.', 'A': 'Option A is incorrect because holes that should appear in column 2 appear in column 3.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 54: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                               | 55/118 [17:24<21:14, 20.23s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 55] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given three views, at least 16 cubes and at most 21 cubes are required to satisfy the constraints.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given three views, at least 16 cubes and at most 21 cubes are required to satisfy the constraints.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 55: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                              | 56/118 [17:39<19:15, 18.64s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 56] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'B': 'Option B is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'B': 'Option B is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 56: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                             | 57/118 [17:54<17:45, 17.47s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 57] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'D': 'Option D is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'D': 'Option D is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 57: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                            | 58/118 [18:09<16:36, 16.61s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 58] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is correct because it was obtained by removing one small cube from the original stack.', 'C': 'Option C is incorrect because the cube stack can be obtained by rotating the original stack around the y-axis by 180 degrees.', 'B': 'Option B is incorrect because the cube stack can be obtained by rotating the original stack around the z-axis by 90 degrees.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is correct because it was obtained by removing one small cube from the original stack.', 'C': 'Option C is incorrect because the cube stack can be obtained by rotating the original stack around the y-axis by 180 degrees.', 'B': 'Option B is incorrect because the cube stack can be obtained by rotating the original stack around the z-axis by 90 degrees.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 58: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                           | 59/118 [18:24<15:51, 16.13s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 59] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given three views, at least 9 cubes and at most 9 cubes are required to satisfy the constraints.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given three views, at least 9 cubes and at most 9 cubes are required to satisfy the constraints.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 59: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                          | 60/118 [18:39<15:17, 15.81s/it]
{'loss': 0.0046, 'grad_norm': 0.028594177216291428, 'learning_rate': 2.5688858559204056e-06, 'epoch': 0.51}
(tensor([[[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -8.2500,  -1.5859,   0.2539,  ...,  -7.9688,  -6.3438,  -4.0000],
         [ -9.5000,   5.6562,   4.1875,  ...,  -4.4375,  -3.6719,   0.0737],
         [  5.9375,  10.5625,   9.6250,  ...,   3.2031,   7.8750,   5.4375]],

        [[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -8.4375,  -1.5703,   0.1777,  ...,  -8.1250,  -6.6875,  -4.0938],
         [ -9.6875,   5.7188,   4.0938,  ...,  -4.3750,  -3.7188,   0.0598],
         [  5.5625,  10.7500,   9.8125,  ...,   3.4062,   7.7812,   5.6250]]],
       device='cuda:0'),)
 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                        | 2/15 [00:02<00:15,  1.19s/it]
(tensor([[[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -9.0625,  -1.7969,  -0.0569,  ...,  -7.9375,  -6.5000,  -4.0312],
         [ -9.5625,   5.9688,   3.9844,  ...,  -4.1250,  -3.3594,   0.3418],
         [  5.8125,  10.7500,   9.7500,  ...,   3.5781,   8.1875,   5.5938]],

        [[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -8.1875,  -0.9453,   0.3496,  ...,  -7.5000,  -6.1562,  -3.5781],
         [ -9.3750,   6.7500,   4.0938,  ...,  -4.1562,  -3.3750,   0.7383],
         [  5.0625,  11.1875,   9.8125,  ...,   3.8438,   7.6875,   5.7188]]],
       device='cuda:0'),)
(tensor([[[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -7.7188,  -0.2314,   1.0547,  ...,  -7.1250,  -5.5938,  -2.9844],
         [ -8.8125,   7.3125,   4.7500,  ...,  -3.2969,  -2.4375,   1.0078],
         [  4.6875,  11.3125,  10.2500,  ...,   4.3750,   8.3750,   5.7812]],

        [[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -9.0000,  -1.0391,   0.0260,  ...,  -7.5938,  -6.3125,  -3.8906],
         [ -9.5000,   6.3125,   3.8906,  ...,  -4.3438,  -3.5312,   0.3516],
         [  6.0625,  11.0625,   9.6250,  ...,   3.5312,   7.4688,   6.0000]]],
       device='cuda:0'),)
(tensor([[[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -8.0000,  -0.1016,   1.0859,  ...,  -7.0000,  -5.4375,  -2.9219],
         [ -8.8125,   6.9375,   4.6875,  ...,  -3.3594,  -2.5625,   0.7578],
         [  4.9062,  11.0000,  10.0625,  ...,   4.0000,   7.8750,   5.4375]],

        [[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -7.7188,  -0.2812,   1.0078,  ...,  -7.0938,  -5.6562,  -2.9844],
         [ -8.8125,   7.3125,   4.7500,  ...,  -3.1719,  -2.4062,   1.1016],
         [  4.9375,  11.3125,  10.3125,  ...,   4.4062,   8.4375,   5.7812]]],
       device='cuda:0'),)
(tensor([[[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -8.2500,  -1.4688,   0.2275,  ...,  -7.5625,  -6.1875,  -3.7031],
         [-10.0000,   6.2812,   3.8750,  ...,  -4.2812,  -3.6719,   0.6719],
         [  5.0000,  11.2500,   9.8750,  ...,   3.9688,   7.7812,   6.0938]],

        [[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -8.8125,  -1.7344,  -0.0227,  ...,  -8.1250,  -6.7500,  -4.1250],
         [-10.2500,   5.5938,   3.8438,  ...,  -4.4062,  -3.9219,  -0.1279],
         [  5.2188,  10.8125,   9.5625,  ...,   3.7188,   7.9688,   5.5000]]],
       device='cuda:0'),)
(tensor([[[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -9.1875,  -1.8047,  -0.1514,  ...,  -8.0625,  -6.8125,  -4.2188],
         [ -9.5000,   6.0000,   4.0312,  ...,  -4.1562,  -3.3125,   0.3691],
         [  5.6562,  11.0000,   9.9375,  ...,   3.7500,   8.1250,   6.0000]],

        [[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -8.4375,  -1.0625,   0.1523,  ...,  -7.6562,  -6.4688,  -3.9844],
         [ -9.1250,   6.7188,   4.3125,  ...,  -3.9062,  -3.0781,   0.7617],
         [  6.0312,  11.0625,   9.4375,  ...,   3.4375,   7.4688,   6.1250]]],
       device='cuda:0'),)
(tensor([[[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -8.5000,  -1.5469,   0.1128,  ...,  -7.7500,  -6.2812,  -3.9062],
         [-10.1875,   5.9688,   3.6094,  ...,  -4.6562,  -4.0625,   0.2383],
         [  5.2812,  11.5000,  10.1250,  ...,   4.0625,   8.0625,   6.3438]],

        [[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -7.6875,  -1.1953,   0.3711,  ...,  -7.7500,  -6.1250,  -3.5625],
         [ -9.5000,   6.2188,   4.0625,  ...,  -4.1562,  -3.4531,   0.3496],
         [  5.9062,  11.1250,  10.0000,  ...,   3.6094,   7.9062,   5.9688]]],
       device='cuda:0'),)
(tensor([[[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -8.0000,  -1.2891,   0.3164,  ...,  -7.8750,  -6.3438,  -3.7500],
         [ -9.4375,   6.3125,   4.0625,  ...,  -4.0938,  -3.4062,   0.3984],
         [  5.7812,  11.1250,   9.9375,  ...,   3.6562,   7.9375,   6.0000]],

        [[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -8.3750,  -1.4688,   0.2969,  ...,  -7.8750,  -6.4375,  -4.0625],
         [ -9.0625,   6.8125,   4.5000,  ...,  -3.6094,  -2.8125,   0.4199],
         [  5.2812,  10.6875,   9.8750,  ...,   3.5938,   7.8750,   5.1875]]],
       device='cuda:0'),)
(tensor([[[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -8.8125,  -1.3281,   0.0791,  ...,  -7.7812,  -6.5938,  -3.8750],
         [ -9.2500,   6.6562,   4.2188,  ...,  -3.7969,  -3.0156,   0.7969],
         [  5.4375,  11.5000,  10.3125,  ...,   4.2500,   8.5000,   6.5312]],

        [[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -8.6250,  -0.9102,   0.3652,  ...,  -7.6875,  -6.4062,  -3.7031],
         [ -9.8125,   6.3438,   4.0938,  ...,  -4.1875,  -3.5312,   0.4941],
         [  5.3125,  10.9375,   9.6875,  ...,   3.5469,   7.6250,   6.0312]]],
       device='cuda:0'),)
(tensor([[[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -9.0000,  -1.2734,   0.1738,  ...,  -7.7812,  -6.6250,  -3.8281],
         [ -9.0000,   6.5625,   4.3750,  ...,  -3.7500,  -2.8438,   0.7227],
         [  5.6562,  10.8750,   9.8125,  ...,   3.7031,   7.9062,   6.0625]],

        [[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -8.1875,  -1.3359,   0.4375,  ...,  -7.6250,  -6.2188,  -3.6875],
         [ -9.7500,   6.2500,   4.2188,  ...,  -3.8750,  -3.3438,   0.5430],
         [  4.9688,  11.2500,  10.1250,  ...,   4.0312,   7.9375,   5.9375]]],
       device='cuda:0'),)
(tensor([[[-1.0938e+01, -6.3125e+00, -1.7969e+00,  ..., -9.6875e+00,
          -4.6562e+00, -2.4844e+00],
         [-1.0938e+01, -6.3125e+00, -1.7969e+00,  ..., -9.6875e+00,
          -4.6562e+00, -2.4844e+00],
         [-1.0938e+01, -6.3125e+00, -1.7969e+00,  ..., -9.6875e+00,
          -4.6562e+00, -2.4844e+00],
         ...,
         [-9.0000e+00, -1.6953e+00, -1.8921e-02,  ..., -7.9688e+00,
          -6.7188e+00, -4.1562e+00],
         [-9.3125e+00,  6.0000e+00,  4.1875e+00,  ..., -4.0625e+00,
          -3.2344e+00,  3.9648e-01],
         [ 5.6875e+00,  1.0938e+01,  9.9375e+00,  ...,  3.6094e+00,
           8.0000e+00,  6.0000e+00]],

        [[-1.0938e+01, -6.3125e+00, -1.7969e+00,  ..., -9.6875e+00,
          -4.6562e+00, -2.4844e+00],
         [-1.0938e+01, -6.3125e+00, -1.7969e+00,  ..., -9.6875e+00,
          -4.6562e+00, -2.4844e+00],
         [-1.0938e+01, -6.3125e+00, -1.7969e+00,  ..., -9.6875e+00,
          -4.6562e+00, -2.4844e+00],
         ...,
         [-9.0625e+00, -1.8203e+00, -1.9922e-01,  ..., -8.1250e+00,
          -6.7500e+00, -4.2812e+00],
         [-1.0375e+01,  5.8438e+00,  3.6875e+00,  ..., -4.6250e+00,
          -4.0625e+00,  1.1047e-02],
         [ 5.5625e+00,  1.1125e+01,  9.7500e+00,  ...,  3.7500e+00,
           8.1875e+00,  5.8438e+00]]], device='cuda:0'),)
(tensor([[[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -9.0625,  -1.4375,   0.0178,  ...,  -7.7188,  -6.4688,  -3.9531],
         [ -9.0000,   6.3750,   4.1250,  ...,  -3.8906,  -3.0312,   0.4434],
         [  5.1562,  11.2500,  10.0625,  ...,   4.0938,   8.2500,   5.8438]],

        [[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -8.2500,  -1.4766,   0.0791,  ...,  -7.8125,  -6.3750,  -3.8750],
         [-10.1250,   6.1562,   3.8438,  ...,  -4.4062,  -3.7500,   0.3945],
         [  5.2188,  10.9375,   9.6875,  ...,   3.6719,   7.7812,   5.6562]]],
       device='cuda:0'),)
(tensor([[[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -8.5000,  -1.7031,   0.0566,  ...,  -8.1250,  -6.6875,  -4.0625],
         [-10.0000,   5.6562,   3.9844,  ...,  -4.4062,  -3.8281,  -0.1235],
         [  5.4062,  10.7500,   9.6875,  ...,   3.6562,   7.9375,   5.4688]],

        [[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -8.6875,  -1.1094,   0.2734,  ...,  -7.3125,  -6.2500,  -3.7812],
         [ -8.1875,   7.5625,   4.9375,  ...,  -2.8750,  -1.9922,   1.2344],
         [  5.6562,  11.3750,  10.1250,  ...,   4.2500,   8.5000,   5.9062]]],
       device='cuda:0'),)
(tensor([[[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -8.0625,  -0.6016,   0.6172,  ...,  -7.4062,  -6.1250,  -3.2969],
         [ -9.2500,   6.7812,   4.3750,  ...,  -3.9844,  -3.2188,   0.9414],
         [  5.4062,  11.0000,   9.7500,  ...,   3.7188,   7.5312,   6.0000]],

        [[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -8.3125,  -1.0234,   0.2852,  ...,  -7.6562,  -6.3125,  -3.7344],
         [ -9.8125,   6.4688,   3.9062,  ...,  -4.2500,  -3.7188,   0.6250],
         [  5.5312,  11.5625,  10.1875,  ...,   4.0938,   8.1875,   6.5625]]],
       device='cuda:0'),)
(tensor([[[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -8.5000,  -1.1328,   0.1846,  ...,  -7.5938,  -6.2500,  -3.8281],
         [ -9.0000,   7.0000,   4.2500,  ...,  -3.8750,  -3.0938,   0.9844],
         [  5.8125,  10.8750,   9.4375,  ...,   3.3594,   7.1875,   5.9062]],

        [[-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         [-10.9375,  -6.3125,  -1.7969,  ...,  -9.6875,  -4.6562,  -2.4844],
         ...,
         [ -8.6250,  -1.0703,   0.5000,  ...,  -7.5000,  -6.1875,  -3.6875],
         [ -8.7500,   7.2812,   4.5938,  ...,  -3.2344,  -2.2812,   1.0625],
         [  4.9688,  11.2500,  10.5000,  ...,   4.4375,   8.7500,   6.0000]]],
       device='cuda:0'),)
{'eval_loss': 0.0007201529224403203, 'eval_runtime': 35.018, 'eval_samples_per_second': 6.739, 'eval_steps_per_second': 0.428, 'epoch': 0.51}

======================================== [DEBUGGING AT GLOBAL STEP: 60] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'D': 'Option D is incorrect because it is the cross-section made by a plane perpendicular to the YZ plane and rotated 45 degrees around the x-axis.', 'B': 'Option B is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'D': 'Option D is incorrect because it is the cross-section made by a plane perpendicular to the YZ plane and rotated 45 degrees around the x-axis.', 'B': 'Option B is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 60: 'NoneType' object has no attribute 'shape'[0m
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                         | 61/118 [19:29<24:55, 26.24s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 61] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because it was obtained by rotating the original image 180 degrees.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 90 degrees and then flipping it horizontally.', 'B': 'Option B is incorrect because it was obtained by rotating the asymmetric patterns in the image.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is correct because it was obtained by rotating the original image 180 degrees.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 90 degrees and then flipping it horizontally.', 'B': 'Option B is incorrect because it was obtained by rotating the asymmetric patterns in the image.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 61: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                        | 62/118 [19:44<21:16, 22.80s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 62] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is correct because the squares with asymmetric patterns have been rotated, so it cannot form the cube shown in the left image.', 'C': 'Option C is incorrect because the relative positions of three faces match the cube shown in the left image.', 'D': 'Option D is incorrect because the relative positions of three faces match the cube shown in the left image.', 'A': 'Option A is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is correct because the squares with asymmetric patterns have been rotated, so it cannot form the cube shown in the left image.', 'C': 'Option C is incorrect because the relative positions of three faces match the cube shown in the left image.', 'D': 'Option D is incorrect because the relative positions of three faces match the cube shown in the left image.', 'A': 'Option A is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 62: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                       | 63/118 [19:59<18:39, 20.36s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 63] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because one cube is missing, resulting in an incorrect cube stack shape.', 'B': 'Option B is incorrect because one cube is missing, resulting in an incorrect cube stack shape.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is incorrect because one cube is missing, resulting in an incorrect cube stack shape.', 'B': 'Option B is incorrect because one cube is missing, resulting in an incorrect cube stack shape.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 63: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                      | 64/118 [20:14<16:53, 18.77s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 64] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is correct because the initial state can be transformed into the final state.', 'ACD': 'Option ACD is incorrect because the initial state cannot be transformed into the final state.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is correct because the initial state can be transformed into the final state.', 'ACD': 'Option ACD is incorrect because the initial state cannot be transformed into the final state.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 64: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                     | 65/118 [20:29<15:37, 17.69s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 65] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is correct because two faces have swapped positions, so it cannot form the cube shown in the left image.„ÄÇ', 'D': 'Option D is incorrect because the relative positions of three faces match the cube shown in the left image.', 'C': 'Option C is incorrect because the relative positions of three faces match the cube shown in the left image.', 'B': 'Option B is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is correct because two faces have swapped positions, so it cannot form the cube shown in the left image.„ÄÇ', 'D': 'Option D is incorrect because the relative positions of three faces match the cube shown in the left image.', 'C': 'Option C is incorrect because the relative positions of three faces match the cube shown in the left image.', 'B': 'Option B is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 65: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                    | 66/118 [20:44<14:35, 16.83s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 66] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'B': 'Option B is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'B': 'Option B is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 66: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                   | 67/118 [20:59<13:48, 16.24s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 67] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because it was obtained by rotating the original image 180 degrees.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it vertically.', 'B': 'Option B is incorrect because it was obtained by rotating the asymmetric patterns in the image.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is correct because it was obtained by rotating the original image 180 degrees.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it vertically.', 'B': 'Option B is incorrect because it was obtained by rotating the asymmetric patterns in the image.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 67: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                  | 68/118 [21:13<13:10, 15.81s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 68] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because the internal outlines are missing.', 'B': 'Option B is incorrect because the internal outlines are missing.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is incorrect because the internal outlines are missing.', 'B': 'Option B is incorrect because the internal outlines are missing.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 68: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                 | 69/118 [21:29<12:43, 15.59s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 69] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is correct because the squares with asymmetric patterns have been rotated, so it cannot form the cube shown in the left image.', 'A': 'Option A is incorrect because the relative positions of three faces match the cube shown in the left image.', 'C': 'Option C is incorrect because the relative positions of three faces match the cube shown in the left image.', 'D': 'Option D is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is correct because the squares with asymmetric patterns have been rotated, so it cannot form the cube shown in the left image.', 'A': 'Option A is incorrect because the relative positions of three faces match the cube shown in the left image.', 'C': 'Option C is incorrect because the relative positions of three faces match the cube shown in the left image.', 'D': 'Option D is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 69: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                | 70/118 [21:43<12:17, 15.37s/it]
{'loss': 0.0002, 'grad_norm': 0.06918802112340927, 'learning_rate': 1.8862862821480023e-06, 'epoch': 0.59}
(tensor([[[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -8.1250,  -1.8516,   0.2012,  ...,  -8.1875,  -6.5625,  -4.3438],
         [ -7.4688,   6.6250,   5.2812,  ...,  -3.2188,  -2.2812,   0.6719],
         [  5.6875,  10.6875,  10.3750,  ...,   3.2031,   7.7500,   5.4062]],

        [[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -8.3750,  -1.8125,   0.1309,  ...,  -8.3125,  -6.9375,  -4.4688],
         [ -7.6875,   6.7188,   5.0625,  ...,  -3.1406,  -2.2344,   0.7227],
         [  5.3125,  11.0625,  10.6250,  ...,   3.4219,   7.7500,   5.6250]]],
       device='cuda:0'),)
 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                        | 2/15 [00:02<00:15,  1.18s/it]
(tensor([[[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -8.8750,  -2.0000,  -0.0908,  ...,  -8.1250,  -6.8438,  -4.4688],
         [ -7.4688,   6.8125,   4.9375,  ...,  -2.9844,  -2.0156,   0.8203],
         [  5.6250,  11.0625,  10.5625,  ...,   3.5781,   8.1875,   5.5938]],

        [[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -8.1250,  -1.1719,   0.3184,  ...,  -7.7188,  -6.4375,  -3.8906],
         [ -7.3750,   7.3438,   4.9688,  ...,  -3.1719,  -2.1406,   1.0078],
         [  4.8750,  11.6875,  10.8125,  ...,   4.1250,   7.8438,   6.0000]]],
       device='cuda:0'),)
(tensor([[[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -7.5312,  -0.6328,   1.0078,  ...,  -7.4375,  -5.9062,  -3.4375],
         [ -6.8125,   8.0625,   5.5625,  ...,  -2.2656,  -1.2812,   1.4219],
         [  4.2188,  11.8750,  11.1875,  ...,   4.5625,   8.3125,   6.0312]],

        [[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -8.9375,  -1.5469,  -0.1152,  ...,  -8.0625,  -6.8438,  -4.5312],
         [ -7.3750,   7.2812,   4.8750,  ...,  -3.2500,  -2.2344,   0.8984],
         [  5.7500,  11.3125,  10.4375,  ...,   3.5938,   7.5938,   6.0312]]],
       device='cuda:0'),)
(tensor([[[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -7.4688,  -0.2598,   1.1875,  ...,  -7.1250,  -5.4688,  -3.1250],
         [ -6.7500,   7.7500,   5.5312,  ...,  -2.4375,  -1.4297,   1.1016],
         [  4.6250,  11.5000,  11.0000,  ...,   4.1875,   7.9375,   5.6562]],

        [[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -7.4688,  -0.6016,   0.9805,  ...,  -7.4062,  -5.9688,  -3.4219],
         [ -6.7812,   7.9375,   5.5312,  ...,  -2.2969,  -1.2969,   1.4062],
         [  4.4062,  11.9375,  11.2500,  ...,   4.6250,   8.4375,   6.0312]]],
       device='cuda:0'),)
(tensor([[[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -8.1875,  -1.7109,   0.2031,  ...,  -7.8750,  -6.5625,  -4.0312],
         [ -8.0000,   7.0938,   4.6562,  ...,  -3.2969,  -2.4531,   0.9609],
         [  4.7188,  11.5625,  10.8125,  ...,   4.0625,   7.7812,   6.2500]],

        [[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -8.6250,  -2.0781,  -0.0859,  ...,  -8.3750,  -7.0312,  -4.5312],
         [ -8.0000,   6.5625,   4.7812,  ...,  -3.2969,  -2.4219,   0.3711],
         [  4.9375,  11.1250,  10.4375,  ...,   3.7656,   8.0000,   5.5625]]],
       device='cuda:0'),)
(tensor([[[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -9.0000,  -2.0781,  -0.1992,  ...,  -8.2500,  -6.9688,  -4.5312],
         [ -7.2188,   6.9688,   5.0625,  ...,  -2.8281,  -1.7891,   0.9961],
         [  5.4062,  11.1875,  10.7500,  ...,   3.6406,   8.0625,   5.9375]],

        [[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -8.3125,  -1.4609,   0.0540,  ...,  -8.1250,  -7.0000,  -4.5000],
         [ -6.8750,   7.5312,   5.3750,  ...,  -2.9062,  -1.9297,   1.2188],
         [  5.8125,  11.2500,  10.2500,  ...,   3.5156,   7.6250,   6.1562]]],
       device='cuda:0'),)
(tensor([[[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -8.3125,  -1.6953,   0.1396,  ...,  -7.9062,  -6.5312,  -4.2188],
         [ -8.0625,   6.7500,   4.4688,  ...,  -3.6719,  -2.8438,   0.6484],
         [  4.9062,  11.7500,  11.0625,  ...,   4.1250,   8.0625,   6.5312]],

        [[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -7.9062,  -1.6562,   0.2539,  ...,  -8.0625,  -6.6250,  -4.1562],
         [ -7.5000,   7.1562,   4.9375,  ...,  -3.0469,  -2.0625,   0.8984],
         [  5.6875,  11.3750,  10.8125,  ...,   3.5781,   8.0000,   6.0312]]],
       device='cuda:0'),)
(tensor([[[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -7.9688,  -1.5547,   0.2656,  ...,  -8.1250,  -6.7188,  -4.1875],
         [ -7.5625,   7.2188,   4.9375,  ...,  -3.0156,  -2.0312,   0.9102],
         [  5.5312,  11.5000,  10.8125,  ...,   3.7500,   7.9688,   6.0938]],

        [[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -8.1250,  -1.8906,   0.2598,  ...,  -8.1875,  -6.7812,  -4.4688],
         [ -6.8750,   7.5000,   5.3438,  ...,  -2.7188,  -1.7969,   0.7812],
         [  4.8125,  10.9375,  10.6875,  ...,   3.6719,   7.7812,   5.2812]]],
       device='cuda:0'),)
(tensor([[[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -8.5000,  -1.4219,   0.1206,  ...,  -7.9688,  -6.7188,  -4.1250],
         [ -7.1250,   7.3750,   5.0625,  ...,  -2.6875,  -1.5234,   1.1406],
         [  5.0938,  11.7500,  11.1875,  ...,   4.2500,   8.3750,   6.5312]],

        [[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -8.4375,  -1.1484,   0.3945,  ...,  -7.9062,  -6.6562,  -4.0312],
         [ -7.6250,   7.2500,   5.0000,  ...,  -3.1406,  -2.1406,   1.0000],
         [  5.0625,  11.3750,  10.6250,  ...,   3.7656,   7.9062,   6.2812]]],
       device='cuda:0'),)
(tensor([[[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -8.6875,  -1.4453,   0.2139,  ...,  -7.9375,  -6.7812,  -4.1250],
         [ -6.8750,   7.4062,   5.3438,  ...,  -2.5312,  -1.3750,   1.2500],
         [  5.4688,  11.1875,  10.7500,  ...,   3.8125,   8.0625,   6.1875]],

        [[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -8.3125,  -1.8125,   0.2480,  ...,  -8.0625,  -6.6562,  -4.1562],
         [ -7.7188,   7.2812,   5.0000,  ...,  -2.8594,  -1.9609,   0.9883],
         [  4.6562,  11.6250,  11.0000,  ...,   4.0625,   7.9375,   6.1250]]],
       device='cuda:0'),)
(tensor([[[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -8.8750,  -1.9219,  -0.0415,  ...,  -8.2500,  -7.0312,  -4.5312],
         [ -7.2500,   6.9062,   5.1250,  ...,  -2.8438,  -1.7578,   0.9609],
         [  5.4688,  11.2500,  10.7500,  ...,   3.6406,   8.0625,   6.0625]],

        [[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -8.6875,  -1.8672,  -0.0923,  ...,  -8.1875,  -6.8438,  -4.4688],
         [ -8.6250,   6.5000,   4.4688,  ...,  -3.7031,  -2.8750,   0.3477],
         [  5.2188,  11.3750,  10.5625,  ...,   3.7656,   8.1875,   5.8750]]],
       device='cuda:0'),)
(tensor([[[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -9.0000,  -1.7031,  -0.0334,  ...,  -8.0625,  -6.8750,  -4.3125],
         [ -7.0312,   6.9375,   4.9062,  ...,  -2.9688,  -1.8750,   0.7734],
         [  4.9375,  11.6250,  10.9375,  ...,   4.1875,   8.2500,   5.9375]],

        [[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -8.0625,  -1.6406,   0.0742,  ...,  -8.0000,  -6.6562,  -4.1250],
         [ -8.0625,   6.9375,   4.7188,  ...,  -3.3594,  -2.4219,   0.8438],
         [  5.0625,  11.3125,  10.5000,  ...,   3.8125,   7.8438,   5.8750]]],
       device='cuda:0'),)
(tensor([[[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -8.6875,  -2.0781,  -0.0255,  ...,  -8.3750,  -7.0938,  -4.5312],
         [ -8.0000,   6.4375,   4.8125,  ...,  -3.3281,  -2.4688,   0.3105],
         [  5.0625,  11.0625,  10.5000,  ...,   3.6719,   7.9688,   5.6562]],

        [[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -8.3125,  -1.5156,   0.2178,  ...,  -7.6562,  -6.5000,  -4.2812],
         [ -6.0938,   8.1250,   5.8438,  ...,  -2.0156,  -0.9766,   1.5156],
         [  5.3125,  11.6875,  11.0625,  ...,   4.4062,   8.5000,   6.0938]]],
       device='cuda:0'),)
(tensor([[[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -7.8125,  -0.8320,   0.6328,  ...,  -7.5938,  -6.2812,  -3.5781],
         [ -7.1875,   7.5938,   5.2188,  ...,  -2.8594,  -1.8438,   1.3281],
         [  5.0938,  11.3125,  10.6875,  ...,   3.7188,   7.6250,   6.0312]],

        [[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -8.0625,  -1.1719,   0.3086,  ...,  -7.8438,  -6.5000,  -4.0312],
         [ -7.7812,   7.2812,   4.7500,  ...,  -3.2812,  -2.3281,   0.9922],
         [  5.3438,  11.8125,  11.0625,  ...,   4.0625,   8.1875,   6.5625]]],
       device='cuda:0'),)
(tensor([[[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -8.3125,  -1.4062,   0.1484,  ...,  -7.9062,  -6.6562,  -4.2188],
         [ -7.1250,   7.7188,   5.1250,  ...,  -2.9062,  -1.9922,   1.3359],
         [  5.7188,  11.1250,  10.3125,  ...,   3.4219,   7.3750,   5.9688]],

        [[-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         [-10.5000,  -6.2188,  -1.5859,  ...,  -9.5000,  -4.4688,  -2.3906],
         ...,
         [ -8.2500,  -1.2578,   0.4707,  ...,  -7.7188,  -6.3438,  -4.0938],
         [ -7.0312,   7.8438,   5.3125,  ...,  -2.3906,  -1.3125,   1.2578],
         [  4.3125,  11.7500,  11.3750,  ...,   4.5938,   8.6250,   6.1562]]],
       device='cuda:0'),)
{'eval_loss': 0.0009625325328670442, 'eval_runtime': 35.0859, 'eval_samples_per_second': 6.726, 'eval_steps_per_second': 0.428, 'epoch': 0.59}

======================================== [DEBUGGING AT GLOBAL STEP: 70] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given two views, at least 6 cubes and at most 6 cubes are required to satisfy the constraints.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given two views, at least 6 cubes and at most 6 cubes are required to satisfy the constraints.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 70: 'NoneType' object has no attribute 'shape'[0m
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                               | 71/118 [22:34<20:18, 25.93s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 71] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is incorrect because it is the cross-section made by a plane perpendicular to the YZ plane and rotated 45 degrees around the x-axis.', 'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'A': 'Option A is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is incorrect because it is the cross-section made by a plane perpendicular to the YZ plane and rotated 45 degrees around the x-axis.', 'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'A': 'Option A is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 71: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                              | 72/118 [22:49<17:19, 22.61s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 72] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is correct because the initial state can be transformed into the final state.', 'BCD': 'Option BCD is incorrect because the initial state cannot be transformed into the final state.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is correct because the initial state can be transformed into the final state.', 'BCD': 'Option BCD is incorrect because the initial state cannot be transformed into the final state.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 72: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                             | 73/118 [23:04<15:11, 20.27s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 73] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'D': 'Option D is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'D': 'Option D is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 73: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                            | 74/118 [23:19<13:42, 18.70s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 74] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is correct because the squares with asymmetric patterns have been rotated, so it cannot form the cube shown in the left image.', 'B': 'Option B is incorrect because the relative positions of three faces match the cube shown in the left image.', 'A': 'Option A is incorrect because the relative positions of three faces match the cube shown in the left image.', 'C': 'Option C is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is correct because the squares with asymmetric patterns have been rotated, so it cannot form the cube shown in the left image.', 'B': 'Option B is incorrect because the relative positions of three faces match the cube shown in the left image.', 'A': 'Option A is incorrect because the relative positions of three faces match the cube shown in the left image.', 'C': 'Option C is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 74: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                           | 75/118 [23:33<12:33, 17.53s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 75] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is incorrect because the internal outlines are missing.', 'A': 'Option A is incorrect because the internal outlines are missing.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is incorrect because the internal outlines are missing.', 'A': 'Option A is incorrect because the internal outlines are missing.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 75: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                          | 76/118 [23:49<11:46, 16.81s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 76] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'B': 'Option B is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'B': 'Option B is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 76: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                         | 77/118 [24:04<11:06, 16.25s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 77] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given two views, at least 7 cubes and at most 9 cubes are required to satisfy the constraints.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given two views, at least 7 cubes and at most 9 cubes are required to satisfy the constraints.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 77: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                        | 78/118 [24:18<10:32, 15.81s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 78] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because it was obtained by rotating the original image 180 degrees.', 'B': 'Option B is incorrect because it was obtained by rotating the original image 270 degrees and then flipping it horizontally.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 90 degrees and then flipping it vertically.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is correct because it was obtained by rotating the original image 180 degrees.', 'B': 'Option B is incorrect because it was obtained by rotating the original image 270 degrees and then flipping it horizontally.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 90 degrees and then flipping it vertically.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 78: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                       | 79/118 [24:33<10:05, 15.52s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 79] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option A is correct because it shows the back-top-left view.', 'B': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option B is incorrect because it includes rotated non-symmetric faces.', 'C': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option C is incorrect because it includes rotated non-symmetric faces.', 'D': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option D is incorrect because it is a vertically mirrored version of the back-top-right view.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option A is correct because it shows the back-top-left view.', 'B': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option B is incorrect because it includes rotated non-symmetric faces.', 'C': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option C is incorrect because it includes rotated non-symmetric faces.', 'D': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option D is incorrect because it is a vertically mirrored version of the back-top-right view.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 79: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                      | 80/118 [24:48<09:43, 15.35s/it]
{'loss': 0.0001, 'grad_norm': 0.21534280478954315, 'learning_rate': 1.2500000000000007e-06, 'epoch': 0.68}
(tensor([[[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -8.2500,  -2.2812,  -0.0220,  ...,  -8.3750,  -6.9062,  -4.6562],
         [ -7.0625,   6.4688,   5.2500,  ...,  -3.2656,  -2.3281,   0.5078],
         [  5.4375,  10.7500,  10.6875,  ...,   3.2812,   7.7188,   5.4062]],

        [[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -8.5625,  -2.3281,  -0.1396,  ...,  -8.6250,  -7.3438,  -4.7812],
         [ -7.5000,   6.5938,   5.0312,  ...,  -3.0938,  -2.2656,   0.5742],
         [  4.9375,  11.1250,  11.0000,  ...,   3.5000,   7.7812,   5.6562]]],
       device='cuda:0'),)
 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                        | 2/15 [00:02<00:15,  1.19s/it]
(tensor([[[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -9.0000,  -2.5000,  -0.3438,  ...,  -8.4375,  -7.1562,  -4.8125],
         [ -7.1562,   6.6250,   4.9375,  ...,  -3.0312,  -2.0781,   0.6641],
         [  5.3438,  11.0000,  10.8750,  ...,   3.6094,   8.0625,   5.5625]],

        [[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -8.3750,  -1.6094,   0.0299,  ...,  -8.0000,  -6.8750,  -4.2188],
         [ -7.2812,   7.0625,   4.9062,  ...,  -3.2188,  -2.2031,   0.7969],
         [  4.5000,  11.7500,  11.1250,  ...,   4.1562,   7.7500,   6.0000]]],
       device='cuda:0'),)
(tensor([[[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -7.5938,  -0.9844,   0.8281,  ...,  -7.6562,  -6.1875,  -3.7031],
         [ -6.7188,   7.8438,   5.5312,  ...,  -2.2812,  -1.3516,   1.2578],
         [  3.8125,  11.9375,  11.5000,  ...,   4.5938,   8.1875,   6.0312]],

        [[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -8.9375,  -1.9531,  -0.2930,  ...,  -8.3125,  -7.1562,  -4.8750],
         [ -7.2500,   6.9688,   4.8125,  ...,  -3.3281,  -2.3906,   0.6953],
         [  5.4375,  11.2500,  10.7500,  ...,   3.5781,   7.4688,   5.9062]]],
       device='cuda:0'),)
(tensor([[[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -7.8125,  -0.9219,   0.8750,  ...,  -7.5000,  -5.9375,  -3.6094],
         [ -6.6875,   7.5000,   5.4375,  ...,  -2.4688,  -1.4922,   0.9414],
         [  4.3750,  11.6875,  11.3750,  ...,   4.3750,   8.0000,   5.7812]],

        [[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -7.5312,  -0.9570,   0.8203,  ...,  -7.6250,  -6.1875,  -3.6562],
         [ -6.6250,   7.8125,   5.5000,  ...,  -2.3438,  -1.3828,   1.1953],
         [  4.0938,  11.9375,  11.5000,  ...,   4.6250,   8.2500,   6.0000]]],
       device='cuda:0'),)
(tensor([[[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -8.3125,  -2.1719,  -0.1079,  ...,  -8.1250,  -6.9375,  -4.4062],
         [ -7.8125,   6.9062,   4.6250,  ...,  -3.3750,  -2.5312,   0.7773],
         [  4.4375,  11.6875,  11.2500,  ...,   4.1250,   7.8125,   6.2812]],

        [[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -8.8750,  -2.4844,  -0.2617,  ...,  -8.6250,  -7.3438,  -4.8438],
         [ -8.0625,   6.2812,   4.6250,  ...,  -3.3594,  -2.5781,   0.1562],
         [  4.6562,  11.2500,  10.8125,  ...,   3.8125,   8.0000,   5.6250]]],
       device='cuda:0'),)
(tensor([[[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -9.2500,  -2.5000,  -0.4355,  ...,  -8.5000,  -7.3750,  -4.9688],
         [ -7.1562,   6.6562,   4.9688,  ...,  -2.9219,  -1.9062,   0.7812],
         [  5.0938,  11.3125,  11.1250,  ...,   3.7188,   8.0000,   5.9375]],

        [[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -8.3125,  -1.8203,  -0.1211,  ...,  -8.3125,  -7.2812,  -4.7812],
         [ -6.5938,   7.3750,   5.3750,  ...,  -2.8750,  -2.0000,   1.0547],
         [  5.5938,  11.2500,  10.5625,  ...,   3.5312,   7.5625,   6.1562]]],
       device='cuda:0'),)
(tensor([[[-1.0562e+01, -5.9375e+00, -1.5391e+00,  ..., -9.3750e+00,
          -4.6875e+00, -2.2188e+00],
         [-1.0562e+01, -5.9375e+00, -1.5391e+00,  ..., -9.3750e+00,
          -4.6875e+00, -2.2188e+00],
         [-1.0562e+01, -5.9375e+00, -1.5391e+00,  ..., -9.3750e+00,
          -4.6875e+00, -2.2188e+00],
         ...,
         [-8.6250e+00, -2.2969e+00, -1.7676e-01,  ..., -8.3125e+00,
          -7.0000e+00, -4.6875e+00],
         [-8.0000e+00,  6.5312e+00,  4.3750e+00,  ..., -3.7344e+00,
          -2.9062e+00,  3.9844e-01],
         [ 4.7188e+00,  1.1812e+01,  1.1438e+01,  ...,  4.1562e+00,
           8.0625e+00,  6.5000e+00]],

        [[-1.0562e+01, -5.9375e+00, -1.5391e+00,  ..., -9.3750e+00,
          -4.6875e+00, -2.2188e+00],
         [-1.0562e+01, -5.9375e+00, -1.5391e+00,  ..., -9.3750e+00,
          -4.6875e+00, -2.2188e+00],
         [-1.0562e+01, -5.9375e+00, -1.5391e+00,  ..., -9.3750e+00,
          -4.6875e+00, -2.2188e+00],
         ...,
         [-8.1250e+00, -2.1406e+00, -6.1417e-04,  ..., -8.3750e+00,
          -7.0625e+00, -4.5000e+00],
         [-7.4375e+00,  6.8750e+00,  4.8750e+00,  ..., -3.1562e+00,
          -2.2031e+00,  6.2500e-01],
         [ 5.5625e+00,  1.1438e+01,  1.1125e+01,  ...,  3.6719e+00,
           7.9688e+00,  6.0312e+00]]], device='cuda:0'),)
(tensor([[[-1.0562e+01, -5.9375e+00, -1.5391e+00,  ..., -9.3750e+00,
          -4.6875e+00, -2.2188e+00],
         [-1.0562e+01, -5.9375e+00, -1.5391e+00,  ..., -9.3750e+00,
          -4.6875e+00, -2.2188e+00],
         [-1.0562e+01, -5.9375e+00, -1.5391e+00,  ..., -9.3750e+00,
          -4.6875e+00, -2.2188e+00],
         ...,
         [-8.1875e+00, -2.1406e+00, -2.8076e-02,  ..., -8.4375e+00,
          -7.0938e+00, -4.5938e+00],
         [-7.4688e+00,  6.9062e+00,  4.8125e+00,  ..., -3.1094e+00,
          -2.1250e+00,  6.6016e-01],
         [ 5.2500e+00,  1.1500e+01,  1.1125e+01,  ...,  3.7812e+00,
           7.9688e+00,  6.0625e+00]],

        [[-1.0562e+01, -5.9375e+00, -1.5391e+00,  ..., -9.3750e+00,
          -4.6875e+00, -2.2188e+00],
         [-1.0562e+01, -5.9375e+00, -1.5391e+00,  ..., -9.3750e+00,
          -4.6875e+00, -2.2188e+00],
         [-1.0562e+01, -5.9375e+00, -1.5391e+00,  ..., -9.3750e+00,
          -4.6875e+00, -2.2188e+00],
         ...,
         [-8.3125e+00, -2.3906e+00, -1.3962e-03,  ..., -8.4375e+00,
          -7.1562e+00, -4.8438e+00],
         [-6.9062e+00,  7.0625e+00,  5.2188e+00,  ..., -2.9375e+00,
          -2.1250e+00,  4.7461e-01],
         [ 4.5000e+00,  1.1062e+01,  1.0938e+01,  ...,  3.6719e+00,
           7.7500e+00,  5.2188e+00]]], device='cuda:0'),)
(tensor([[[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -8.6875,  -1.9062,  -0.1235,  ...,  -8.3125,  -7.0625,  -4.5625],
         [ -7.1250,   7.0312,   4.9062,  ...,  -2.8125,  -1.6875,   0.9141],
         [  4.7188,  11.7500,  11.5000,  ...,   4.2500,   8.3125,   6.5312]],

        [[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -8.4375,  -1.4844,   0.2324,  ...,  -8.0625,  -6.8125,  -4.2812],
         [ -7.5000,   7.0625,   5.0000,  ...,  -3.1406,  -2.2344,   0.8164],
         [  4.6875,  11.5000,  11.0000,  ...,   3.8438,   7.9062,   6.3438]]],
       device='cuda:0'),)
(tensor([[[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -8.8750,  -1.9844,  -0.0723,  ...,  -8.2500,  -7.1562,  -4.5938],
         [ -6.8438,   7.0312,   5.1875,  ...,  -2.7031,  -1.5078,   0.9297],
         [  5.1875,  11.2500,  11.0625,  ...,   3.8438,   8.0000,   6.1562]],

        [[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -8.4375,  -2.2344,   0.0547,  ...,  -8.3125,  -6.9688,  -4.5312],
         [ -7.5000,   7.0312,   4.9375,  ...,  -2.9531,  -1.9531,   0.8125],
         [  4.3125,  11.7500,  11.3125,  ...,   4.0938,   7.9375,   6.1250]]],
       device='cuda:0'),)
(tensor([[[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -8.9375,  -2.3438,  -0.2754,  ...,  -8.4375,  -7.2812,  -4.8750],
         [ -7.0312,   6.6562,   5.0938,  ...,  -2.8906,  -1.8203,   0.7930],
         [  5.2500,  11.3125,  11.1250,  ...,   3.7188,   8.0625,   6.0938]],

        [[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -9.0000,  -2.4531,  -0.4102,  ...,  -8.5625,  -7.2500,  -4.9062],
         [ -8.4375,   6.3125,   4.4375,  ...,  -3.7188,  -2.9531,   0.1426],
         [  4.9688,  11.3750,  10.9375,  ...,   3.7969,   8.1250,   5.8438]]],
       device='cuda:0'),)
(tensor([[[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -9.1875,  -2.2188,  -0.3184,  ...,  -8.3125,  -7.2188,  -4.7188],
         [ -6.9062,   6.6562,   4.8750,  ...,  -3.0156,  -1.9219,   0.5586],
         [  4.5938,  11.6875,  11.3125,  ...,   4.3125,   8.1875,   5.9688]],

        [[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -8.4375,  -2.1562,  -0.1602,  ...,  -8.2500,  -7.0625,  -4.5312],
         [ -7.9375,   6.7812,   4.7188,  ...,  -3.2969,  -2.4375,   0.6914],
         [  4.7500,  11.3750,  10.8750,  ...,   3.7656,   7.8125,   5.8125]]],
       device='cuda:0'),)
(tensor([[[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -8.9375,  -2.5938,  -0.2969,  ...,  -8.6875,  -7.4375,  -4.8750],
         [ -7.9688,   6.1875,   4.7812,  ...,  -3.4062,  -2.5938,   0.1064],
         [  4.7500,  11.2500,  10.8750,  ...,   3.7656,   8.0000,   5.6875]],

        [[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -8.5000,  -1.8828,   0.0140,  ...,  -7.9062,  -6.8438,  -4.5938],
         [ -5.8750,   7.7812,   5.7500,  ...,  -2.1719,  -1.2031,   1.2266],
         [  5.0625,  11.7500,  11.3750,  ...,   4.4688,   8.4375,   6.0312]]],
       device='cuda:0'),)
(tensor([[[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -7.8750,  -1.1406,   0.4258,  ...,  -7.7812,  -6.6250,  -3.9062],
         [ -7.0312,   7.4688,   5.2188,  ...,  -2.8594,  -1.8984,   1.1406],
         [  4.6875,  11.3750,  11.0000,  ...,   3.7656,   7.6562,   6.0625]],

        [[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -8.1875,  -1.5312,   0.1318,  ...,  -8.0625,  -6.7500,  -4.2812],
         [ -7.6562,   7.0625,   4.6875,  ...,  -3.3281,  -2.3438,   0.8281],
         [  4.9688,  11.8750,  11.4375,  ...,   4.0938,   8.1250,   6.6250]]],
       device='cuda:0'),)
(tensor([[[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -8.5625,  -1.9375,  -0.1089,  ...,  -8.2500,  -7.0625,  -4.6250],
         [ -6.9688,   7.4375,   5.0625,  ...,  -2.9531,  -2.1406,   1.1094],
         [  5.3750,  11.0000,  10.6250,  ...,   3.3750,   7.2500,   5.8750]],

        [[-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         [-10.5625,  -5.9375,  -1.5391,  ...,  -9.3750,  -4.6875,  -2.2188],
         ...,
         [ -8.3750,  -1.7109,   0.2754,  ...,  -8.0000,  -6.7188,  -4.4062],
         [ -6.9375,   7.5625,   5.2188,  ...,  -2.4844,  -1.4688,   1.0625],
         [  4.1250,  11.7500,  11.6875,  ...,   4.5938,   8.5000,   6.1875]]],
       device='cuda:0'),)
{'eval_loss': 0.0010380694875493646, 'eval_runtime': 35.1095, 'eval_samples_per_second': 6.722, 'eval_steps_per_second': 0.427, 'epoch': 0.68}

======================================== [DEBUGGING AT GLOBAL STEP: 80] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option A is correct because it shows the back-bottom-left view.', 'C': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option C is incorrect because it includes rotated non-symmetric faces.', 'D': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option D is incorrect because it is a vertically mirrored version of the back-top-right view.', 'B': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option B is incorrect because it is a vertically mirrored version of the back-bottom-right view.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option A is correct because it shows the back-bottom-left view.', 'C': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option C is incorrect because it includes rotated non-symmetric faces.', 'D': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option D is incorrect because it is a vertically mirrored version of the back-top-right view.', 'B': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option B is incorrect because it is a vertically mirrored version of the back-bottom-right view.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 80: 'NoneType' object has no attribute 'shape'[0m
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                     | 81/118 [25:39<15:59, 25.93s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 81] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'When the outer gear is fixed, the planet gear revolves in the same direction as the sun gear rotates, but spins in the opposite direction.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'When the outer gear is fixed, the planet gear revolves in the same direction as the sun gear rotates, but spins in the opposite direction.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 81: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                    | 82/118 [25:54<13:36, 22.67s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 82] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option B is correct because it shows the front-top-right view.', 'C': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option C is incorrect because it includes rotated non-symmetric faces.', 'D': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option D is incorrect because it is a vertically mirrored version of the back-bottom-right view.', 'A': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option A is incorrect because it is a horizontally mirrored version of the front-bottom-left view.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option B is correct because it shows the front-top-right view.', 'C': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option C is incorrect because it includes rotated non-symmetric faces.', 'D': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option D is incorrect because it is a vertically mirrored version of the back-bottom-right view.', 'A': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option A is incorrect because it is a horizontally mirrored version of the front-bottom-left view.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 82: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                   | 83/118 [26:09<11:51, 20.32s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 83] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option D is correct because it shows the back-top-left view.', 'B': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option B is incorrect because it includes rotated non-symmetric faces.', 'A': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option A is incorrect because it is a vertically mirrored version of the front-top-left view.', 'C': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option C is incorrect because it is a vertically mirrored version of the back-bottom-left view.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option D is correct because it shows the back-top-left view.', 'B': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option B is incorrect because it includes rotated non-symmetric faces.', 'A': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option A is incorrect because it is a vertically mirrored version of the front-top-left view.', 'C': 'Assuming the bottom face is the first cell in the second row of the net, and the right face is the cell to its right. Option C is incorrect because it is a vertically mirrored version of the back-bottom-left view.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 83: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                  | 84/118 [26:23<10:34, 18.67s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 84] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is incorrect because holes in row 2 are missing.', 'B': 'Option B is incorrect because extra holes appear in row 4.', 'A': 'Option A is incorrect because holes that should appear in row 2 appear in row 4.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is incorrect because holes in row 2 are missing.', 'B': 'Option B is incorrect because extra holes appear in row 4.', 'A': 'Option A is incorrect because holes that should appear in row 2 appear in row 4.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 84: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                 | 85/118 [26:38<09:39, 17.55s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 85] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is correct because the initial arrow can be transformed into the final arrow.', 'CAB': 'Option CAB is incorrect because the initial arrow cannot be transformed into the final arrow.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is correct because the initial arrow can be transformed into the final arrow.', 'CAB': 'Option CAB is incorrect because the initial arrow cannot be transformed into the final arrow.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 85: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                | 86/118 [26:53<08:58, 16.81s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 86] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is correct because the initial state can be transformed into the target state.', 'BCA': 'Option BCA is incorrect because the initial state cannot be transformed into the target state.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is correct because the initial state can be transformed into the target state.', 'BCA': 'Option BCA is incorrect because the initial state cannot be transformed into the target state.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 86: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 87/118 [27:08<08:23, 16.23s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 87] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given two views, at least 11 cubes and at most 19 cubes are required to satisfy the constraints.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given two views, at least 11 cubes and at most 19 cubes are required to satisfy the constraints.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 87: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                              | 88/118 [27:23<07:55, 15.84s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 88] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is incorrect because the internal outlines are missing.', 'A': 'Option A is incorrect because the internal outlines are missing.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is incorrect because the internal outlines are missing.', 'A': 'Option A is incorrect because the internal outlines are missing.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 88: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 89/118 [27:38<07:30, 15.53s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 89] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is correct because it was obtained by removing one small cube from the original stack.', 'C': 'Option C is incorrect because the cube stack can be obtained by rotating the original stack around the y-axis by 270 degrees.', 'A': 'Option A is incorrect because the cube stack can be obtained by rotating the original stack around the y-axis by 90 degrees.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is correct because it was obtained by removing one small cube from the original stack.', 'C': 'Option C is incorrect because the cube stack can be obtained by rotating the original stack around the y-axis by 270 degrees.', 'A': 'Option A is incorrect because the cube stack can be obtained by rotating the original stack around the y-axis by 90 degrees.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 89: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                            | 90/118 [27:53<07:10, 15.37s/it]
{'loss': 0.0006, 'grad_norm': 0.004552816040813923, 'learning_rate': 7.080437170788723e-07, 'epoch': 0.76}
(tensor([[[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -9.2500,  -3.6562,  -0.7578,  ...,  -9.2500,  -8.0625,  -5.7500],
         [ -8.6250,   5.3125,   4.4375,  ...,  -4.0625,  -3.6406,  -0.2910],
         [  4.8125,  10.1250,  10.2500,  ...,   2.9375,   7.1562,   4.8750]],

        [[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -9.4375,  -3.6719,  -0.8789,  ...,  -9.4375,  -8.5000,  -5.8750],
         [ -9.0000,   5.2812,   4.1875,  ...,  -4.0625,  -3.7031,  -0.3555],
         [  4.4688,  10.5625,  10.6875,  ...,   3.1250,   7.2188,   5.0938]]],
       device='cuda:0'),)
 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                        | 2/15 [00:02<00:15,  1.18s/it]
(tensor([[[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [-10.0625,  -3.7031,  -1.0859,  ...,  -9.3125,  -8.1875,  -5.8438],
         [ -8.7500,   5.4688,   4.0312,  ...,  -3.9375,  -3.3906,  -0.0933],
         [  4.8750,  10.5000,  10.5625,  ...,   3.3281,   7.5625,   5.0625]],

        [[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -9.1875,  -3.0000,  -0.7109,  ...,  -8.9375,  -7.8750,  -5.3438],
         [ -8.5000,   6.2188,   4.1250,  ...,  -3.9375,  -3.3594,   0.1924],
         [  3.7969,  11.0625,  10.6875,  ...,   3.8125,   7.1562,   5.4062]]],
       device='cuda:0'),)
(tensor([[[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -8.5625,  -2.3438,   0.0317,  ...,  -8.5000,  -7.3750,  -4.8125],
         [ -8.1250,   6.8438,   4.7812,  ...,  -3.0781,  -2.5312,   0.5508],
         [  3.4375,  11.5000,  11.2500,  ...,   4.3750,   7.8438,   5.5000]],

        [[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -9.9375,  -3.2656,  -1.0469,  ...,  -9.0625,  -8.1250,  -5.8125],
         [ -8.3125,   6.0938,   4.1250,  ...,  -3.9844,  -3.3438,   0.0427],
         [  4.8750,  10.6875,  10.3750,  ...,   3.3125,   7.0000,   5.4062]]],
       device='cuda:0'),)
(tensor([[[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -8.7500,  -2.2188,   0.0498,  ...,  -8.5000,  -7.1562,  -4.6875],
         [ -8.3125,   6.3750,   4.5625,  ...,  -3.4375,  -2.8594,   0.1611],
         [  3.6875,  11.0625,  10.9375,  ...,   4.0000,   7.3750,   5.1875]],

        [[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -8.6250,  -2.4219,  -0.0242,  ...,  -8.5625,  -7.4375,  -4.8750],
         [ -8.0625,   6.8125,   4.7500,  ...,  -3.0469,  -2.4531,   0.5820],
         [  3.5469,  11.5000,  11.3125,  ...,   4.4062,   7.8438,   5.5312]]],
       device='cuda:0'),)
(tensor([[[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -9.3750,  -3.5938,  -0.8984,  ...,  -9.0000,  -8.0625,  -5.5938],
         [ -9.1875,   5.9688,   3.8594,  ...,  -4.0312,  -3.5938,   0.1553],
         [  3.9531,  11.1875,  11.0000,  ...,   3.9375,   7.3750,   5.8125]],

        [[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -9.7500,  -3.8594,  -1.0781,  ...,  -9.5625,  -8.5000,  -6.0000],
         [ -9.5000,   5.1250,   3.8281,  ...,  -4.2188,  -3.8438,  -0.6133],
         [  4.0625,  10.6875,  10.5000,  ...,   3.5469,   7.5000,   5.1562]]],
       device='cuda:0'),)
(tensor([[[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [-10.2500,  -3.8906,  -1.2344,  ...,  -9.4375,  -8.5000,  -6.0312],
         [ -8.8750,   5.3750,   4.0312,  ...,  -3.9219,  -3.4375,  -0.1328],
         [  4.5625,  10.6875,  10.8125,  ...,   3.4062,   7.5312,   5.3750]],

        [[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -9.4375,  -3.1406,  -0.9062,  ...,  -9.1250,  -8.3750,  -5.7812],
         [ -7.8750,   6.4375,   4.6250,  ...,  -3.5938,  -3.0312,   0.4395],
         [  4.9688,  10.5625,  10.0625,  ...,   3.1094,   6.9375,   5.5938]]],
       device='cuda:0'),)
(tensor([[[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -9.5000,  -3.6250,  -0.9414,  ...,  -9.1250,  -8.0625,  -5.6875],
         [ -9.3750,   5.5312,   3.5938,  ...,  -4.4062,  -4.0938,  -0.2949],
         [  4.2500,  11.3125,  11.1250,  ...,   3.8438,   7.5938,   5.9375]],

        [[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -9.1250,  -3.3594,  -0.7266,  ...,  -9.2500,  -8.1250,  -5.5625],
         [ -8.6875,   5.8750,   4.1562,  ...,  -3.8594,  -3.3906,  -0.0752],
         [  4.9062,  10.8750,  10.7500,  ...,   3.3125,   7.4062,   5.4688]]],
       device='cuda:0'),)
(tensor([[[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -9.0625,  -3.2969,  -0.6562,  ...,  -9.2500,  -8.0625,  -5.5938],
         [ -8.8125,   5.7500,   4.0312,  ...,  -3.9375,  -3.3750,  -0.0498],
         [  4.7812,  11.0000,  10.8750,  ...,   3.4688,   7.4375,   5.5938]],

        [[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -9.3125,  -3.6094,  -0.6953,  ...,  -9.2500,  -8.1875,  -5.8125],
         [ -8.0000,   6.2500,   4.6250,  ...,  -3.5000,  -3.0312,   0.0127],
         [  3.8594,  10.5000,  10.7500,  ...,   3.4375,   7.2812,   4.7500]]],
       device='cuda:0'),)
(tensor([[[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -9.6250,  -3.2500,  -0.9297,  ...,  -9.1875,  -8.2500,  -5.6875],
         [ -8.6875,   5.9688,   4.0625,  ...,  -3.6875,  -3.0781,   0.1543],
         [  4.2812,  11.2500,  11.2500,  ...,   3.9375,   7.8438,   6.0000]],

        [[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -9.5625,  -2.8906,  -0.6133,  ...,  -9.0000,  -8.0625,  -5.3750],
         [ -9.0000,   5.9688,   4.1875,  ...,  -3.9531,  -3.5000,   0.0469],
         [  4.1250,  10.8125,  10.5625,  ...,   3.4219,   7.2188,   5.6562]]],
       device='cuda:0'),)
(tensor([[[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -9.8750,  -3.2656,  -0.8633,  ...,  -9.2500,  -8.2500,  -5.6562],
         [ -8.3125,   6.0625,   4.3750,  ...,  -3.5000,  -2.8438,   0.2891],
         [  4.6875,  10.7500,  10.7500,  ...,   3.5469,   7.4688,   5.6250]],

        [[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -9.3125,  -3.6094,  -0.7344,  ...,  -9.1875,  -8.0625,  -5.5938],
         [ -9.1250,   5.8438,   4.0625,  ...,  -3.7969,  -3.3906,   0.0121],
         [  3.8125,  11.1250,  11.0625,  ...,   3.7500,   7.3750,   5.5312]]],
       device='cuda:0'),)
(tensor([[[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [-10.0000,  -3.7500,  -1.0938,  ...,  -9.3750,  -8.3750,  -5.9688],
         [ -8.7500,   5.4688,   4.1562,  ...,  -3.8750,  -3.3594,  -0.0879],
         [  4.7812,  10.7500,  10.8125,  ...,   3.4531,   7.5312,   5.5625]],

        [[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -9.8125,  -3.8125,  -1.1719,  ...,  -9.3750,  -8.3125,  -5.9688],
         [ -9.8750,   5.3438,   3.6250,  ...,  -4.5312,  -4.1250,  -0.5469],
         [  4.4375,  10.8125,  10.6875,  ...,   3.5000,   7.6250,   5.3438]]],
       device='cuda:0'),)
(tensor([[[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [-10.0625,  -3.4375,  -1.0000,  ...,  -9.1875,  -8.2500,  -5.7188],
         [ -8.4375,   5.7812,   4.0625,  ...,  -3.8281,  -3.1719,  -0.1592],
         [  3.9531,  11.1250,  10.9375,  ...,   3.9062,   7.6562,   5.4375]],

        [[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -9.3750,  -3.4531,  -0.9531,  ...,  -9.1875,  -8.1875,  -5.6562],
         [ -9.3125,   5.7188,   3.8594,  ...,  -4.1250,  -3.7031,  -0.0806],
         [  4.1250,  10.7500,  10.5000,  ...,   3.4688,   7.2500,   5.2812]]],
       device='cuda:0'),)
(tensor([[[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -9.6875,  -3.9375,  -1.0391,  ...,  -9.5625,  -8.5625,  -6.0000],
         [ -9.3125,   5.2500,   4.0625,  ...,  -4.1562,  -3.7500,  -0.5391],
         [  4.1562,  10.6250,  10.5000,  ...,   3.4531,   7.4375,   5.1250]],

        [[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -9.5625,  -3.2031,  -0.8047,  ...,  -8.8125,  -7.9688,  -5.5938],
         [ -7.4062,   6.7812,   4.9375,  ...,  -2.9531,  -2.3750,   0.5586],
         [  4.4688,  11.1250,  11.0625,  ...,   4.1250,   7.9062,   5.5312]]],
       device='cuda:0'),)
(tensor([[[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -9.0000,  -2.6406,  -0.4004,  ...,  -8.7500,  -7.8125,  -5.0625],
         [ -8.4375,   6.4062,   4.4375,  ...,  -3.6562,  -3.1406,   0.4805],
         [  4.1875,  10.6875,  10.6875,  ...,   3.3906,   6.9688,   5.4375]],

        [[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -9.1875,  -2.9844,  -0.7578,  ...,  -9.0625,  -7.9688,  -5.5000],
         [ -8.9375,   6.0625,   3.8438,  ...,  -4.1250,  -3.5625,   0.1235],
         [  4.5312,  11.3125,  11.1875,  ...,   3.8281,   7.5938,   6.0625]]],
       device='cuda:0'),)
(tensor([[[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -9.5625,  -3.1875,  -0.8555,  ...,  -9.0625,  -8.0625,  -5.5938],
         [ -8.3750,   6.4688,   4.2812,  ...,  -3.6719,  -3.1875,   0.4355],
         [  4.8438,  10.5000,  10.2500,  ...,   3.1719,   6.7812,   5.4375]],

        [[-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         [-11.1875,  -6.3438,  -1.7656,  ...,  -9.5625,  -4.7812,  -2.3750],
         ...,
         [ -9.5625,  -3.0156,  -0.5469,  ...,  -8.8750,  -7.9062,  -5.4375],
         [ -8.4375,   6.5312,   4.3750,  ...,  -3.2969,  -2.6406,   0.3496],
         [  3.6094,  11.2500,  11.3750,  ...,   4.2812,   8.0000,   5.6250]]],
       device='cuda:0'),)
{'eval_loss': 0.0005465357098728418, 'eval_runtime': 35.0778, 'eval_samples_per_second': 6.728, 'eval_steps_per_second': 0.428, 'epoch': 0.76}

======================================== [DEBUGGING AT GLOBAL STEP: 90] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Assuming the bottom face is the first cell in the second row of the net, then after folding, the front face is blue, the back face is yellow, the left face is green, the right face is cyan, the top face is red, the bottom face is pink.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Assuming the bottom face is the first cell in the second row of the net, then after folding, the front face is blue, the back face is yellow, the left face is green, the right face is cyan, the top face is red, the bottom face is pink.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 90: 'NoneType' object has no attribute 'shape'[0m
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                           | 91/118 [28:44<11:40, 25.93s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 91] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is correct because two faces have swapped positions, so it cannot form the cube shown in the left image.„ÄÇ', 'C': 'Option C is incorrect because the relative positions of three faces match the cube shown in the left image.', 'A': 'Option A is incorrect because the relative positions of three faces match the cube shown in the left image.', 'D': 'Option D is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is correct because two faces have swapped positions, so it cannot form the cube shown in the left image.„ÄÇ', 'C': 'Option C is incorrect because the relative positions of three faces match the cube shown in the left image.', 'A': 'Option A is incorrect because the relative positions of three faces match the cube shown in the left image.', 'D': 'Option D is incorrect because the relative positions of three faces match the cube shown in the left image.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 91: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                          | 92/118 [28:59<09:48, 22.62s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 92] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Given three views, at least 5 cubes and at most 5 cubes are required to satisfy the constraints.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Given three views, at least 5 cubes and at most 5 cubes are required to satisfy the constraints.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 92: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 93/118 [29:13<08:27, 20.28s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 93] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because it was obtained by rotating the original image 180 degrees.', 'B': 'Option B is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it horizontally.', 'A': 'Option A is incorrect because it was obtained by rotating the asymmetric patterns in the image.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is correct because it was obtained by rotating the original image 180 degrees.', 'B': 'Option B is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it horizontally.', 'A': 'Option A is incorrect because it was obtained by rotating the asymmetric patterns in the image.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 93: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                        | 94/118 [29:28<07:27, 18.66s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 94] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because the initial state can be transformed into the final state.', 'ABD': 'Option ABD is incorrect because the initial state cannot be transformed into the final state.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is correct because the initial state can be transformed into the final state.', 'ABD': 'Option ABD is incorrect because the initial state cannot be transformed into the final state.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 94: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 95/118 [29:43<06:44, 17.57s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 95] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is correct because it was obtained by rotating the original image 270 degrees.', 'B': 'Option B is incorrect because it was obtained by rotating the original image 270 degrees and then flipping it horizontally.', 'C': 'Option C is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it vertically.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is correct because it was obtained by rotating the original image 270 degrees.', 'B': 'Option B is incorrect because it was obtained by rotating the original image 270 degrees and then flipping it horizontally.', 'C': 'Option C is incorrect because it was obtained by rotating the original image 180 degrees and then flipping it vertically.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 95: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                      | 96/118 [29:58<06:08, 16.75s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 96] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is correct because the initial arrow can be transformed into the final arrow.', 'DAC': 'Option DAC is incorrect because the initial arrow cannot be transformed into the final arrow.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is correct because the initial arrow can be transformed into the final arrow.', 'DAC': 'Option DAC is incorrect because the initial arrow cannot be transformed into the final arrow.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 96: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                     | 97/118 [30:13<05:41, 16.25s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 97] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because the internal outlines are missing.', 'B': 'Option B is incorrect because the internal outlines are missing.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is incorrect because the internal outlines are missing.', 'B': 'Option B is incorrect because the internal outlines are missing.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 97: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                    | 98/118 [30:28<05:17, 15.86s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 98] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'In this connection, the orange object rotates in the opposite direction to the green object.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'In this connection, the orange object rotates in the opposite direction to the green object.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 98: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 99/118 [30:43<04:56, 15.59s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 99] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'Meshed gears rotate in opposite directions.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'Meshed gears rotate in opposite directions.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 99: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 100/118 [30:58<04:36, 15.35s/it]
{'loss': 0.0001, 'grad_norm': 0.003448189701884985, 'learning_rate': 3.0131562198377763e-07, 'epoch': 0.85}
(tensor([[[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [ -9.5000,  -3.8594,  -0.9062,  ...,  -9.4375,  -8.2500,  -5.9375],
         [ -8.8750,   5.1875,   4.3125,  ...,  -4.1562,  -3.8125,  -0.3379],
         [  4.7500,  10.0625,  10.2500,  ...,   2.8906,   7.0938,   4.8438]],

        [[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [ -9.6250,  -3.8750,  -1.0156,  ...,  -9.6250,  -8.6875,  -6.0312],
         [ -9.2500,   5.0938,   4.0312,  ...,  -4.1562,  -3.9062,  -0.4121],
         [  4.3750,  10.5625,  10.6875,  ...,   3.2188,   7.1875,   5.0625]]],
       device='cuda:0'),)
 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                        | 2/15 [00:02<00:15,  1.19s/it]
(tensor([[[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [-10.1875,  -4.0000,  -1.1953,  ...,  -9.4375,  -8.3750,  -6.0625],
         [ -9.0625,   5.3750,   3.8906,  ...,  -4.0625,  -3.6094,  -0.1621],
         [  4.7188,  10.4375,  10.5000,  ...,   3.2500,   7.5000,   5.0000]],

        [[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [ -9.5625,  -3.2344,  -0.8477,  ...,  -9.0625,  -8.1250,  -5.5000],
         [ -8.6875,   6.1562,   4.0625,  ...,  -3.9688,  -3.4844,   0.1855],
         [  3.6250,  11.0000,  10.6875,  ...,   3.8125,   7.1250,   5.3125]]],
       device='cuda:0'),)
(tensor([[[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [ -8.6250,  -2.4844,  -0.0679,  ...,  -8.6250,  -7.5625,  -4.9062],
         [ -8.3750,   6.6875,   4.6250,  ...,  -3.1875,  -2.6562,   0.4707],
         [  3.2500,  11.4375,  11.1875,  ...,   4.3438,   7.7188,   5.5000]],

        [[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [-10.0000,  -3.4062,  -1.1250,  ...,  -9.1250,  -8.1875,  -5.8750],
         [ -8.7500,   5.9062,   3.9375,  ...,  -4.1250,  -3.6250,  -0.0718],
         [  4.8125,  10.7500,  10.3750,  ...,   3.2969,   6.9688,   5.4062]]],
       device='cuda:0'),)
(tensor([[[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [ -8.9375,  -2.5156,  -0.1060,  ...,  -8.6875,  -7.3750,  -4.8750],
         [ -8.5625,   6.1250,   4.3750,  ...,  -3.5312,  -3.0938,   0.0525],
         [  3.6406,  10.9375,  10.9375,  ...,   4.0312,   7.3750,   5.1875]],

        [[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [ -8.8750,  -2.6562,  -0.1943,  ...,  -8.7500,  -7.6875,  -5.0625],
         [ -8.3750,   6.5938,   4.5625,  ...,  -3.1719,  -2.6875,   0.4336],
         [  3.5000,  11.5625,  11.3125,  ...,   4.4375,   7.8750,   5.5312]]],
       device='cuda:0'),)
(tensor([[[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [ -9.5625,  -3.7812,  -0.9805,  ...,  -9.1875,  -8.2500,  -5.6875],
         [ -9.6250,   5.5938,   3.6406,  ...,  -4.2500,  -3.9688,  -0.0413],
         [  3.9688,  11.1875,  11.0625,  ...,   3.9219,   7.3438,   5.7812]],

        [[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [-10.0000,  -4.0625,  -1.1406,  ...,  -9.6250,  -8.5625,  -6.0938],
         [ -9.7500,   4.9688,   3.7656,  ...,  -4.2812,  -4.0000,  -0.6992],
         [  3.8906,  10.5625,  10.5000,  ...,   3.5469,   7.3750,   5.0312]]],
       device='cuda:0'),)
(tensor([[[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [-10.3750,  -4.0312,  -1.3281,  ...,  -9.6250,  -8.6875,  -6.1875],
         [ -9.0625,   5.2500,   3.8594,  ...,  -4.0938,  -3.6406,  -0.2617],
         [  4.5312,  10.6250,  10.8125,  ...,   3.3906,   7.4375,   5.3438]],

        [[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [ -9.7500,  -3.3750,  -1.0625,  ...,  -9.3125,  -8.6250,  -6.0000],
         [ -8.1875,   6.2812,   4.5000,  ...,  -3.7344,  -3.2188,   0.3223],
         [  4.8125,  10.5000,  10.0625,  ...,   3.0781,   6.8438,   5.4375]]],
       device='cuda:0'),)
(tensor([[[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [ -9.6250,  -3.8125,  -1.0312,  ...,  -9.2500,  -8.1875,  -5.8438],
         [ -9.6875,   5.5312,   3.5625,  ...,  -4.4375,  -4.2500,  -0.3613],
         [  4.1250,  11.2500,  11.1250,  ...,   3.8906,   7.5625,   5.8750]],

        [[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [ -9.1250,  -3.4375,  -0.8164,  ...,  -9.3125,  -8.2500,  -5.6562],
         [ -9.1875,   5.6562,   3.9531,  ...,  -4.0312,  -3.6719,  -0.2002],
         [  4.8125,  10.8125,  10.7500,  ...,   3.2969,   7.3125,   5.4062]]],
       device='cuda:0'),)
(tensor([[[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [ -9.1875,  -3.4531,  -0.8008,  ...,  -9.3750,  -8.2500,  -5.7188],
         [ -9.0625,   5.6875,   3.9375,  ...,  -4.0000,  -3.6250,  -0.1348],
         [  4.6875,  11.0000,  10.8125,  ...,   3.4375,   7.3125,   5.5000]],

        [[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [ -9.5625,  -3.8125,  -0.8164,  ...,  -9.3125,  -8.3750,  -5.9375],
         [ -8.2500,   6.1875,   4.5000,  ...,  -3.5781,  -3.1875,  -0.0791],
         [  3.8281,  10.5000,  10.6875,  ...,   3.4375,   7.1875,   4.7188]]],
       device='cuda:0'),)
(tensor([[[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [ -9.8125,  -3.5469,  -1.0625,  ...,  -9.4375,  -8.5000,  -5.9062],
         [ -8.8750,   5.8125,   3.9531,  ...,  -3.8750,  -3.3438,   0.0239],
         [  4.1562,  11.2500,  11.2500,  ...,   3.9844,   7.8750,   5.9688]],

        [[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [ -9.7500,  -3.1094,  -0.8008,  ...,  -9.1875,  -8.3125,  -5.6250],
         [ -9.2500,   5.8750,   4.0625,  ...,  -3.9844,  -3.6094,   0.0287],
         [  4.0000,  10.8750,  10.6875,  ...,   3.4531,   7.1875,   5.6562]]],
       device='cuda:0'),)
(tensor([[[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [-10.0625,  -3.4688,  -0.9766,  ...,  -9.3750,  -8.5000,  -5.8125],
         [ -8.5625,   5.8750,   4.2812,  ...,  -3.6406,  -3.0625,   0.1611],
         [  4.5625,  10.6250,  10.8125,  ...,   3.5156,   7.3750,   5.5625]],

        [[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [ -9.5625,  -3.7344,  -0.8086,  ...,  -9.2500,  -8.2500,  -5.7188],
         [ -9.4375,   5.6875,   4.0312,  ...,  -3.8750,  -3.5625,  -0.1074],
         [  3.6875,  11.1250,  11.0625,  ...,   3.7656,   7.3750,   5.5312]]],
       device='cuda:0'),)
(tensor([[[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [-10.0000,  -3.8438,  -1.1406,  ...,  -9.4375,  -8.5625,  -6.0312],
         [ -8.9375,   5.2500,   4.0312,  ...,  -4.0000,  -3.5781,  -0.2139],
         [  4.6250,  10.7500,  10.8125,  ...,   3.5156,   7.5312,   5.5625]],

        [[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [-10.0625,  -3.9531,  -1.2734,  ...,  -9.5000,  -8.5625,  -6.0938],
         [-10.0625,   5.3125,   3.5469,  ...,  -4.5312,  -4.1875,  -0.5391],
         [  4.2500,  10.6875,  10.6250,  ...,   3.4688,   7.5312,   5.2812]]],
       device='cuda:0'),)
(tensor([[[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [-10.3125,  -3.6719,  -1.1484,  ...,  -9.3125,  -8.3750,  -5.9062],
         [ -8.6250,   5.6562,   4.0000,  ...,  -3.8594,  -3.3438,  -0.1797],
         [  3.8594,  11.0625,  10.9375,  ...,   3.9062,   7.5625,   5.3438]],

        [[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [ -9.4375,  -3.6875,  -1.1016,  ...,  -9.3125,  -8.3125,  -5.8125],
         [ -9.5000,   5.6250,   3.8438,  ...,  -4.2188,  -3.7969,  -0.1206],
         [  4.1875,  10.6875,  10.5625,  ...,   3.5000,   7.2500,   5.2188]]],
       device='cuda:0'),)
(tensor([[[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [ -9.8750,  -4.0625,  -1.1484,  ...,  -9.6875,  -8.6875,  -6.1250],
         [ -9.5000,   5.0625,   3.9062,  ...,  -4.3125,  -3.9688,  -0.6758],
         [  4.1562,  10.6250,  10.5625,  ...,   3.4844,   7.4375,   5.0938]],

        [[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [ -9.8750,  -3.4531,  -0.9414,  ...,  -9.0000,  -8.1875,  -5.8125],
         [ -7.7500,   6.6250,   4.7500,  ...,  -3.1094,  -2.6250,   0.4766],
         [  4.2812,  11.1250,  11.0000,  ...,   4.0938,   7.8750,   5.5312]]],
       device='cuda:0'),)
(tensor([[[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [ -9.1875,  -2.8750,  -0.5352,  ...,  -8.8750,  -8.0625,  -5.2500],
         [ -8.7500,   6.2812,   4.2812,  ...,  -3.7188,  -3.2969,   0.4316],
         [  3.9844,  10.6250,  10.6875,  ...,   3.4219,   6.9375,   5.4375]],

        [[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [ -9.3750,  -3.1719,  -0.8633,  ...,  -9.2500,  -8.1875,  -5.6250],
         [ -9.3125,   6.0312,   3.8281,  ...,  -4.1250,  -3.7188,   0.0840],
         [  4.4375,  11.3125,  11.1875,  ...,   3.8125,   7.5625,   6.0312]]],
       device='cuda:0'),)
(tensor([[[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [ -9.6250,  -3.4219,  -0.9609,  ...,  -9.1250,  -8.2500,  -5.7812],
         [ -8.3125,   6.4062,   4.2500,  ...,  -3.6875,  -3.2656,   0.4082],
         [  4.6562,  10.3750,  10.1250,  ...,   3.0312,   6.5938,   5.2812]],

        [[-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         [-11.0000,  -6.3125,  -1.7812,  ...,  -9.8125,  -4.9375,  -2.4844],
         ...,
         [ -9.6875,  -3.2344,  -0.6484,  ...,  -9.0000,  -8.0625,  -5.5938],
         [ -8.5000,   6.5000,   4.3750,  ...,  -3.3594,  -2.7500,   0.3613],
         [  3.5469,  11.1875,  11.3750,  ...,   4.3438,   8.0625,   5.6250]]],
       device='cuda:0'),)
{'eval_loss': 0.0008119387202896178, 'eval_runtime': 35.0489, 'eval_samples_per_second': 6.733, 'eval_steps_per_second': 0.428, 'epoch': 0.85}
2025-09-30 00:09:38,994 - INFO - vq_config is None. initializing the ChameleonVQConfig with default values.

======================================== [DEBUGGING AT GLOBAL STEP: 100] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is incorrect because the red cubes are not in the correct position in the view.', 'A': 'Option A is incorrect because the shape matches the right view instead of the left view, and the red cubes are not in the correct position.', 'C': 'Option C is incorrect because the image shows the right view of the cube stack instead of the left view.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is incorrect because the red cubes are not in the correct position in the view.', 'A': 'Option A is incorrect because the shape matches the right view instead of the left view, and the red cubes are not in the correct position.', 'C': 'Option C is incorrect because the image shows the right view of the cube stack instead of the left view.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
[91mCould not generate and log output at step 100: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 101/118 [32:28<10:41, 37.74s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 101] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is correct because it was obtained by removing one small cube from the original stack.', 'B': 'Option B is incorrect because the cube stack can be obtained by rotating the original stack around the x-axis by 270 degrees.', 'C': 'Option C is incorrect because the cube stack can be obtained by rotating the original stack around the x-axis by 90 degrees.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is correct because it was obtained by removing one small cube from the original stack.', 'B': 'Option B is incorrect because the cube stack can be obtained by rotating the original stack around the x-axis by 270 degrees.', 'C': 'Option C is incorrect because the cube stack can be obtained by rotating the original stack around the x-axis by 90 degrees.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 101: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                | 102/118 [32:43<08:15, 30.95s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 102] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is incorrect because holes in row 5 are missing.', 'D': 'Option D is incorrect because extra holes appear in row 2.', 'B': 'Option B is incorrect because holes that should appear in row 5 appear in row 2.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is incorrect because holes in row 5 are missing.', 'D': 'Option D is incorrect because extra holes appear in row 2.', 'B': 'Option B is incorrect because holes that should appear in row 5 appear in row 2.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 102: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 103/118 [32:58<06:31, 26.11s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 103] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'D': 'Option D is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'C': 'Option C is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'D': 'Option D is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 103: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 104/118 [33:13<05:18, 22.74s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 104] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is correct because the initial state can be transformed into the final state.', 'BCD': 'Option BCD is incorrect because the initial state cannot be transformed into the final state.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is correct because the initial state can be transformed into the final state.', 'BCD': 'Option BCD is incorrect because the initial state cannot be transformed into the final state.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 104: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 105/118 [33:28<04:25, 20.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 105] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'C': 'Option C is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'D': 'Option D is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XZ plane.', 'C': 'Option C is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 105: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 106/118 [33:43<03:45, 18.79s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 106] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is correct because the relative positions of three faces match the cube shown in the left image.', 'D': 'Option D is incorrect because the squares with asymmetric patterns have been rotated.', 'B': 'Option B is incorrect because the squares with asymmetric patterns have been rotated.', 'C': 'Option C is incorrect because two faces have swapped positions.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is correct because the relative positions of three faces match the cube shown in the left image.', 'D': 'Option D is incorrect because the squares with asymmetric patterns have been rotated.', 'B': 'Option B is incorrect because the squares with asymmetric patterns have been rotated.', 'C': 'Option C is incorrect because two faces have swapped positions.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 106: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 107/118 [33:57<03:13, 17.58s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 107] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is correct because it was obtained by rotating the original image 180 degrees.', 'C': 'Option C is incorrect because it was obtained by rotating the original image 90 degrees and then flipping it vertically.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 270 degrees and then flipping it horizontally.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is correct because it was obtained by rotating the original image 180 degrees.', 'C': 'Option C is incorrect because it was obtained by rotating the original image 90 degrees and then flipping it vertically.', 'A': 'Option A is incorrect because it was obtained by rotating the original image 270 degrees and then flipping it horizontally.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 107: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 108/118 [34:12<02:48, 16.81s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 108] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is correct because the relative positions of three faces match the cube shown in the left image.', 'B': 'Option B is incorrect because the squares with asymmetric patterns have been rotated.', 'C': 'Option C is incorrect because the squares with asymmetric patterns have been rotated.', 'D': 'Option D is incorrect because two faces have swapped positions.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is correct because the relative positions of three faces match the cube shown in the left image.', 'B': 'Option B is incorrect because the squares with asymmetric patterns have been rotated.', 'C': 'Option C is incorrect because the squares with asymmetric patterns have been rotated.', 'D': 'Option D is incorrect because two faces have swapped positions.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 108: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 109/118 [34:27<02:26, 16.27s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 109] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'C': 'Option C is correct because it was obtained by removing one small cube from the original stack.', 'B': 'Option B is incorrect because the cube stack can be obtained by rotating the original stack around the y-axis by 270 degrees.', 'A': 'Option A is incorrect because the cube stack can be obtained by rotating the original stack around the x-axis by 270 degrees.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'C': 'Option C is correct because it was obtained by removing one small cube from the original stack.', 'B': 'Option B is incorrect because the cube stack can be obtained by rotating the original stack around the y-axis by 270 degrees.', 'A': 'Option A is incorrect because the cube stack can be obtained by rotating the original stack around the x-axis by 270 degrees.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 109: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 110/118 [34:42<02:06, 15.87s/it]
{'loss': 0.0011, 'grad_norm': 0.004403860308229923, 'learning_rate': 6.050904343141095e-08, 'epoch': 0.93}
(tensor([[[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [ -9.4375,  -3.8438,  -0.8672,  ...,  -9.4375,  -8.2500,  -5.8750],
         [ -8.8125,   5.1562,   4.3125,  ...,  -4.1562,  -3.7656,  -0.3398],
         [  4.7500,  10.1250,  10.3750,  ...,   2.9219,   7.1562,   4.8750]],

        [[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [ -9.6250,  -3.7344,  -0.9492,  ...,  -9.5625,  -8.5625,  -5.9375],
         [ -9.3125,   5.1250,   4.0625,  ...,  -4.1250,  -3.8594,  -0.3535],
         [  4.3438,  10.5000,  10.6875,  ...,   3.1562,   7.2188,   5.0312]]],
       device='cuda:0'),)
 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                        | 2/15 [00:02<00:15,  1.18s/it]
(tensor([[[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [-10.1250,  -3.8750,  -1.1562,  ...,  -9.4375,  -8.3125,  -5.9375],
         [ -8.9375,   5.4688,   3.9688,  ...,  -3.9844,  -3.5938,  -0.1357],
         [  4.7812,  10.3750,  10.5625,  ...,   3.2812,   7.4688,   4.9688]],

        [[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [ -9.3750,  -3.1719,  -0.8086,  ...,  -9.0000,  -8.0625,  -5.4375],
         [ -8.7500,   6.1562,   4.0938,  ...,  -3.9531,  -3.4375,   0.2432],
         [  3.7656,  11.0625,  10.7500,  ...,   3.8281,   7.1562,   5.3750]]],
       device='cuda:0'),)
(tensor([[[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [ -8.8750,  -2.5625,  -0.0918,  ...,  -8.6875,  -7.6562,  -5.0000],
         [ -8.3750,   6.6562,   4.6875,  ...,  -3.1406,  -2.7031,   0.4492],
         [  3.3750,  11.5000,  11.3125,  ...,   4.4062,   7.8125,   5.5312]],

        [[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [-10.0625,  -3.4375,  -1.1328,  ...,  -9.1250,  -8.2500,  -5.9062],
         [ -8.7500,   6.0000,   3.9688,  ...,  -4.0312,  -3.5156,  -0.0327],
         [  4.8750,  10.8125,  10.5000,  ...,   3.3906,   7.0625,   5.5000]]],
       device='cuda:0'),)
(tensor([[[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [ -8.9375,  -2.4219,  -0.0444,  ...,  -8.6250,  -7.2812,  -4.8750],
         [ -8.5000,   6.3125,   4.5000,  ...,  -3.4375,  -2.9844,   0.2061],
         [  3.5625,  11.0000,  10.9375,  ...,   3.9688,   7.2812,   5.1250]],

        [[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [ -8.9375,  -2.7344,  -0.2207,  ...,  -8.7500,  -7.7812,  -5.0938],
         [ -8.4375,   6.5312,   4.6250,  ...,  -3.1562,  -2.6719,   0.4688],
         [  3.4688,  11.5625,  11.3125,  ...,   4.4688,   7.9062,   5.5625]]],
       device='cuda:0'),)
(tensor([[[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [ -9.6250,  -3.7500,  -0.9883,  ...,  -9.1250,  -8.2500,  -5.7188],
         [ -9.3750,   5.7500,   3.7500,  ...,  -4.0938,  -3.8125,   0.0623],
         [  3.8594,  11.1250,  11.0625,  ...,   3.9219,   7.3750,   5.7500]],

        [[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [ -9.9375,  -4.0312,  -1.1406,  ...,  -9.6250,  -8.6250,  -6.1250],
         [ -9.6875,   5.0938,   3.7812,  ...,  -4.2500,  -3.9688,  -0.6445],
         [  3.9688,  10.6250,  10.5625,  ...,   3.6250,   7.4375,   5.0625]]],
       device='cuda:0'),)
(tensor([[[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [-10.1875,  -4.0000,  -1.2891,  ...,  -9.5625,  -8.6250,  -6.1562],
         [ -9.0000,   5.2500,   3.9219,  ...,  -4.0312,  -3.6094,  -0.1875],
         [  4.4375,  10.6875,  10.8125,  ...,   3.3750,   7.4688,   5.3438]],

        [[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [ -9.6250,  -3.4062,  -1.0000,  ...,  -9.2500,  -8.5000,  -5.9688],
         [ -8.1875,   6.3750,   4.5312,  ...,  -3.6406,  -3.1562,   0.3770],
         [  4.9062,  10.5625,  10.1250,  ...,   3.1562,   6.9375,   5.5000]]],
       device='cuda:0'),)
(tensor([[[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [ -9.6250,  -3.7500,  -1.0078,  ...,  -9.1875,  -8.1875,  -5.8438],
         [ -9.5625,   5.6562,   3.6719,  ...,  -4.3438,  -4.0938,  -0.2383],
         [  4.1250,  11.3125,  11.1875,  ...,   3.9219,   7.5938,   5.9062]],

        [[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [ -9.0625,  -3.4688,  -0.8125,  ...,  -9.3125,  -8.1875,  -5.6562],
         [ -9.0625,   5.5938,   4.0312,  ...,  -3.9844,  -3.5938,  -0.1660],
         [  4.9062,  10.8750,  10.7500,  ...,   3.3594,   7.3750,   5.5000]]],
       device='cuda:0'),)
(tensor([[[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [ -9.1875,  -3.4531,  -0.7617,  ...,  -9.3750,  -8.2500,  -5.7188],
         [ -9.0000,   5.7188,   3.9688,  ...,  -3.9688,  -3.5781,  -0.1523],
         [  4.6875,  11.0000,  10.8750,  ...,   3.4844,   7.3750,   5.5000]],

        [[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [ -9.5000,  -3.7812,  -0.7852,  ...,  -9.3125,  -8.3750,  -5.8750],
         [ -8.3125,   6.2812,   4.5625,  ...,  -3.4844,  -3.0938,   0.0132],
         [  3.7344,  10.5000,  10.6875,  ...,   3.4531,   7.1875,   4.7188]]],
       device='cuda:0'),)
(tensor([[[-1.0812e+01, -6.1562e+00, -1.6250e+00,  ..., -9.5000e+00,
          -4.8125e+00, -2.2344e+00],
         [-1.0812e+01, -6.1562e+00, -1.6250e+00,  ..., -9.5000e+00,
          -4.8125e+00, -2.2344e+00],
         [-1.0812e+01, -6.1562e+00, -1.6250e+00,  ..., -9.5000e+00,
          -4.8125e+00, -2.2344e+00],
         ...,
         [-9.9375e+00, -3.5312e+00, -1.0469e+00,  ..., -9.3750e+00,
          -8.4375e+00, -5.9062e+00],
         [-8.8125e+00,  5.8750e+00,  3.9844e+00,  ..., -3.7969e+00,
          -3.2656e+00,  9.9609e-02],
         [ 4.1250e+00,  1.1250e+01,  1.1312e+01,  ...,  3.9844e+00,
           7.8125e+00,  5.9688e+00]],

        [[-1.0812e+01, -6.1562e+00, -1.6250e+00,  ..., -9.5000e+00,
          -4.8125e+00, -2.2344e+00],
         [-1.0812e+01, -6.1562e+00, -1.6250e+00,  ..., -9.5000e+00,
          -4.8125e+00, -2.2344e+00],
         [-1.0812e+01, -6.1562e+00, -1.6250e+00,  ..., -9.5000e+00,
          -4.8125e+00, -2.2344e+00],
         ...,
         [-9.7500e+00, -3.1406e+00, -7.8516e-01,  ..., -9.1875e+00,
          -8.2500e+00, -5.6250e+00],
         [-9.1250e+00,  5.8438e+00,  4.0625e+00,  ..., -4.0000e+00,
          -3.5781e+00, -1.3809e-03],
         [ 4.0312e+00,  1.0875e+01,  1.0625e+01,  ...,  3.5000e+00,
           7.2188e+00,  5.6250e+00]]], device='cuda:0'),)
(tensor([[[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [ -9.9375,  -3.4688,  -0.9219,  ...,  -9.2500,  -8.3750,  -5.7500],
         [ -8.3750,   6.0938,   4.3750,  ...,  -3.5312,  -2.9375,   0.2412],
         [  4.5000,  10.6875,  10.7500,  ...,   3.5156,   7.4062,   5.5312]],

        [[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [ -9.4375,  -3.7344,  -0.7578,  ...,  -9.2500,  -8.1875,  -5.6562],
         [ -9.3125,   5.7812,   4.0312,  ...,  -3.8125,  -3.5312,  -0.0447],
         [  3.7188,  11.1250,  11.1250,  ...,   3.7656,   7.3750,   5.5000]]],
       device='cuda:0'),)
(tensor([[[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [-10.1250,  -3.8750,  -1.1719,  ...,  -9.5000,  -8.5625,  -6.1250],
         [ -8.8125,   5.3750,   4.1250,  ...,  -3.9219,  -3.4844,  -0.1309],
         [  4.6250,  10.8125,  10.9375,  ...,   3.5312,   7.5625,   5.6250]],

        [[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [ -9.9375,  -3.9062,  -1.2656,  ...,  -9.4375,  -8.5000,  -6.0938],
         [ -9.8125,   5.4375,   3.6094,  ...,  -4.4375,  -4.1250,  -0.5234],
         [  4.2812,  10.8125,  10.7500,  ...,   3.5312,   7.5938,   5.3125]]],
       device='cuda:0'),)
(tensor([[[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [-10.0625,  -3.5781,  -1.0625,  ...,  -9.2500,  -8.3750,  -5.8438],
         [ -8.5625,   5.7500,   4.0312,  ...,  -3.8438,  -3.3281,  -0.1387],
         [  3.7500,  11.0625,  10.9375,  ...,   3.9062,   7.5625,   5.3438]],

        [[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [ -9.5000,  -3.7031,  -1.0625,  ...,  -9.3125,  -8.3125,  -5.8125],
         [ -9.3750,   5.6875,   3.8594,  ...,  -4.1250,  -3.7812,  -0.0684],
         [  4.0938,  10.7500,  10.6250,  ...,   3.5625,   7.2812,   5.2812]]],
       device='cuda:0'),)
(tensor([[[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [ -9.7500,  -4.0312,  -1.0703,  ...,  -9.6250,  -8.6250,  -6.0625],
         [ -9.5625,   5.0938,   3.9844,  ...,  -4.2188,  -3.9062,  -0.6211],
         [  4.0938,  10.6875,  10.6250,  ...,   3.5000,   7.4688,   5.1250]],

        [[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [ -9.8750,  -3.3906,  -0.9102,  ...,  -8.9375,  -8.1250,  -5.7500],
         [ -7.7812,   6.6250,   4.7812,  ...,  -3.0625,  -2.5938,   0.4609],
         [  4.3438,  11.1875,  11.0625,  ...,   4.1250,   7.9375,   5.5625]]],
       device='cuda:0'),)
(tensor([[[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [ -9.1875,  -2.8906,  -0.5469,  ...,  -8.9375,  -8.0625,  -5.2812],
         [ -8.6250,   6.2812,   4.3750,  ...,  -3.7188,  -3.2500,   0.4492],
         [  4.0000,  10.7500,  10.7500,  ...,   3.5000,   7.0000,   5.5312]],

        [[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [ -9.3125,  -3.2188,  -0.8672,  ...,  -9.1875,  -8.1875,  -5.6562],
         [ -9.3125,   5.9375,   3.8438,  ...,  -4.1562,  -3.7188,   0.0491],
         [  4.4688,  11.3125,  11.2500,  ...,   3.8438,   7.5938,   6.0000]]],
       device='cuda:0'),)
(tensor([[[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [ -9.6875,  -3.4219,  -0.9453,  ...,  -9.1250,  -8.2500,  -5.7500],
         [ -8.4375,   6.3438,   4.1875,  ...,  -3.7656,  -3.3438,   0.3945],
         [  4.7188,  10.5000,  10.2500,  ...,   3.1562,   6.7188,   5.3750]],

        [[-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         [-10.8125,  -6.1562,  -1.6250,  ...,  -9.5000,  -4.8125,  -2.2344],
         ...,
         [ -9.5625,  -3.1719,  -0.6250,  ...,  -9.0000,  -8.0000,  -5.5625],
         [ -8.5000,   6.5000,   4.3750,  ...,  -3.3438,  -2.7031,   0.3438],
         [  3.5156,  11.2500,  11.4375,  ...,   4.3438,   8.0625,   5.6562]]],
       device='cuda:0'),)
{'eval_loss': 0.0007650752668268979, 'eval_runtime': 35.2137, 'eval_samples_per_second': 6.702, 'eval_steps_per_second': 0.426, 'epoch': 0.93}

======================================== [DEBUGGING AT GLOBAL STEP: 110] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is correct because the relative positions of three faces match the cube shown in the left image.', 'C': 'Option C is incorrect because the squares with asymmetric patterns have been rotated.', 'A': 'Option A is incorrect because the squares with asymmetric patterns have been rotated.', 'B': 'Option B is incorrect because two faces have swapped positions.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is correct because the relative positions of three faces match the cube shown in the left image.', 'C': 'Option C is incorrect because the squares with asymmetric patterns have been rotated.', 'A': 'Option A is incorrect because the squares with asymmetric patterns have been rotated.', 'B': 'Option B is incorrect because two faces have swapped positions.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 110: 'NoneType' object has no attribute 'shape'[0m
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 111/118 [35:33<03:04, 26.32s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 111] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'D': 'Option D is incorrect because holes in row 2 are missing.', 'C': 'Option C is incorrect because extra holes appear in row 3.', 'A': 'Option A is incorrect because holes that should appear in row 2 appear in row 3.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'D': 'Option D is incorrect because holes in row 2 are missing.', 'C': 'Option C is incorrect because extra holes appear in row 3.', 'A': 'Option A is incorrect because holes that should appear in row 2 appear in row 3.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 111: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 112/118 [35:48<02:17, 22.87s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 112] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'The green rod only drives the blue gear to rotate clockwise.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'The green rod only drives the blue gear to rotate clockwise.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 112: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 113/118 [36:03<01:42, 20.52s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 113] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': "In this case, the green shaft rotates in the same direction as the green gear's own rotation."} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': "In this case, the green shaft rotates in the same direction as the green gear's own rotation."} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 113: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 114/118 [36:18<01:15, 18.81s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 114] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'ABCD': 'In this system, the pink rod and the orange object are effectively meshed, so the orange object rotates in the opposite direction of the pink rod.'} The final answer is <answer>A</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'ABCD': 'In this system, the pink rod and the orange object are effectively meshed, so the orange object rotates in the opposite direction of the pink rod.'} The final answer is <answer>A</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 114: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 115/118 [36:33<00:52, 17.66s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 115] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'C': 'Option C is incorrect because it is the cross-section made by a plane perpendicular to the YZ plane and rotated 135 degrees around the x-axis.', 'D': 'Option D is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>D</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is incorrect because it is the cross-section of the shape made by a plane parallel to the YZ plane.', 'B': 'Option B is incorrect because it is the cross-section of the shape made by a plane parallel to the XY plane.', 'C': 'Option C is incorrect because it is the cross-section made by a plane perpendicular to the YZ plane and rotated 135 degrees around the x-axis.', 'D': 'Option D is correct because the corresponding cross-section does not match the shape shown in the reference image.'} The final answer is <answer>D</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 115: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 116/118 [36:48<00:33, 16.80s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 116] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'B': 'Option B is correct because the initial state can be transformed into the target state.', 'ACD': 'Option BCD is incorrect because the initial state cannot be transformed into the target state.'} The final answer is <answer>B</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'B': 'Option B is correct because the initial state can be transformed into the target state.', 'ACD': 'Option BCD is incorrect because the initial state cannot be transformed into the target state.'} The final answer is <answer>B</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 116: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 117/118 [37:03<00:16, 16.32s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

======================================== [DEBUGGING AT GLOBAL STEP: 117] (TRAIN) ========================================

--- [1. Ground Truth Labels] ---
  - Sample 0 Label: [92m'A': 'Option A is incorrect because one cube is missing, resulting in an incorrect cube stack shape.', 'B': 'Option B is incorrect because one cube is missing, resulting in an incorrect cube stack shape.'} The final answer is <answer>C</answer>[0m

--- [2. Model Prediction from Logits] ---
  - Sample 0 Pred: [93m'A': 'Option A is incorrect because one cube is missing, resulting in an incorrect cube stack shape.', 'B': 'Option B is incorrect because one cube is missing, resulting in an incorrect cube stack shape.'} The final answer is <answer>C</answer>[0m
===========================================================================================================


--- [3. Live Generation Output] ---
multimodal_generation_mode text-only
[91mCould not generate and log output at step 117: 'NoneType' object has no attribute 'shape'[0m
Traceback (most recent call last):
  File "/data1/oujingfeng/project/twgi/Orthus/train/sft_orthus.py", line 265, in compute_loss
    generated_ids = self.model.generate(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2046, in generate
    return super().generate_cfg(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 2290, in generate_cfg
    result = self._sample_orthus_cfg(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/transformers/src/transformers/generation/utils.py", line 3958, in _sample_orthus_cfg
    outputs = self(**model_inputs, return_dict=True, mode=mode, cfg_scale=model_kwargs['cfg_scale'], \
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
           ^^^^^^^
  File "/data1/conda/envs/orthus/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1827, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data1/oujingfeng/project/twgi/Orthus/models/modeling_orthus_for_inteleave_cfg.py", line 2133, in forward
    bsz, seq_len, _ = target_image_latents.shape # [bsz, 1024, 256]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 118/118 [37:17<00:00, 15.84s/it]2025-09-30 00:15:23,291 - INFO - vq_config is None. initializing the ChameleonVQConfig with default values.
2025-09-30 00:15:23,291 - INFO - vq_config is None. initializing the ChameleonVQConfig with default values.
2025-09-30 00:15:23,324 - INFO - vq_config is None. initializing the ChameleonVQConfig with default values.
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 118/118 [37:53<00:00, 19.27s/it]
{'train_runtime': 2275.8038, 'train_samples_per_second': 0.415, 'train_steps_per_second': 0.052, 'train_loss': 1.8018471906750888, 'epoch': 1.0}
2025-09-30 00:15:49,181 - INFO -

‚úÖ [Success] Training completed successfully!
2025-09-30 00:15:49,181 - INFO - Saving final model...
2025-09-30 00:15:59,544 - INFO - vq_config is None. initializing the ChameleonVQConfig with default values.
2025-09-30 00:15:59,545 - INFO - vq_config is None. initializing the ChameleonVQConfig with default values.
2025-09-30 00:15:59,577 - INFO - vq_config is None. initializing the ChameleonVQConfig with default values.
2025-09-30 00:16:17,791 - INFO - Final model and processor saved to /data1/oujingfeng/project/twgi/checkpoints/orthus-7b-sft-v4
